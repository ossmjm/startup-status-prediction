{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c97d6be6e4094345877a14460c27b031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ba5e9fd4b4649ed9b267caf7b2feba8",
              "IPY_MODEL_95821f4925984ad8a5cf0d9d67fdd80a"
            ],
            "layout": "IPY_MODEL_801fa3d946784e57acdff5bcba29174c"
          }
        },
        "4ba5e9fd4b4649ed9b267caf7b2feba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edde8fe012214d488fbef7df1bfb9c35",
            "placeholder": "​",
            "style": "IPY_MODEL_6dae511030c942f883453eb57db72160",
            "value": "131.522 MB of 141.309 MB uploaded (0.342 MB deduped)\r"
          }
        },
        "95821f4925984ad8a5cf0d9d67fdd80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_437b8cce77d94cb69bff455c0ed8c264",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9b7e508bc824a47b4e11752d12478c3",
            "value": 0.9307435181795319
          }
        },
        "801fa3d946784e57acdff5bcba29174c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edde8fe012214d488fbef7df1bfb9c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dae511030c942f883453eb57db72160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "437b8cce77d94cb69bff455c0ed8c264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9b7e508bc824a47b4e11752d12478c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e707ce8d043c4cccaaf6629aace5cdd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c8d872bc68d423fbbbe910d77d16ab3",
              "IPY_MODEL_7b649d7e0ad44e50bf22f150f3d04f1b"
            ],
            "layout": "IPY_MODEL_01b9ea89c7614d1aae3b5090b12b568d"
          }
        },
        "7c8d872bc68d423fbbbe910d77d16ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24681ce362ba4303899da0b334398d9c",
            "placeholder": "​",
            "style": "IPY_MODEL_f1ab21fa4932460d862fcdb2211d9400",
            "value": "161.471 MB of 161.516 MB uploaded (0.399 MB deduped)\r"
          }
        },
        "7b649d7e0ad44e50bf22f150f3d04f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54916c17070b4a509a56db7bc8917f58",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa445047f6b14c509eab4f09b9820194",
            "value": 0.9997158989828043
          }
        },
        "01b9ea89c7614d1aae3b5090b12b568d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24681ce362ba4303899da0b334398d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ab21fa4932460d862fcdb2211d9400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54916c17070b4a509a56db7bc8917f58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa445047f6b14c509eab4f09b9820194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TDPL2-h4MDKx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/startup data.csv')"
      ],
      "metadata": {
        "id": "LW16BrFzMhr9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns',None)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "3udlcW8wMl6X",
        "outputId": "266778f7-28cd-48ca-da46-438bad30dd09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0 state_code   latitude   longitude zip_code       id  \\\n",
              "0          1005         CA  42.358880  -71.056820    92101   c:6669   \n",
              "1           204         CA  37.238916 -121.973718    95032  c:16283   \n",
              "2          1001         CA  32.901049 -117.192656    92121  c:65620   \n",
              "3           738         CA  37.320309 -122.050040    95014  c:42668   \n",
              "4          1002         CA  37.779281 -122.419236    94105  c:65806   \n",
              "..          ...        ...        ...         ...      ...      ...   \n",
              "918         352         CA  37.740594 -122.376471    94107  c:21343   \n",
              "919         721         MA  42.504817  -71.195611     1803  c:41747   \n",
              "920         557         CA  37.408261 -122.015920    94089  c:31549   \n",
              "921         589         CA  37.556732 -122.288378    94404  c:33198   \n",
              "922         462         CA  37.386778 -121.966277    95054  c:26702   \n",
              "\n",
              "              city              Unnamed: 6                  name  labels  \\\n",
              "0        San Diego                     NaN           Bandsintown       1   \n",
              "1        Los Gatos                     NaN             TriCipher       1   \n",
              "2        San Diego      San Diego CA 92121                 Plixi       1   \n",
              "3        Cupertino      Cupertino CA 95014     Solidcore Systems       1   \n",
              "4    San Francisco  San Francisco CA 94105        Inhale Digital       0   \n",
              "..             ...                     ...                   ...     ...   \n",
              "918  San Francisco                     NaN               CoTweet       1   \n",
              "919     Burlington      Burlington MA 1803    Reef Point Systems       0   \n",
              "920      Sunnyvale                     NaN       Paracor Medical       0   \n",
              "921  San Francisco                     NaN               Causata       1   \n",
              "922    Santa Clara    Santa Clara CA 95054  Asempra Technologies       1   \n",
              "\n",
              "    founded_at  closed_at first_funding_at last_funding_at  \\\n",
              "0     1/1/2007        NaN         4/1/2009        1/1/2010   \n",
              "1     1/1/2000        NaN        2/14/2005      12/28/2009   \n",
              "2    3/18/2009        NaN        3/30/2010       3/30/2010   \n",
              "3     1/1/2002        NaN        2/17/2005       4/25/2007   \n",
              "4     8/1/2010  10/1/2012         8/1/2010        4/1/2012   \n",
              "..         ...        ...              ...             ...   \n",
              "918   1/1/2009        NaN         7/9/2009        7/9/2009   \n",
              "919   1/1/1998  6/25/2008         4/1/2005       3/23/2007   \n",
              "920   1/1/1999  6/17/2012        6/29/2007       6/29/2007   \n",
              "921   1/1/2009        NaN        10/5/2009       11/1/2011   \n",
              "922   1/1/2003        NaN        2/13/2006       2/13/2006   \n",
              "\n",
              "     age_first_funding_year  age_last_funding_year  age_first_milestone_year  \\\n",
              "0                    2.2493                 3.0027                    4.6685   \n",
              "1                    5.1260                 9.9973                    7.0055   \n",
              "2                    1.0329                 1.0329                    1.4575   \n",
              "3                    3.1315                 5.3151                    6.0027   \n",
              "4                    0.0000                 1.6685                    0.0384   \n",
              "..                      ...                    ...                       ...   \n",
              "918                  0.5178                 0.5178                    0.5808   \n",
              "919                  7.2521                 9.2274                    6.0027   \n",
              "920                  8.4959                 8.4959                    9.0055   \n",
              "921                  0.7589                 2.8329                    0.7589   \n",
              "922                  3.1205                 3.1205                    4.0027   \n",
              "\n",
              "     age_last_milestone_year  relationships  funding_rounds  \\\n",
              "0                     6.7041              3               3   \n",
              "1                     7.0055              9               4   \n",
              "2                     2.2055              5               1   \n",
              "3                     6.0027              5               3   \n",
              "4                     0.0384              2               2   \n",
              "..                       ...            ...             ...   \n",
              "918                   4.5260              9               1   \n",
              "919                   6.0027              1               3   \n",
              "920                   9.0055              5               1   \n",
              "921                   3.8356             12               2   \n",
              "922                   4.0027              4               1   \n",
              "\n",
              "     funding_total_usd  milestones state_code.1  is_CA  is_NY  is_MA  is_TX  \\\n",
              "0               375000           3           CA      1      0      0      0   \n",
              "1             40100000           1           CA      1      0      0      0   \n",
              "2              2600000           2           CA      1      0      0      0   \n",
              "3             40000000           1           CA      1      0      0      0   \n",
              "4              1300000           1           CA      1      0      0      0   \n",
              "..                 ...         ...          ...    ...    ...    ...    ...   \n",
              "918            1100000           2           CA      1      0      0      0   \n",
              "919           52000000           1           MA      0      0      1      0   \n",
              "920           44000000           1           CA      1      0      0      0   \n",
              "921           15500000           2           CA      1      0      0      0   \n",
              "922           20000000           1           CA      1      0      0      0   \n",
              "\n",
              "     is_otherstate category_code  is_software  is_web  is_mobile  \\\n",
              "0                0         music            0       0          0   \n",
              "1                0    enterprise            0       0          0   \n",
              "2                0           web            0       1          0   \n",
              "3                0      software            1       0          0   \n",
              "4                0   games_video            0       0          0   \n",
              "..             ...           ...          ...     ...        ...   \n",
              "918              0   advertising            0       0          0   \n",
              "919              0      security            0       0          0   \n",
              "920              0       biotech            0       0          0   \n",
              "921              0      software            1       0          0   \n",
              "922              0      security            0       0          0   \n",
              "\n",
              "     is_enterprise  is_advertising  is_gamesvideo  is_ecommerce  is_biotech  \\\n",
              "0                0               0              0             0           0   \n",
              "1                1               0              0             0           0   \n",
              "2                0               0              0             0           0   \n",
              "3                0               0              0             0           0   \n",
              "4                0               0              1             0           0   \n",
              "..             ...             ...            ...           ...         ...   \n",
              "918              0               1              0             0           0   \n",
              "919              0               0              0             0           0   \n",
              "920              0               0              0             0           1   \n",
              "921              0               0              0             0           0   \n",
              "922              0               0              0             0           0   \n",
              "\n",
              "     is_consulting  is_othercategory object_id  has_VC  has_angel  has_roundA  \\\n",
              "0                0                 1    c:6669       0          1           0   \n",
              "1                0                 0   c:16283       1          0           0   \n",
              "2                0                 0   c:65620       0          0           1   \n",
              "3                0                 0   c:42668       0          0           0   \n",
              "4                0                 0   c:65806       1          1           0   \n",
              "..             ...               ...       ...     ...        ...         ...   \n",
              "918              0                 0   c:21343       0          0           1   \n",
              "919              0                 1   c:41747       1          0           0   \n",
              "920              0                 0   c:31549       0          0           0   \n",
              "921              0                 0   c:33198       0          0           1   \n",
              "922              0                 1   c:26702       0          0           0   \n",
              "\n",
              "     has_roundB  has_roundC  has_roundD  avg_participants  is_top500    status  \n",
              "0             0           0           0            1.0000          0  acquired  \n",
              "1             1           1           1            4.7500          1  acquired  \n",
              "2             0           0           0            4.0000          1  acquired  \n",
              "3             1           1           1            3.3333          1  acquired  \n",
              "4             0           0           0            1.0000          1    closed  \n",
              "..          ...         ...         ...               ...        ...       ...  \n",
              "918           0           0           0            6.0000          1  acquired  \n",
              "919           1           0           0            2.6667          1    closed  \n",
              "920           0           0           1            8.0000          1    closed  \n",
              "921           1           0           0            1.0000          1  acquired  \n",
              "922           1           0           0            3.0000          1  acquired  \n",
              "\n",
              "[923 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70784616-d1a1-463e-b482-8a37eb4bf69d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>state_code</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>id</th>\n",
              "      <th>city</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>name</th>\n",
              "      <th>labels</th>\n",
              "      <th>founded_at</th>\n",
              "      <th>closed_at</th>\n",
              "      <th>first_funding_at</th>\n",
              "      <th>last_funding_at</th>\n",
              "      <th>age_first_funding_year</th>\n",
              "      <th>age_last_funding_year</th>\n",
              "      <th>age_first_milestone_year</th>\n",
              "      <th>age_last_milestone_year</th>\n",
              "      <th>relationships</th>\n",
              "      <th>funding_rounds</th>\n",
              "      <th>funding_total_usd</th>\n",
              "      <th>milestones</th>\n",
              "      <th>state_code.1</th>\n",
              "      <th>is_CA</th>\n",
              "      <th>is_NY</th>\n",
              "      <th>is_MA</th>\n",
              "      <th>is_TX</th>\n",
              "      <th>is_otherstate</th>\n",
              "      <th>category_code</th>\n",
              "      <th>is_software</th>\n",
              "      <th>is_web</th>\n",
              "      <th>is_mobile</th>\n",
              "      <th>is_enterprise</th>\n",
              "      <th>is_advertising</th>\n",
              "      <th>is_gamesvideo</th>\n",
              "      <th>is_ecommerce</th>\n",
              "      <th>is_biotech</th>\n",
              "      <th>is_consulting</th>\n",
              "      <th>is_othercategory</th>\n",
              "      <th>object_id</th>\n",
              "      <th>has_VC</th>\n",
              "      <th>has_angel</th>\n",
              "      <th>has_roundA</th>\n",
              "      <th>has_roundB</th>\n",
              "      <th>has_roundC</th>\n",
              "      <th>has_roundD</th>\n",
              "      <th>avg_participants</th>\n",
              "      <th>is_top500</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1005</td>\n",
              "      <td>CA</td>\n",
              "      <td>42.358880</td>\n",
              "      <td>-71.056820</td>\n",
              "      <td>92101</td>\n",
              "      <td>c:6669</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bandsintown</td>\n",
              "      <td>1</td>\n",
              "      <td>1/1/2007</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4/1/2009</td>\n",
              "      <td>1/1/2010</td>\n",
              "      <td>2.2493</td>\n",
              "      <td>3.0027</td>\n",
              "      <td>4.6685</td>\n",
              "      <td>6.7041</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>375000</td>\n",
              "      <td>3</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>music</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c:6669</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>acquired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>204</td>\n",
              "      <td>CA</td>\n",
              "      <td>37.238916</td>\n",
              "      <td>-121.973718</td>\n",
              "      <td>95032</td>\n",
              "      <td>c:16283</td>\n",
              "      <td>Los Gatos</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TriCipher</td>\n",
              "      <td>1</td>\n",
              "      <td>1/1/2000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2/14/2005</td>\n",
              "      <td>12/28/2009</td>\n",
              "      <td>5.1260</td>\n",
              "      <td>9.9973</td>\n",
              "      <td>7.0055</td>\n",
              "      <td>7.0055</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>40100000</td>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>enterprise</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>c:16283</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.7500</td>\n",
              "      <td>1</td>\n",
              "      <td>acquired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1001</td>\n",
              "      <td>CA</td>\n",
              "      <td>32.901049</td>\n",
              "      <td>-117.192656</td>\n",
              "      <td>92121</td>\n",
              "      <td>c:65620</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>San Diego CA 92121</td>\n",
              "      <td>Plixi</td>\n",
              "      <td>1</td>\n",
              "      <td>3/18/2009</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3/30/2010</td>\n",
              "      <td>3/30/2010</td>\n",
              "      <td>1.0329</td>\n",
              "      <td>1.0329</td>\n",
              "      <td>1.4575</td>\n",
              "      <td>2.2055</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2600000</td>\n",
              "      <td>2</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>web</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>c:65620</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>acquired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>738</td>\n",
              "      <td>CA</td>\n",
              "      <td>37.320309</td>\n",
              "      <td>-122.050040</td>\n",
              "      <td>95014</td>\n",
              "      <td>c:42668</td>\n",
              "      <td>Cupertino</td>\n",
              "      <td>Cupertino CA 95014</td>\n",
              "      <td>Solidcore Systems</td>\n",
              "      <td>1</td>\n",
              "      <td>1/1/2002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2/17/2005</td>\n",
              "      <td>4/25/2007</td>\n",
              "      <td>3.1315</td>\n",
              "      <td>5.3151</td>\n",
              "      <td>6.0027</td>\n",
              "      <td>6.0027</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>40000000</td>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>software</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>c:42668</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.3333</td>\n",
              "      <td>1</td>\n",
              "      <td>acquired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1002</td>\n",
              "      <td>CA</td>\n",
              "      <td>37.779281</td>\n",
              "      <td>-122.419236</td>\n",
              "      <td>94105</td>\n",
              "      <td>c:65806</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>San Francisco CA 94105</td>\n",
              "      <td>Inhale Digital</td>\n",
              "      <td>0</td>\n",
              "      <td>8/1/2010</td>\n",
              "      <td>10/1/2012</td>\n",
              "      <td>8/1/2010</td>\n",
              "      <td>4/1/2012</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.6685</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1300000</td>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>games_video</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>c:65806</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>closed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>352</td>\n",
              "      <td>CA</td>\n",
              "      <td>37.740594</td>\n",
              "      <td>-122.376471</td>\n",
              "      <td>94107</td>\n",
              "      <td>c:21343</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CoTweet</td>\n",
              "      <td>1</td>\n",
              "      <td>1/1/2009</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7/9/2009</td>\n",
              "      <td>7/9/2009</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>0.5808</td>\n",
              "      <td>4.5260</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1100000</td>\n",
              "      <td>2</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>advertising</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>c:21343</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>acquired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>721</td>\n",
              "      <td>MA</td>\n",
              "      <td>42.504817</td>\n",
              "      <td>-71.195611</td>\n",
              "      <td>1803</td>\n",
              "      <td>c:41747</td>\n",
              "      <td>Burlington</td>\n",
              "      <td>Burlington MA 1803</td>\n",
              "      <td>Reef Point Systems</td>\n",
              "      <td>0</td>\n",
              "      <td>1/1/1998</td>\n",
              "      <td>6/25/2008</td>\n",
              "      <td>4/1/2005</td>\n",
              "      <td>3/23/2007</td>\n",
              "      <td>7.2521</td>\n",
              "      <td>9.2274</td>\n",
              "      <td>6.0027</td>\n",
              "      <td>6.0027</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>52000000</td>\n",
              "      <td>1</td>\n",
              "      <td>MA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>security</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c:41747</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.6667</td>\n",
              "      <td>1</td>\n",
              "      <td>closed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>920</th>\n",
              "      <td>557</td>\n",
              "      <td>CA</td>\n",
              "      <td>37.408261</td>\n",
              "      <td>-122.015920</td>\n",
              "      <td>94089</td>\n",
              "      <td>c:31549</td>\n",
              "      <td>Sunnyvale</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Paracor Medical</td>\n",
              "      <td>0</td>\n",
              "      <td>1/1/1999</td>\n",
              "      <td>6/17/2012</td>\n",
              "      <td>6/29/2007</td>\n",
              "      <td>6/29/2007</td>\n",
              "      <td>8.4959</td>\n",
              "      <td>8.4959</td>\n",
              "      <td>9.0055</td>\n",
              "      <td>9.0055</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>44000000</td>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>biotech</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>c:31549</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>closed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>589</td>\n",
              "      <td>CA</td>\n",
              "      <td>37.556732</td>\n",
              "      <td>-122.288378</td>\n",
              "      <td>94404</td>\n",
              "      <td>c:33198</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Causata</td>\n",
              "      <td>1</td>\n",
              "      <td>1/1/2009</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10/5/2009</td>\n",
              "      <td>11/1/2011</td>\n",
              "      <td>0.7589</td>\n",
              "      <td>2.8329</td>\n",
              "      <td>0.7589</td>\n",
              "      <td>3.8356</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>15500000</td>\n",
              "      <td>2</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>software</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>c:33198</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>acquired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>922</th>\n",
              "      <td>462</td>\n",
              "      <td>CA</td>\n",
              "      <td>37.386778</td>\n",
              "      <td>-121.966277</td>\n",
              "      <td>95054</td>\n",
              "      <td>c:26702</td>\n",
              "      <td>Santa Clara</td>\n",
              "      <td>Santa Clara CA 95054</td>\n",
              "      <td>Asempra Technologies</td>\n",
              "      <td>1</td>\n",
              "      <td>1/1/2003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2/13/2006</td>\n",
              "      <td>2/13/2006</td>\n",
              "      <td>3.1205</td>\n",
              "      <td>3.1205</td>\n",
              "      <td>4.0027</td>\n",
              "      <td>4.0027</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>20000000</td>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>security</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c:26702</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>acquired</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>923 rows × 49 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70784616-d1a1-463e-b482-8a37eb4bf69d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70784616-d1a1-463e-b482-8a37eb4bf69d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70784616-d1a1-463e-b482-8a37eb4bf69d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8cfd6ede-1064-49ac-a2cb-1be6e9e8f9ed\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8cfd6ede-1064-49ac-a2cb-1be6e9e8f9ed')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8cfd6ede-1064-49ac-a2cb-1be6e9e8f9ed button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31wQBSAKMscF",
        "outputId": "b0b9e577-ac08-48b1-c5a3-0114eafb0c1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 923 entries, 0 to 922\n",
            "Data columns (total 49 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Unnamed: 0                923 non-null    int64  \n",
            " 1   state_code                923 non-null    object \n",
            " 2   latitude                  923 non-null    float64\n",
            " 3   longitude                 923 non-null    float64\n",
            " 4   zip_code                  923 non-null    object \n",
            " 5   id                        923 non-null    object \n",
            " 6   city                      923 non-null    object \n",
            " 7   Unnamed: 6                430 non-null    object \n",
            " 8   name                      923 non-null    object \n",
            " 9   labels                    923 non-null    int64  \n",
            " 10  founded_at                923 non-null    object \n",
            " 11  closed_at                 335 non-null    object \n",
            " 12  first_funding_at          923 non-null    object \n",
            " 13  last_funding_at           923 non-null    object \n",
            " 14  age_first_funding_year    923 non-null    float64\n",
            " 15  age_last_funding_year     923 non-null    float64\n",
            " 16  age_first_milestone_year  771 non-null    float64\n",
            " 17  age_last_milestone_year   771 non-null    float64\n",
            " 18  relationships             923 non-null    int64  \n",
            " 19  funding_rounds            923 non-null    int64  \n",
            " 20  funding_total_usd         923 non-null    int64  \n",
            " 21  milestones                923 non-null    int64  \n",
            " 22  state_code.1              922 non-null    object \n",
            " 23  is_CA                     923 non-null    int64  \n",
            " 24  is_NY                     923 non-null    int64  \n",
            " 25  is_MA                     923 non-null    int64  \n",
            " 26  is_TX                     923 non-null    int64  \n",
            " 27  is_otherstate             923 non-null    int64  \n",
            " 28  category_code             923 non-null    object \n",
            " 29  is_software               923 non-null    int64  \n",
            " 30  is_web                    923 non-null    int64  \n",
            " 31  is_mobile                 923 non-null    int64  \n",
            " 32  is_enterprise             923 non-null    int64  \n",
            " 33  is_advertising            923 non-null    int64  \n",
            " 34  is_gamesvideo             923 non-null    int64  \n",
            " 35  is_ecommerce              923 non-null    int64  \n",
            " 36  is_biotech                923 non-null    int64  \n",
            " 37  is_consulting             923 non-null    int64  \n",
            " 38  is_othercategory          923 non-null    int64  \n",
            " 39  object_id                 923 non-null    object \n",
            " 40  has_VC                    923 non-null    int64  \n",
            " 41  has_angel                 923 non-null    int64  \n",
            " 42  has_roundA                923 non-null    int64  \n",
            " 43  has_roundB                923 non-null    int64  \n",
            " 44  has_roundC                923 non-null    int64  \n",
            " 45  has_roundD                923 non-null    int64  \n",
            " 46  avg_participants          923 non-null    float64\n",
            " 47  is_top500                 923 non-null    int64  \n",
            " 48  status                    923 non-null    object \n",
            "dtypes: float64(7), int64(28), object(14)\n",
            "memory usage: 353.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "YI4HIN5iBN7w",
        "outputId": "7d206b27-9ab8-4883-b9a6-2da666648300"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0    latitude   longitude      labels  \\\n",
              "count   923.000000  923.000000  923.000000  923.000000   \n",
              "mean    572.297941   38.517442 -103.539212    0.646804   \n",
              "std     333.585431    3.741497   22.394167    0.478222   \n",
              "min       1.000000   25.752358 -122.756956    0.000000   \n",
              "25%     283.500000   37.388869 -122.198732    0.000000   \n",
              "50%     577.000000   37.779281 -118.374037    1.000000   \n",
              "75%     866.500000   40.730646  -77.214731    1.000000   \n",
              "max    1153.000000   59.335232   18.057121    1.000000   \n",
              "\n",
              "       age_first_funding_year  age_last_funding_year  \\\n",
              "count              923.000000             923.000000   \n",
              "mean                 2.235630               3.931456   \n",
              "std                  2.510449               2.967910   \n",
              "min                 -9.046600              -9.046600   \n",
              "25%                  0.576700               1.669850   \n",
              "50%                  1.446600               3.528800   \n",
              "75%                  3.575350               5.560250   \n",
              "max                 21.895900              21.895900   \n",
              "\n",
              "       age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
              "count                771.000000               771.000000     923.000000   \n",
              "mean                   3.055353                 4.754423       7.710726   \n",
              "std                    2.977057                 3.212107       7.265776   \n",
              "min                  -14.169900                -7.005500       0.000000   \n",
              "25%                    1.000000                 2.411000       3.000000   \n",
              "50%                    2.520500                 4.476700       5.000000   \n",
              "75%                    4.686300                 6.753400      10.000000   \n",
              "max                   24.684900                24.684900      63.000000   \n",
              "\n",
              "       funding_rounds  funding_total_usd  milestones       is_CA       is_NY  \\\n",
              "count      923.000000       9.230000e+02  923.000000  923.000000  923.000000   \n",
              "mean         2.310943       2.541975e+07    1.841820    0.527627    0.114843   \n",
              "std          1.390922       1.896344e+08    1.322632    0.499507    0.319005   \n",
              "min          1.000000       1.100000e+04    0.000000    0.000000    0.000000   \n",
              "25%          1.000000       2.725000e+06    1.000000    0.000000    0.000000   \n",
              "50%          2.000000       1.000000e+07    2.000000    1.000000    0.000000   \n",
              "75%          3.000000       2.472500e+07    3.000000    1.000000    0.000000   \n",
              "max         10.000000       5.700000e+09    8.000000    1.000000    1.000000   \n",
              "\n",
              "            is_MA       is_TX  is_otherstate  is_software      is_web  \\\n",
              "count  923.000000  923.000000     923.000000   923.000000  923.000000   \n",
              "mean     0.089924    0.045504       0.221018     0.165764    0.156013   \n",
              "std      0.286228    0.208519       0.415158     0.372070    0.363064   \n",
              "min      0.000000    0.000000       0.000000     0.000000    0.000000   \n",
              "25%      0.000000    0.000000       0.000000     0.000000    0.000000   \n",
              "50%      0.000000    0.000000       0.000000     0.000000    0.000000   \n",
              "75%      0.000000    0.000000       0.000000     0.000000    0.000000   \n",
              "max      1.000000    1.000000       1.000000     1.000000    1.000000   \n",
              "\n",
              "       is_mobile  is_enterprise  is_advertising  is_gamesvideo  is_ecommerce  \\\n",
              "count  923.00000     923.000000      923.000000     923.000000    923.000000   \n",
              "mean     0.08559       0.079090        0.067172       0.056338      0.027086   \n",
              "std      0.27991       0.270025        0.250456       0.230698      0.162421   \n",
              "min      0.00000       0.000000        0.000000       0.000000      0.000000   \n",
              "25%      0.00000       0.000000        0.000000       0.000000      0.000000   \n",
              "50%      0.00000       0.000000        0.000000       0.000000      0.000000   \n",
              "75%      0.00000       0.000000        0.000000       0.000000      0.000000   \n",
              "max      1.00000       1.000000        1.000000       1.000000      1.000000   \n",
              "\n",
              "       is_biotech  is_consulting  is_othercategory      has_VC   has_angel  \\\n",
              "count  923.000000     923.000000        923.000000  923.000000  923.000000   \n",
              "mean     0.036836       0.003250          0.322860    0.326111    0.254605   \n",
              "std      0.188462       0.056949          0.467823    0.469042    0.435875   \n",
              "min      0.000000       0.000000          0.000000    0.000000    0.000000   \n",
              "25%      0.000000       0.000000          0.000000    0.000000    0.000000   \n",
              "50%      0.000000       0.000000          0.000000    0.000000    0.000000   \n",
              "75%      0.000000       0.000000          1.000000    1.000000    1.000000   \n",
              "max      1.000000       1.000000          1.000000    1.000000    1.000000   \n",
              "\n",
              "       has_roundA  has_roundB  has_roundC  has_roundD  avg_participants  \\\n",
              "count  923.000000  923.000000  923.000000  923.000000        923.000000   \n",
              "mean     0.508126    0.392199    0.232936    0.099675          2.838586   \n",
              "std      0.500205    0.488505    0.422931    0.299729          1.874601   \n",
              "min      0.000000    0.000000    0.000000    0.000000          1.000000   \n",
              "25%      0.000000    0.000000    0.000000    0.000000          1.500000   \n",
              "50%      1.000000    0.000000    0.000000    0.000000          2.500000   \n",
              "75%      1.000000    1.000000    0.000000    0.000000          3.800000   \n",
              "max      1.000000    1.000000    1.000000    1.000000         16.000000   \n",
              "\n",
              "        is_top500  \n",
              "count  923.000000  \n",
              "mean     0.809317  \n",
              "std      0.393052  \n",
              "min      0.000000  \n",
              "25%      1.000000  \n",
              "50%      1.000000  \n",
              "75%      1.000000  \n",
              "max      1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2376e4fc-e0f5-43c9-8d63-98ca111a4100\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>labels</th>\n",
              "      <th>age_first_funding_year</th>\n",
              "      <th>age_last_funding_year</th>\n",
              "      <th>age_first_milestone_year</th>\n",
              "      <th>age_last_milestone_year</th>\n",
              "      <th>relationships</th>\n",
              "      <th>funding_rounds</th>\n",
              "      <th>funding_total_usd</th>\n",
              "      <th>milestones</th>\n",
              "      <th>is_CA</th>\n",
              "      <th>is_NY</th>\n",
              "      <th>is_MA</th>\n",
              "      <th>is_TX</th>\n",
              "      <th>is_otherstate</th>\n",
              "      <th>is_software</th>\n",
              "      <th>is_web</th>\n",
              "      <th>is_mobile</th>\n",
              "      <th>is_enterprise</th>\n",
              "      <th>is_advertising</th>\n",
              "      <th>is_gamesvideo</th>\n",
              "      <th>is_ecommerce</th>\n",
              "      <th>is_biotech</th>\n",
              "      <th>is_consulting</th>\n",
              "      <th>is_othercategory</th>\n",
              "      <th>has_VC</th>\n",
              "      <th>has_angel</th>\n",
              "      <th>has_roundA</th>\n",
              "      <th>has_roundB</th>\n",
              "      <th>has_roundC</th>\n",
              "      <th>has_roundD</th>\n",
              "      <th>avg_participants</th>\n",
              "      <th>is_top500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>771.000000</td>\n",
              "      <td>771.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>9.230000e+02</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.00000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "      <td>923.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>572.297941</td>\n",
              "      <td>38.517442</td>\n",
              "      <td>-103.539212</td>\n",
              "      <td>0.646804</td>\n",
              "      <td>2.235630</td>\n",
              "      <td>3.931456</td>\n",
              "      <td>3.055353</td>\n",
              "      <td>4.754423</td>\n",
              "      <td>7.710726</td>\n",
              "      <td>2.310943</td>\n",
              "      <td>2.541975e+07</td>\n",
              "      <td>1.841820</td>\n",
              "      <td>0.527627</td>\n",
              "      <td>0.114843</td>\n",
              "      <td>0.089924</td>\n",
              "      <td>0.045504</td>\n",
              "      <td>0.221018</td>\n",
              "      <td>0.165764</td>\n",
              "      <td>0.156013</td>\n",
              "      <td>0.08559</td>\n",
              "      <td>0.079090</td>\n",
              "      <td>0.067172</td>\n",
              "      <td>0.056338</td>\n",
              "      <td>0.027086</td>\n",
              "      <td>0.036836</td>\n",
              "      <td>0.003250</td>\n",
              "      <td>0.322860</td>\n",
              "      <td>0.326111</td>\n",
              "      <td>0.254605</td>\n",
              "      <td>0.508126</td>\n",
              "      <td>0.392199</td>\n",
              "      <td>0.232936</td>\n",
              "      <td>0.099675</td>\n",
              "      <td>2.838586</td>\n",
              "      <td>0.809317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>333.585431</td>\n",
              "      <td>3.741497</td>\n",
              "      <td>22.394167</td>\n",
              "      <td>0.478222</td>\n",
              "      <td>2.510449</td>\n",
              "      <td>2.967910</td>\n",
              "      <td>2.977057</td>\n",
              "      <td>3.212107</td>\n",
              "      <td>7.265776</td>\n",
              "      <td>1.390922</td>\n",
              "      <td>1.896344e+08</td>\n",
              "      <td>1.322632</td>\n",
              "      <td>0.499507</td>\n",
              "      <td>0.319005</td>\n",
              "      <td>0.286228</td>\n",
              "      <td>0.208519</td>\n",
              "      <td>0.415158</td>\n",
              "      <td>0.372070</td>\n",
              "      <td>0.363064</td>\n",
              "      <td>0.27991</td>\n",
              "      <td>0.270025</td>\n",
              "      <td>0.250456</td>\n",
              "      <td>0.230698</td>\n",
              "      <td>0.162421</td>\n",
              "      <td>0.188462</td>\n",
              "      <td>0.056949</td>\n",
              "      <td>0.467823</td>\n",
              "      <td>0.469042</td>\n",
              "      <td>0.435875</td>\n",
              "      <td>0.500205</td>\n",
              "      <td>0.488505</td>\n",
              "      <td>0.422931</td>\n",
              "      <td>0.299729</td>\n",
              "      <td>1.874601</td>\n",
              "      <td>0.393052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.752358</td>\n",
              "      <td>-122.756956</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-9.046600</td>\n",
              "      <td>-9.046600</td>\n",
              "      <td>-14.169900</td>\n",
              "      <td>-7.005500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.100000e+04</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>283.500000</td>\n",
              "      <td>37.388869</td>\n",
              "      <td>-122.198732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.576700</td>\n",
              "      <td>1.669850</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.411000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.725000e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>577.000000</td>\n",
              "      <td>37.779281</td>\n",
              "      <td>-118.374037</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.446600</td>\n",
              "      <td>3.528800</td>\n",
              "      <td>2.520500</td>\n",
              "      <td>4.476700</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000e+07</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>866.500000</td>\n",
              "      <td>40.730646</td>\n",
              "      <td>-77.214731</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.575350</td>\n",
              "      <td>5.560250</td>\n",
              "      <td>4.686300</td>\n",
              "      <td>6.753400</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.472500e+07</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1153.000000</td>\n",
              "      <td>59.335232</td>\n",
              "      <td>18.057121</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>21.895900</td>\n",
              "      <td>21.895900</td>\n",
              "      <td>24.684900</td>\n",
              "      <td>24.684900</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.700000e+09</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2376e4fc-e0f5-43c9-8d63-98ca111a4100')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2376e4fc-e0f5-43c9-8d63-98ca111a4100 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2376e4fc-e0f5-43c9-8d63-98ca111a4100');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-764a7871-f8ed-4d83-8562-4545ae9fef11\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-764a7871-f8ed-4d83-8562-4545ae9fef11')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-764a7871-f8ed-4d83-8562-4545ae9fef11 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling missing values"
      ],
      "metadata": {
        "id": "F99dFrRVNG5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bjYlX3BBnYK",
        "outputId": "ee9ebe11-07a6-4507-e7c4-ba033bd40872"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                    0\n",
              "state_code                    0\n",
              "latitude                      0\n",
              "longitude                     0\n",
              "zip_code                      0\n",
              "id                            0\n",
              "city                          0\n",
              "Unnamed: 6                  493\n",
              "name                          0\n",
              "labels                        0\n",
              "founded_at                    0\n",
              "closed_at                   588\n",
              "first_funding_at              0\n",
              "last_funding_at               0\n",
              "age_first_funding_year        0\n",
              "age_last_funding_year         0\n",
              "age_first_milestone_year    152\n",
              "age_last_milestone_year     152\n",
              "relationships                 0\n",
              "funding_rounds                0\n",
              "funding_total_usd             0\n",
              "milestones                    0\n",
              "state_code.1                  1\n",
              "is_CA                         0\n",
              "is_NY                         0\n",
              "is_MA                         0\n",
              "is_TX                         0\n",
              "is_otherstate                 0\n",
              "category_code                 0\n",
              "is_software                   0\n",
              "is_web                        0\n",
              "is_mobile                     0\n",
              "is_enterprise                 0\n",
              "is_advertising                0\n",
              "is_gamesvideo                 0\n",
              "is_ecommerce                  0\n",
              "is_biotech                    0\n",
              "is_consulting                 0\n",
              "is_othercategory              0\n",
              "object_id                     0\n",
              "has_VC                        0\n",
              "has_angel                     0\n",
              "has_roundA                    0\n",
              "has_roundB                    0\n",
              "has_roundC                    0\n",
              "has_roundD                    0\n",
              "avg_participants              0\n",
              "is_top500                     0\n",
              "status                        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns:\n",
        "    if df[i].isnull().any():\n",
        "        nullperc = df[i].isnull().sum()/df.shape[0] * 100\n",
        "        print(f'null percentage of {i} is {round(nullperc,ndigits=3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OakYvdFdCIlp",
        "outputId": "0d691b0a-da9c-4a66-b1a1-8ec8f74f74e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "null percentage of Unnamed: 6 is 53.413\n",
            "null percentage of closed_at is 63.705\n",
            "null percentage of age_first_milestone_year is 16.468\n",
            "null percentage of age_last_milestone_year is 16.468\n",
            "null percentage of state_code.1 is 0.108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropping useless columns"
      ],
      "metadata": {
        "id": "XosSVrU_NMKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 6','state_code.1','zip_code','id','Unnamed: 0','object_id','state_code'],axis = 1,inplace = True)"
      ],
      "metadata": {
        "id": "F0hvFLYCCqWg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropping non-logical columns"
      ],
      "metadata": {
        "id": "Vruq7qg8NZs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[(pd.to_datetime(df['closed_at']) - pd.to_datetime(df['founded_at'])<'0')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "C4pQOea_Lx1X",
        "outputId": "570ba6cb-f7e9-47cf-9895-13ddaa948772"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      latitude   longitude           city       name  labels founded_at  \\\n",
              "73   37.779026 -122.401840  San Francisco    adBrite       1   1/1/2003   \n",
              "88   37.388869 -122.072353  Mountain View        Yub       0   1/1/2013   \n",
              "558  40.743662  -73.984268       New York  Advaliant       0  4/16/2013   \n",
              "\n",
              "    closed_at first_funding_at last_funding_at  age_first_funding_year  \\\n",
              "73   2/1/2001         9/1/2004        5/1/2012                  1.6685   \n",
              "88   1/1/2005       11/19/2013      11/19/2013                  0.8822   \n",
              "558  5/4/2009         4/1/2004        4/1/2004                 -9.0466   \n",
              "\n",
              "     age_last_funding_year  age_first_milestone_year  age_last_milestone_year  \\\n",
              "73                  9.3370                    7.3808                  10.4740   \n",
              "88                  0.8822                       NaN                      NaN   \n",
              "558                -9.0466                   -6.0466                  -3.8822   \n",
              "\n",
              "     relationships  funding_rounds  funding_total_usd  milestones  is_CA  \\\n",
              "73              17               4           40400000           3      1   \n",
              "88               7               1           12000000           0      1   \n",
              "558              6               1             100000           2      0   \n",
              "\n",
              "     is_NY  is_MA  is_TX  is_otherstate category_code  is_software  is_web  \\\n",
              "73       0      0      0              0   advertising            0       0   \n",
              "88       0      0      0              0     ecommerce            0       0   \n",
              "558      1      0      0              0   advertising            0       0   \n",
              "\n",
              "     is_mobile  is_enterprise  is_advertising  is_gamesvideo  is_ecommerce  \\\n",
              "73           0              0               1              0             0   \n",
              "88           0              0               0              0             1   \n",
              "558          0              0               1              0             0   \n",
              "\n",
              "     is_biotech  is_consulting  is_othercategory  has_VC  has_angel  \\\n",
              "73            0              0                 0       0          0   \n",
              "88            0              0                 0       1          0   \n",
              "558           0              0                 0       0          1   \n",
              "\n",
              "     has_roundA  has_roundB  has_roundC  has_roundD  avg_participants  \\\n",
              "73            1           1           1           1            1.6667   \n",
              "88            0           0           0           0            9.0000   \n",
              "558           0           0           0           0            1.0000   \n",
              "\n",
              "     is_top500    status  \n",
              "73           1  acquired  \n",
              "88           1    closed  \n",
              "558          0    closed  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04cf933f-b521-42b0-8e46-760787de2a13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>city</th>\n",
              "      <th>name</th>\n",
              "      <th>labels</th>\n",
              "      <th>founded_at</th>\n",
              "      <th>closed_at</th>\n",
              "      <th>first_funding_at</th>\n",
              "      <th>last_funding_at</th>\n",
              "      <th>age_first_funding_year</th>\n",
              "      <th>age_last_funding_year</th>\n",
              "      <th>age_first_milestone_year</th>\n",
              "      <th>age_last_milestone_year</th>\n",
              "      <th>relationships</th>\n",
              "      <th>funding_rounds</th>\n",
              "      <th>funding_total_usd</th>\n",
              "      <th>milestones</th>\n",
              "      <th>is_CA</th>\n",
              "      <th>is_NY</th>\n",
              "      <th>is_MA</th>\n",
              "      <th>is_TX</th>\n",
              "      <th>is_otherstate</th>\n",
              "      <th>category_code</th>\n",
              "      <th>is_software</th>\n",
              "      <th>is_web</th>\n",
              "      <th>is_mobile</th>\n",
              "      <th>is_enterprise</th>\n",
              "      <th>is_advertising</th>\n",
              "      <th>is_gamesvideo</th>\n",
              "      <th>is_ecommerce</th>\n",
              "      <th>is_biotech</th>\n",
              "      <th>is_consulting</th>\n",
              "      <th>is_othercategory</th>\n",
              "      <th>has_VC</th>\n",
              "      <th>has_angel</th>\n",
              "      <th>has_roundA</th>\n",
              "      <th>has_roundB</th>\n",
              "      <th>has_roundC</th>\n",
              "      <th>has_roundD</th>\n",
              "      <th>avg_participants</th>\n",
              "      <th>is_top500</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>37.779026</td>\n",
              "      <td>-122.401840</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>adBrite</td>\n",
              "      <td>1</td>\n",
              "      <td>1/1/2003</td>\n",
              "      <td>2/1/2001</td>\n",
              "      <td>9/1/2004</td>\n",
              "      <td>5/1/2012</td>\n",
              "      <td>1.6685</td>\n",
              "      <td>9.3370</td>\n",
              "      <td>7.3808</td>\n",
              "      <td>10.4740</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>40400000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>advertising</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.6667</td>\n",
              "      <td>1</td>\n",
              "      <td>acquired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>37.388869</td>\n",
              "      <td>-122.072353</td>\n",
              "      <td>Mountain View</td>\n",
              "      <td>Yub</td>\n",
              "      <td>0</td>\n",
              "      <td>1/1/2013</td>\n",
              "      <td>1/1/2005</td>\n",
              "      <td>11/19/2013</td>\n",
              "      <td>11/19/2013</td>\n",
              "      <td>0.8822</td>\n",
              "      <td>0.8822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>12000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ecommerce</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>closed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>40.743662</td>\n",
              "      <td>-73.984268</td>\n",
              "      <td>New York</td>\n",
              "      <td>Advaliant</td>\n",
              "      <td>0</td>\n",
              "      <td>4/16/2013</td>\n",
              "      <td>5/4/2009</td>\n",
              "      <td>4/1/2004</td>\n",
              "      <td>4/1/2004</td>\n",
              "      <td>-9.0466</td>\n",
              "      <td>-9.0466</td>\n",
              "      <td>-6.0466</td>\n",
              "      <td>-3.8822</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>100000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>advertising</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>closed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04cf933f-b521-42b0-8e46-760787de2a13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04cf933f-b521-42b0-8e46-760787de2a13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04cf933f-b521-42b0-8e46-760787de2a13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-640ce295-0d2d-4a6b-9150-f34ed95517b4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-640ce295-0d2d-4a6b-9150-f34ed95517b4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-640ce295-0d2d-4a6b-9150-f34ed95517b4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df[(pd.to_datetime(df['closed_at']) - pd.to_datetime(df['founded_at'])<'0')].index,inplace = True)"
      ],
      "metadata": {
        "id": "oPUomccXKPsG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fill missing values"
      ],
      "metadata": {
        "id": "g4vor_uzNtBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['closed_at'] = pd.to_datetime(df['closed_at'])\n",
        "df['closed_at'] = (pd.to_datetime('1-1-2024') - df['closed_at']).fillna('0')"
      ],
      "metadata": {
        "id": "-3eO9r5VENXj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = ['age_first_milestone_year','age_last_milestone_year']\n",
        "df[lst] = df[lst].fillna(0)"
      ],
      "metadata": {
        "id": "10PrgjRdFBSd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### change columns datatypes"
      ],
      "metadata": {
        "id": "vfq5O466OJ65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst = ['founded_at','first_funding_at','last_funding_at']\n",
        "df['founded_at'] = pd.to_datetime(df['founded_at'])\n",
        "df['first_funding_at'] = pd.to_datetime(df['first_funding_at'])\n",
        "df['last_funding_at'] = pd.to_datetime(df['last_funding_at'])"
      ],
      "metadata": {
        "id": "hNxNhzNaFvRt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x = 'status', data = df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Cr2mrOIfVY4O",
        "outputId": "e8adb8c8-8ff4-4ff1-fe03-4eba252b95ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='status', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "MLHts32_VVE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yMtilqfi5yj",
        "outputId": "25a043bb-96b6-409d-eae0-0b9bc740e7e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.15.11-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=e398c87c5694fc274d5cc131cdba201ec722f8d130373c93ce007251fb5e112f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.37 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.31.0 setproctitle-1.3.2 smmap-5.0.1 wandb-0.15.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "2PMG1cFMkHNO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABvDxkCCjf9B",
        "outputId": "2ea820e2-4198-4a4e-cfc7-eb4af04fbd78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.regularizers import L1,L2\n",
        "import tensorflow as tf\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "wgXTqxOAGaC7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = (df.dtypes == 'object')\n",
        "cat_col = list(s[s].index)\n",
        "cat_col"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcII75ykPGEk",
        "outputId": "4d9b0615-cdbb-4e9d-e45a-8666372a7b93"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['city', 'name', 'category_code', 'status']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in cat_col:\n",
        "  lb = LabelEncoder()\n",
        "  df[i] = lb.fit_transform(df[i])"
      ],
      "metadata": {
        "id": "p69ykbpkR8kS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = df.drop(['status','founded_at','first_funding_at','last_funding_at','closed_at','name','city'],axis = 1), df['status']\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size= 0.25,random_state = 42)"
      ],
      "metadata": {
        "id": "bFwg3T_8SSzU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = 'Startups',name = 'first_trail')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "c97d6be6e4094345877a14460c27b031",
            "4ba5e9fd4b4649ed9b267caf7b2feba8",
            "95821f4925984ad8a5cf0d9d67fdd80a",
            "801fa3d946784e57acdff5bcba29174c",
            "edde8fe012214d488fbef7df1bfb9c35",
            "6dae511030c942f883453eb57db72160",
            "437b8cce77d94cb69bff455c0ed8c264",
            "a9b7e508bc824a47b4e11752d12478c3"
          ]
        },
        "id": "xCOusbLmkr_l",
        "outputId": "292cfd6f-5102-49d5-9ca3-08da02741b35"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:sadt98gk) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='141.245 MB of 141.245 MB uploaded (0.342 MB deduped)\\r'), FloatProgress(value=1.0,…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c97d6be6e4094345877a14460c27b031"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>binary_accuracy</td><td>▆▆▇█▆▆█▆▂▄▃▃▅█▃▃▂▆▄▃▃▆▇▁█▅▄▆▅▄▆▂▃▇▆▆▇▇▃▆</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>false_negatives_2</td><td>▁▆██▄▇█▇▆▆▄▇▄▆▆▃▅▆▇▂▅▇▆▃▆▅▇▆▄▆▇▂▆██▇▃▅▄▃</td></tr><tr><td>loss</td><td>▂▃█▆▅▅▅█▇▅▆▅▅▄▂▁▂▂▄▂▄▄▅▅▁▂▂▁▁▄▃▆▃▃▇▆▄█▇▆</td></tr><tr><td>val_binary_accuracy</td><td>█▁████████▁█████▁▁██████▁█▁▁██▁█████▂█▁▁</td></tr><tr><td>val_false_negatives_2</td><td>█▁████████▁█████▁▁██████▁█▁▁██▁█████▁█▁▁</td></tr><tr><td>val_loss</td><td>▂▃▇▆▆▅▄██▅▇▄▅▄▂▁▂▂▃▂▅▄▄▅▁▂▂▁▂▄▄▅▃▃▆▆▅▇▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>658</td></tr><tr><td>best_val_loss</td><td>5.59997</td></tr><tr><td>binary_accuracy</td><td>0.64203</td></tr><tr><td>epoch</td><td>999</td></tr><tr><td>false_negatives_2</td><td>229.0</td></tr><tr><td>loss</td><td>22.38039</td></tr><tr><td>val_binary_accuracy</td><td>0.65652</td></tr><tr><td>val_false_negatives_2</td><td>79.0</td></tr><tr><td>val_loss</td><td>21.48089</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Fifth Trail</strong> at: <a href='https://wandb.ai/ossm0394/Startups/runs/sadt98gk' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/sadt98gk</a><br/>Synced 5 W&B file(s), 1 media file(s), 65 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231002_123945-sadt98gk/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:sadt98gk). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231002_130608-ff4koyvd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ossm0394/Startups/runs/ff4koyvd' target=\"_blank\">first_trail</a></strong> to <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">https://wandb.ai/ossm0394/Startups</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ossm0394/Startups/runs/ff4koyvd' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/ff4koyvd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ossm0394/Startups/runs/ff4koyvd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c9ddc1f7e80>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "J40cGvNPS5qx"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(units=35,activation='relu',kernel_initializer='GlorotNormal'))\n",
        "\n",
        "model.add(Dense(units=500,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(units=300,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(units=200,activation='relu',kernel_initializer='GlorotNormal'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "JRPYY4x1S7Qc"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
        "              tf.keras.metrics.FalseNegatives()])"
      ],
      "metadata": {
        "id": "Wjxtz0SPVDmO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = x_train,y = y_train,epochs = 700,validation_data = (x_test,y_test),callbacks = [WandbCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnlKG8YNWg2h",
        "outputId": "a6955b65-c3c1-49bb-a612-feb37b667320"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.8418 - binary_accuracy: 0.5595 - false_negatives_3: 112.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 149ms/step - loss: 0.8491 - binary_accuracy: 0.5565 - false_negatives_3: 115.0000 - val_loss: 0.7090 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 2/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7224 - binary_accuracy: 0.6062 - false_negatives_3: 122.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 143ms/step - loss: 0.7277 - binary_accuracy: 0.6087 - false_negatives_3: 131.0000 - val_loss: 0.6972 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 3/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.7074 - binary_accuracy: 0.6265 - false_negatives_3: 150.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 167ms/step - loss: 0.7079 - binary_accuracy: 0.6290 - false_negatives_3: 153.0000 - val_loss: 0.6806 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 4/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6692 - binary_accuracy: 0.6760 - false_negatives_3: 128.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 125ms/step - loss: 0.6694 - binary_accuracy: 0.6739 - false_negatives_3: 148.0000 - val_loss: 0.6696 - val_binary_accuracy: 0.6609 - val_false_negatives_3: 78.0000\n",
            "Epoch 5/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.7012 - binary_accuracy: 0.6414 - false_negatives_3: 139.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 186ms/step - loss: 0.7004 - binary_accuracy: 0.6391 - false_negatives_3: 157.0000 - val_loss: 0.6695 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 6/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6758 - binary_accuracy: 0.6333 - false_negatives_3: 158.0000 - val_loss: 0.6873 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 7/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6943 - binary_accuracy: 0.6422 - false_negatives_3: 151.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 124ms/step - loss: 0.6978 - binary_accuracy: 0.6391 - false_negatives_3: 165.0000 - val_loss: 0.6632 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 8/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6645 - binary_accuracy: 0.6449 - false_negatives_3: 170.0000 - val_loss: 0.7044 - val_binary_accuracy: 0.6609 - val_false_negatives_3: 78.0000\n",
            "Epoch 9/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6660 - binary_accuracy: 0.6464 - false_negatives_3: 153.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 201ms/step - loss: 0.6660 - binary_accuracy: 0.6464 - false_negatives_3: 153.0000 - val_loss: 0.6575 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 10/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6595 - binary_accuracy: 0.6522 - false_negatives_3: 170.0000 - val_loss: 911.2480 - val_binary_accuracy: 0.3261 - val_false_negatives_3: 4.0000\n",
            "Epoch 11/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6674 - binary_accuracy: 0.6435 - false_negatives_3: 157.0000 - val_loss: 0.6712 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 12/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6803 - binary_accuracy: 0.6406 - false_negatives_3: 166.0000 - val_loss: 0.6627 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 13/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6755 - binary_accuracy: 0.6246 - false_negatives_3: 174.0000 - val_loss: 0.6736 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 14/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6428 - binary_accuracy: 0.6580 - false_negatives_3: 160.0000 - val_loss: 0.6833 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 15/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6456 - binary_accuracy: 0.6609 - false_negatives_3: 151.0000 - val_loss: 0.6704 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 16/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6448 - binary_accuracy: 0.6551 - false_negatives_3: 165.0000 - val_loss: 0.6815 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 17/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6407 - binary_accuracy: 0.6377 - false_negatives_3: 164.0000 - val_loss: 0.7029 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 18/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6591 - binary_accuracy: 0.6507 - false_negatives_3: 162.0000 - val_loss: 0.6760 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 19/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6344 - binary_accuracy: 0.6594 - false_negatives_3: 169.0000 - val_loss: 0.6977 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 20/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6382 - binary_accuracy: 0.6594 - false_negatives_3: 165.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 21/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6544 - binary_accuracy: 0.6638 - false_negatives_3: 152.0000 - val_loss: 0.7020 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 22/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6490 - binary_accuracy: 0.6464 - false_negatives_3: 173.0000 - val_loss: 0.6892 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 23/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6420 - binary_accuracy: 0.6652 - false_negatives_3: 160.0000 - val_loss: 0.6912 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 24/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6337 - binary_accuracy: 0.6623 - false_negatives_3: 173.0000 - val_loss: 0.6968 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 25/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6445 - binary_accuracy: 0.6667 - false_negatives_3: 149.0000 - val_loss: 0.6697 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 26/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6422 - binary_accuracy: 0.6420 - false_negatives_3: 177.0000 - val_loss: 0.7047 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 27/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6305 - binary_accuracy: 0.6594 - false_negatives_3: 158.0000 - val_loss: 0.6655 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 28/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6521 - binary_accuracy: 0.6449 - false_negatives_3: 185.0000 - val_loss: 0.6900 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 29/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6210 - binary_accuracy: 0.6725 - false_negatives_3: 150.0000 - val_loss: 0.7095 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 30/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6510 - binary_accuracy: 0.6435 - false_negatives_3: 168.0000 - val_loss: 0.6943 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 31/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6289 - binary_accuracy: 0.6667 - false_negatives_3: 161.0000 - val_loss: 0.6664 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 32/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6333 - binary_accuracy: 0.6696 - false_negatives_3: 163.0000 - val_loss: 0.6879 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 33/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6306 - binary_accuracy: 0.6536 - false_negatives_3: 171.0000 - val_loss: 0.6798 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 34/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6323 - binary_accuracy: 0.6681 - false_negatives_3: 163.0000 - val_loss: 0.6661 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 35/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6275 - binary_accuracy: 0.6725 - false_negatives_3: 163.0000 - val_loss: 0.6810 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 36/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6306 - binary_accuracy: 0.6565 - false_negatives_3: 152.0000 - val_loss: 0.6644 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 37/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6311 - binary_accuracy: 0.6565 - false_negatives_3: 177.0000 - val_loss: 0.6670 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 38/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6338 - binary_accuracy: 0.6638 - false_negatives_3: 172.0000 - val_loss: 0.6816 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 39/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6294 - binary_accuracy: 0.6710 - false_negatives_3: 155.0000 - val_loss: 0.6998 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 40/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6319 - binary_accuracy: 0.6783 - false_negatives_3: 165.0000 - val_loss: 0.6606 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 41/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6231 - binary_accuracy: 0.6739 - false_negatives_3: 166.0000 - val_loss: 0.6888 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 42/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6300 - binary_accuracy: 0.6681 - false_negatives_3: 156.0000 - val_loss: 0.6611 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 43/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6266 - binary_accuracy: 0.6638 - false_negatives_3: 173.0000 - val_loss: 0.6720 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 44/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6327 - binary_accuracy: 0.6739 - false_negatives_3: 156.0000 - val_loss: 0.6711 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 45/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6228 - binary_accuracy: 0.6783 - false_negatives_3: 151.0000 - val_loss: 0.6743 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 46/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6204 - binary_accuracy: 0.6652 - false_negatives_3: 160.0000 - val_loss: 0.6713 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 47/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6342 - binary_accuracy: 0.6522 - false_negatives_3: 165.0000 - val_loss: 0.6731 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 48/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6278 - binary_accuracy: 0.6565 - false_negatives_3: 153.0000 - val_loss: 0.6914 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 49/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6370 - binary_accuracy: 0.6391 - false_negatives_3: 172.0000 - val_loss: 0.6914 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 50/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6312 - binary_accuracy: 0.6522 - false_negatives_3: 171.0000 - val_loss: 0.6727 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 51/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6302 - binary_accuracy: 0.6696 - false_negatives_3: 154.0000 - val_loss: 0.6622 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 52/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6176 - binary_accuracy: 0.6594 - false_negatives_3: 163.0000 - val_loss: 0.6998 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 53/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6208 - binary_accuracy: 0.6710 - false_negatives_3: 150.0000 - val_loss: 0.7029 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 54/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.6197 - binary_accuracy: 0.6739 - false_negatives_3: 153.0000 - val_loss: 0.6925 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 55/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6297 - binary_accuracy: 0.6536 - false_negatives_3: 175.0000 - val_loss: 0.6986 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 56/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6211 - binary_accuracy: 0.6652 - false_negatives_3: 144.0000 - val_loss: 0.6970 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 57/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6282 - binary_accuracy: 0.6507 - false_negatives_3: 176.0000 - val_loss: 0.6769 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 58/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6196 - binary_accuracy: 0.6710 - false_negatives_3: 173.0000 - val_loss: 0.7020 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 59/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6222 - binary_accuracy: 0.6696 - false_negatives_3: 155.0000 - val_loss: 0.6872 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 60/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6178 - binary_accuracy: 0.6609 - false_negatives_3: 164.0000 - val_loss: 0.6742 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 61/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6184 - binary_accuracy: 0.6652 - false_negatives_3: 155.0000 - val_loss: 0.6807 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 62/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6142 - binary_accuracy: 0.6855 - false_negatives_3: 160.0000 - val_loss: 0.6814 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 63/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6176 - binary_accuracy: 0.6797 - false_negatives_3: 157.0000 - val_loss: 0.6782 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 64/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6207 - binary_accuracy: 0.6609 - false_negatives_3: 161.0000 - val_loss: 0.6879 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 65/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6173 - binary_accuracy: 0.6797 - false_negatives_3: 158.0000 - val_loss: 0.6868 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 66/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6146 - binary_accuracy: 0.6768 - false_negatives_3: 146.0000 - val_loss: 0.6728 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 67/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6251 - binary_accuracy: 0.6623 - false_negatives_3: 174.0000 - val_loss: 0.6739 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 68/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6178 - binary_accuracy: 0.6696 - false_negatives_3: 153.0000 - val_loss: 0.6792 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 69/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6105 - binary_accuracy: 0.6797 - false_negatives_3: 160.0000 - val_loss: 0.6748 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 70/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6115 - binary_accuracy: 0.6870 - false_negatives_3: 150.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 71/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6263 - binary_accuracy: 0.6638 - false_negatives_3: 171.0000 - val_loss: 0.6636 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 72/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6081 - binary_accuracy: 0.6870 - false_negatives_3: 150.0000 - val_loss: 0.6709 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 73/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6110 - binary_accuracy: 0.6754 - false_negatives_3: 149.0000 - val_loss: 0.6881 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 74/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6164 - binary_accuracy: 0.6841 - false_negatives_3: 166.0000 - val_loss: 0.6879 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 75/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6161 - binary_accuracy: 0.6797 - false_negatives_3: 161.0000 - val_loss: 0.6824 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 76/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6163 - binary_accuracy: 0.6754 - false_negatives_3: 160.0000 - val_loss: 0.6927 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 77/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6117 - binary_accuracy: 0.6652 - false_negatives_3: 154.0000 - val_loss: 0.6936 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 78/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6203 - binary_accuracy: 0.6797 - false_negatives_3: 154.0000 - val_loss: 0.6984 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 79/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6157 - binary_accuracy: 0.6797 - false_negatives_3: 156.0000 - val_loss: 0.6856 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 80/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6212 - binary_accuracy: 0.6609 - false_negatives_3: 164.0000 - val_loss: 0.6725 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 81/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6087 - binary_accuracy: 0.6725 - false_negatives_3: 164.0000 - val_loss: 0.6783 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 82/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6130 - binary_accuracy: 0.6841 - false_negatives_3: 149.0000 - val_loss: 0.6948 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 83/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6079 - binary_accuracy: 0.6725 - false_negatives_3: 150.0000 - val_loss: 0.6828 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 84/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6285 - binary_accuracy: 0.6725 - false_negatives_3: 166.0000 - val_loss: 0.6828 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 85/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6211 - binary_accuracy: 0.6681 - false_negatives_3: 163.0000 - val_loss: 0.6924 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 86/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6243 - binary_accuracy: 0.6696 - false_negatives_3: 148.0000 - val_loss: 0.6696 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 87/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6248 - binary_accuracy: 0.6681 - false_negatives_3: 166.0000 - val_loss: 0.6807 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 88/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6169 - binary_accuracy: 0.6710 - false_negatives_3: 164.0000 - val_loss: 0.6750 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 89/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6172 - binary_accuracy: 0.6725 - false_negatives_3: 154.0000 - val_loss: 0.6727 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 90/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6182 - binary_accuracy: 0.6826 - false_negatives_3: 158.0000 - val_loss: 0.6693 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 91/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6202 - binary_accuracy: 0.6783 - false_negatives_3: 159.0000 - val_loss: 0.6828 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 92/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6091 - binary_accuracy: 0.6884 - false_negatives_3: 150.0000 - val_loss: 0.6816 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 93/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6168 - binary_accuracy: 0.6623 - false_negatives_3: 154.0000 - val_loss: 0.6849 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 94/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6221 - binary_accuracy: 0.6580 - false_negatives_3: 171.0000 - val_loss: 0.6832 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 95/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6124 - binary_accuracy: 0.6768 - false_negatives_3: 141.0000 - val_loss: 0.6862 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 96/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6189 - binary_accuracy: 0.6812 - false_negatives_3: 161.0000 - val_loss: 0.6833 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 97/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6162 - binary_accuracy: 0.6739 - false_negatives_3: 148.0000 - val_loss: 0.6751 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 98/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6084 - binary_accuracy: 0.6783 - false_negatives_3: 155.0000 - val_loss: 0.6788 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 99/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6090 - binary_accuracy: 0.6870 - false_negatives_3: 149.0000 - val_loss: 0.6939 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 100/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6112 - binary_accuracy: 0.6855 - false_negatives_3: 145.0000 - val_loss: 0.6795 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 101/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6062 - binary_accuracy: 0.6884 - false_negatives_3: 165.0000 - val_loss: 0.6820 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 102/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6175 - binary_accuracy: 0.6783 - false_negatives_3: 159.0000 - val_loss: 0.6767 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 103/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6161 - binary_accuracy: 0.6957 - false_negatives_3: 142.0000 - val_loss: 0.6802 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 104/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6197 - binary_accuracy: 0.6768 - false_negatives_3: 164.0000 - val_loss: 0.6694 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 105/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6130 - binary_accuracy: 0.6696 - false_negatives_3: 159.0000 - val_loss: 0.6722 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 106/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6176 - binary_accuracy: 0.6899 - false_negatives_3: 144.0000 - val_loss: 0.6651 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 107/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6142 - binary_accuracy: 0.6623 - false_negatives_3: 169.0000 - val_loss: 0.6726 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 108/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6183 - binary_accuracy: 0.6681 - false_negatives_3: 162.0000 - val_loss: 0.6762 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 109/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6127 - binary_accuracy: 0.6812 - false_negatives_3: 149.0000 - val_loss: 0.6764 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 110/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6115 - binary_accuracy: 0.6884 - false_negatives_3: 161.0000 - val_loss: 0.6792 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 111/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6180 - binary_accuracy: 0.6594 - false_negatives_3: 161.0000 - val_loss: 0.6673 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 112/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6181 - binary_accuracy: 0.6710 - false_negatives_3: 161.0000 - val_loss: 0.6756 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 113/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6198 - binary_accuracy: 0.6725 - false_negatives_3: 178.0000 - val_loss: 0.6687 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 114/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6122 - binary_accuracy: 0.6754 - false_negatives_3: 148.0000 - val_loss: 0.6787 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 115/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6175 - binary_accuracy: 0.6754 - false_negatives_3: 169.0000 - val_loss: 0.6650 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 116/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6135 - binary_accuracy: 0.6913 - false_negatives_3: 158.0000 - val_loss: 0.6746 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 117/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6188 - binary_accuracy: 0.6826 - false_negatives_3: 163.0000 - val_loss: 0.6767 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 118/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6106 - binary_accuracy: 0.6884 - false_negatives_3: 151.0000 - val_loss: 0.6898 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 119/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6130 - binary_accuracy: 0.6652 - false_negatives_3: 153.0000 - val_loss: 0.6800 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 120/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6335 - binary_accuracy: 0.6797 - false_negatives_3: 150.0000 - val_loss: 0.6801 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 121/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6164 - binary_accuracy: 0.6797 - false_negatives_3: 187.0000 - val_loss: 0.6718 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 122/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6124 - binary_accuracy: 0.6812 - false_negatives_3: 148.0000 - val_loss: 0.6869 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 123/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6153 - binary_accuracy: 0.6681 - false_negatives_3: 163.0000 - val_loss: 0.6917 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 124/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6109 - binary_accuracy: 0.6797 - false_negatives_3: 152.0000 - val_loss: 0.6962 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 125/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6155 - binary_accuracy: 0.6870 - false_negatives_3: 145.0000 - val_loss: 0.6982 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 126/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6037 - binary_accuracy: 0.6826 - false_negatives_3: 152.0000 - val_loss: 0.7001 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 127/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6175 - binary_accuracy: 0.6870 - false_negatives_3: 155.0000 - val_loss: 0.7005 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 128/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6123 - binary_accuracy: 0.6696 - false_negatives_3: 151.0000 - val_loss: 0.7046 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 129/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6141 - binary_accuracy: 0.6710 - false_negatives_3: 173.0000 - val_loss: 0.6757 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 130/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6206 - binary_accuracy: 0.6667 - false_negatives_3: 154.0000 - val_loss: 0.6902 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 131/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6132 - binary_accuracy: 0.6652 - false_negatives_3: 163.0000 - val_loss: 0.6970 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 132/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6179 - binary_accuracy: 0.6652 - false_negatives_3: 159.0000 - val_loss: 0.6823 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 133/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6100 - binary_accuracy: 0.6841 - false_negatives_3: 152.0000 - val_loss: 0.6934 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 134/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6223 - binary_accuracy: 0.6594 - false_negatives_3: 157.0000 - val_loss: 0.6737 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 135/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6161 - binary_accuracy: 0.6812 - false_negatives_3: 162.0000 - val_loss: 0.6928 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 136/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6133 - binary_accuracy: 0.6913 - false_negatives_3: 156.0000 - val_loss: 0.6788 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 137/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6132 - binary_accuracy: 0.6812 - false_negatives_3: 150.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 138/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6050 - binary_accuracy: 0.6768 - false_negatives_3: 162.0000 - val_loss: 0.6939 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 139/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6202 - binary_accuracy: 0.6768 - false_negatives_3: 147.0000 - val_loss: 0.6675 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 140/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6183 - binary_accuracy: 0.6580 - false_negatives_3: 182.0000 - val_loss: 0.6648 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 141/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6130 - binary_accuracy: 0.6841 - false_negatives_3: 149.0000 - val_loss: 0.6816 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 142/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6116 - binary_accuracy: 0.6928 - false_negatives_3: 135.0000 - val_loss: 0.6747 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 143/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6186 - binary_accuracy: 0.6522 - false_negatives_3: 178.0000 - val_loss: 0.6693 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 144/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6083 - binary_accuracy: 0.6855 - false_negatives_3: 163.0000 - val_loss: 0.6646 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 145/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6101 - binary_accuracy: 0.6884 - false_negatives_3: 153.0000 - val_loss: 0.6826 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 146/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6110 - binary_accuracy: 0.6725 - false_negatives_3: 170.0000 - val_loss: 0.6789 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 147/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6200 - binary_accuracy: 0.6725 - false_negatives_3: 161.0000 - val_loss: 0.6848 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 148/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6151 - binary_accuracy: 0.6812 - false_negatives_3: 150.0000 - val_loss: 0.6783 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 149/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6106 - binary_accuracy: 0.6797 - false_negatives_3: 158.0000 - val_loss: 0.6737 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 150/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6118 - binary_accuracy: 0.6812 - false_negatives_3: 150.0000 - val_loss: 0.6976 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 151/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6122 - binary_accuracy: 0.6841 - false_negatives_3: 160.0000 - val_loss: 0.6845 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 152/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6187 - binary_accuracy: 0.6623 - false_negatives_3: 161.0000 - val_loss: 0.6723 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 153/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6166 - binary_accuracy: 0.6783 - false_negatives_3: 153.0000 - val_loss: 0.6755 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 154/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6115 - binary_accuracy: 0.6754 - false_negatives_3: 158.0000 - val_loss: 0.6742 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 155/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6124 - binary_accuracy: 0.6565 - false_negatives_3: 167.0000 - val_loss: 0.6867 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 156/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6202 - binary_accuracy: 0.6667 - false_negatives_3: 154.0000 - val_loss: 0.6724 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 157/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6142 - binary_accuracy: 0.6710 - false_negatives_3: 163.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 158/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6111 - binary_accuracy: 0.6768 - false_negatives_3: 165.0000 - val_loss: 0.6839 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 159/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6112 - binary_accuracy: 0.6754 - false_negatives_3: 148.0000 - val_loss: 0.6949 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 160/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6137 - binary_accuracy: 0.6652 - false_negatives_3: 161.0000 - val_loss: 0.6818 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 161/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6106 - binary_accuracy: 0.6768 - false_negatives_3: 163.0000 - val_loss: 0.6830 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 162/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6009 - binary_accuracy: 0.6754 - false_negatives_3: 153.0000 - val_loss: 0.6942 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 163/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6147 - binary_accuracy: 0.6797 - false_negatives_3: 158.0000 - val_loss: 0.6886 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 164/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6142 - binary_accuracy: 0.6710 - false_negatives_3: 163.0000 - val_loss: 0.6851 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 165/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6119 - binary_accuracy: 0.6826 - false_negatives_3: 153.0000 - val_loss: 0.6854 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 166/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6085 - binary_accuracy: 0.6783 - false_negatives_3: 155.0000 - val_loss: 0.6871 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 167/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6101 - binary_accuracy: 0.6768 - false_negatives_3: 163.0000 - val_loss: 0.6905 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 168/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6125 - binary_accuracy: 0.6783 - false_negatives_3: 165.0000 - val_loss: 0.6940 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 169/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6121 - binary_accuracy: 0.6768 - false_negatives_3: 150.0000 - val_loss: 0.6979 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 170/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6166 - binary_accuracy: 0.6797 - false_negatives_3: 155.0000 - val_loss: 0.6929 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 171/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6113 - binary_accuracy: 0.6725 - false_negatives_3: 169.0000 - val_loss: 0.6784 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 172/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6093 - binary_accuracy: 0.6768 - false_negatives_3: 147.0000 - val_loss: 0.6918 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 173/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6113 - binary_accuracy: 0.6841 - false_negatives_3: 158.0000 - val_loss: 0.6893 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 174/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6118 - binary_accuracy: 0.6667 - false_negatives_3: 163.0000 - val_loss: 0.6729 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 175/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6179 - binary_accuracy: 0.6667 - false_negatives_3: 159.0000 - val_loss: 0.6919 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 176/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6152 - binary_accuracy: 0.6841 - false_negatives_3: 143.0000 - val_loss: 0.6893 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 177/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6152 - binary_accuracy: 0.6870 - false_negatives_3: 164.0000 - val_loss: 0.6749 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 178/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6097 - binary_accuracy: 0.6768 - false_negatives_3: 162.0000 - val_loss: 0.6794 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 179/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6067 - binary_accuracy: 0.6739 - false_negatives_3: 157.0000 - val_loss: 0.6848 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 180/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6139 - binary_accuracy: 0.6754 - false_negatives_3: 162.0000 - val_loss: 0.6804 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 181/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6155 - binary_accuracy: 0.6652 - false_negatives_3: 174.0000 - val_loss: 0.6830 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 182/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6209 - binary_accuracy: 0.6768 - false_negatives_3: 143.0000 - val_loss: 0.6730 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 183/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6206 - binary_accuracy: 0.6710 - false_negatives_3: 167.0000 - val_loss: 0.6721 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 184/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6092 - binary_accuracy: 0.6696 - false_negatives_3: 150.0000 - val_loss: 0.6911 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 185/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6086 - binary_accuracy: 0.6928 - false_negatives_3: 158.0000 - val_loss: 0.6821 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 186/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6187 - binary_accuracy: 0.6536 - false_negatives_3: 175.0000 - val_loss: 0.6860 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 187/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6139 - binary_accuracy: 0.6855 - false_negatives_3: 155.0000 - val_loss: 0.6897 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 188/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6093 - binary_accuracy: 0.6783 - false_negatives_3: 149.0000 - val_loss: 0.6876 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 189/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6057 - binary_accuracy: 0.6826 - false_negatives_3: 155.0000 - val_loss: 0.6868 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 190/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6107 - binary_accuracy: 0.6855 - false_negatives_3: 155.0000 - val_loss: 0.6842 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 191/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6180 - binary_accuracy: 0.6739 - false_negatives_3: 159.0000 - val_loss: 0.6811 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 192/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6197 - binary_accuracy: 0.6710 - false_negatives_3: 169.0000 - val_loss: 0.6860 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 193/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6137 - binary_accuracy: 0.6725 - false_negatives_3: 153.0000 - val_loss: 0.6783 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 194/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6122 - binary_accuracy: 0.6826 - false_negatives_3: 163.0000 - val_loss: 0.6839 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 195/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6150 - binary_accuracy: 0.6681 - false_negatives_3: 164.0000 - val_loss: 0.6877 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 196/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6127 - binary_accuracy: 0.6797 - false_negatives_3: 167.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 197/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6120 - binary_accuracy: 0.6768 - false_negatives_3: 161.0000 - val_loss: 0.6779 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 198/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6100 - binary_accuracy: 0.6797 - false_negatives_3: 159.0000 - val_loss: 0.6802 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 199/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6188 - binary_accuracy: 0.6725 - false_negatives_3: 152.0000 - val_loss: 0.6776 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 200/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6168 - binary_accuracy: 0.6855 - false_negatives_3: 164.0000 - val_loss: 0.6758 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 201/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6141 - binary_accuracy: 0.6725 - false_negatives_3: 166.0000 - val_loss: 0.6797 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 202/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6140 - binary_accuracy: 0.6754 - false_negatives_3: 161.0000 - val_loss: 0.6787 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 203/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6163 - binary_accuracy: 0.6783 - false_negatives_3: 159.0000 - val_loss: 0.6818 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 204/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6078 - binary_accuracy: 0.6797 - false_negatives_3: 153.0000 - val_loss: 0.6889 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 205/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6140 - binary_accuracy: 0.6884 - false_negatives_3: 164.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 206/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6143 - binary_accuracy: 0.6768 - false_negatives_3: 165.0000 - val_loss: 0.6848 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 207/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6157 - binary_accuracy: 0.6783 - false_negatives_3: 165.0000 - val_loss: 0.6854 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 208/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6185 - binary_accuracy: 0.6826 - false_negatives_3: 155.0000 - val_loss: 0.6819 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 209/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6163 - binary_accuracy: 0.6754 - false_negatives_3: 169.0000 - val_loss: 0.6813 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 210/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6170 - binary_accuracy: 0.6812 - false_negatives_3: 161.0000 - val_loss: 0.6751 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 211/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6042 - binary_accuracy: 0.6899 - false_negatives_3: 159.0000 - val_loss: 0.6849 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 212/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6143 - binary_accuracy: 0.6783 - false_negatives_3: 156.0000 - val_loss: 0.6824 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 213/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6156 - binary_accuracy: 0.6812 - false_negatives_3: 153.0000 - val_loss: 0.6809 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 214/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6176 - binary_accuracy: 0.6565 - false_negatives_3: 171.0000 - val_loss: 0.6690 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 215/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6169 - binary_accuracy: 0.6783 - false_negatives_3: 159.0000 - val_loss: 0.6794 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 216/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6140 - binary_accuracy: 0.6783 - false_negatives_3: 158.0000 - val_loss: 0.6808 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 217/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6063 - binary_accuracy: 0.6899 - false_negatives_3: 159.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 218/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6085 - binary_accuracy: 0.6739 - false_negatives_3: 158.0000 - val_loss: 0.6731 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 219/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6139 - binary_accuracy: 0.6725 - false_negatives_3: 151.0000 - val_loss: 0.6772 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 220/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6197 - binary_accuracy: 0.6696 - false_negatives_3: 164.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 221/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6145 - binary_accuracy: 0.6652 - false_negatives_3: 172.0000 - val_loss: 0.6768 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 222/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6152 - binary_accuracy: 0.6638 - false_negatives_3: 179.0000 - val_loss: 0.6768 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 223/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6195 - binary_accuracy: 0.6667 - false_negatives_3: 165.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 224/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6112 - binary_accuracy: 0.6826 - false_negatives_3: 165.0000 - val_loss: 0.6803 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 225/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6067 - binary_accuracy: 0.6986 - false_negatives_3: 152.0000 - val_loss: 0.6844 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 226/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6097 - binary_accuracy: 0.6725 - false_negatives_3: 158.0000 - val_loss: 0.6843 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 227/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6022 - binary_accuracy: 0.6783 - false_negatives_3: 171.0000 - val_loss: 0.6894 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 228/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6037 - binary_accuracy: 0.6812 - false_negatives_3: 152.0000 - val_loss: 0.6975 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 229/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6085 - binary_accuracy: 0.6913 - false_negatives_3: 151.0000 - val_loss: 0.6972 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 230/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6215 - binary_accuracy: 0.6623 - false_negatives_3: 161.0000 - val_loss: 0.6838 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 231/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6123 - binary_accuracy: 0.6609 - false_negatives_3: 181.0000 - val_loss: 0.6827 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 232/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6177 - binary_accuracy: 0.6565 - false_negatives_3: 175.0000 - val_loss: 0.6870 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 233/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6232 - binary_accuracy: 0.6580 - false_negatives_3: 164.0000 - val_loss: 0.6860 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 234/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6088 - binary_accuracy: 0.6797 - false_negatives_3: 150.0000 - val_loss: 0.6814 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 235/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6175 - binary_accuracy: 0.6681 - false_negatives_3: 170.0000 - val_loss: 0.6727 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 236/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6174 - binary_accuracy: 0.6884 - false_negatives_3: 153.0000 - val_loss: 0.6924 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 237/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6159 - binary_accuracy: 0.6913 - false_negatives_3: 175.0000 - val_loss: 0.6824 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 238/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6092 - binary_accuracy: 0.6812 - false_negatives_3: 163.0000 - val_loss: 0.6863 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 239/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6163 - binary_accuracy: 0.6841 - false_negatives_3: 156.0000 - val_loss: 0.6853 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 240/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6198 - binary_accuracy: 0.6507 - false_negatives_3: 177.0000 - val_loss: 0.6803 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 241/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6027 - binary_accuracy: 0.6884 - false_negatives_3: 149.0000 - val_loss: 0.6893 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 242/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6253 - binary_accuracy: 0.6638 - false_negatives_3: 157.0000 - val_loss: 0.6855 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 243/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6206 - binary_accuracy: 0.6652 - false_negatives_3: 176.0000 - val_loss: 0.6726 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 244/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6131 - binary_accuracy: 0.6725 - false_negatives_3: 167.0000 - val_loss: 0.6753 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 245/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6111 - binary_accuracy: 0.6754 - false_negatives_3: 167.0000 - val_loss: 0.6830 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 246/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6147 - binary_accuracy: 0.6696 - false_negatives_3: 161.0000 - val_loss: 0.6874 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 247/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6110 - binary_accuracy: 0.6855 - false_negatives_3: 165.0000 - val_loss: 0.6843 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 248/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6216 - binary_accuracy: 0.6623 - false_negatives_3: 157.0000 - val_loss: 0.6813 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 249/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6239 - binary_accuracy: 0.6638 - false_negatives_3: 161.0000 - val_loss: 0.6751 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 250/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6123 - binary_accuracy: 0.6855 - false_negatives_3: 160.0000 - val_loss: 0.6761 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 251/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6112 - binary_accuracy: 0.6681 - false_negatives_3: 170.0000 - val_loss: 0.6790 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 252/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6087 - binary_accuracy: 0.6855 - false_negatives_3: 153.0000 - val_loss: 0.6794 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 253/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6210 - binary_accuracy: 0.6681 - false_negatives_3: 158.0000 - val_loss: 0.6733 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 254/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6192 - binary_accuracy: 0.6841 - false_negatives_3: 158.0000 - val_loss: 0.6723 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 255/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6272 - binary_accuracy: 0.6580 - false_negatives_3: 175.0000 - val_loss: 0.6692 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 256/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6141 - binary_accuracy: 0.6710 - false_negatives_3: 165.0000 - val_loss: 0.6663 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 257/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6169 - binary_accuracy: 0.6594 - false_negatives_3: 174.0000 - val_loss: 0.6781 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 258/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6104 - binary_accuracy: 0.6826 - false_negatives_3: 159.0000 - val_loss: 0.6797 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 259/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6134 - binary_accuracy: 0.6667 - false_negatives_3: 163.0000 - val_loss: 0.6795 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 260/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6100 - binary_accuracy: 0.6841 - false_negatives_3: 163.0000 - val_loss: 0.6838 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 261/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6168 - binary_accuracy: 0.6667 - false_negatives_3: 167.0000 - val_loss: 0.6773 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 262/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6242 - binary_accuracy: 0.6652 - false_negatives_3: 162.0000 - val_loss: 0.6756 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 263/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6106 - binary_accuracy: 0.6725 - false_negatives_3: 174.0000 - val_loss: 0.6680 - val_binary_accuracy: 0.6609 - val_false_negatives_3: 78.0000\n",
            "Epoch 264/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6163 - binary_accuracy: 0.6739 - false_negatives_3: 160.0000 - val_loss: 0.6742 - val_binary_accuracy: 0.6609 - val_false_negatives_3: 78.0000\n",
            "Epoch 265/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6110 - binary_accuracy: 0.6754 - false_negatives_3: 160.0000 - val_loss: 0.6776 - val_binary_accuracy: 0.6609 - val_false_negatives_3: 78.0000\n",
            "Epoch 266/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6194 - binary_accuracy: 0.6681 - false_negatives_3: 163.0000 - val_loss: 0.6798 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 267/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6082 - binary_accuracy: 0.6812 - false_negatives_3: 155.0000 - val_loss: 0.6914 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 268/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6154 - binary_accuracy: 0.6696 - false_negatives_3: 167.0000 - val_loss: 0.6859 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 269/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6125 - binary_accuracy: 0.6855 - false_negatives_3: 150.0000 - val_loss: 0.6836 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 270/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6109 - binary_accuracy: 0.6768 - false_negatives_3: 160.0000 - val_loss: 0.6832 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 271/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6137 - binary_accuracy: 0.6884 - false_negatives_3: 162.0000 - val_loss: 0.6779 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 272/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6144 - binary_accuracy: 0.6797 - false_negatives_3: 158.0000 - val_loss: 0.6774 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 273/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6132 - binary_accuracy: 0.6754 - false_negatives_3: 169.0000 - val_loss: 0.6759 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 274/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6068 - binary_accuracy: 0.6826 - false_negatives_3: 153.0000 - val_loss: 0.6707 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 275/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6063 - binary_accuracy: 0.6971 - false_negatives_3: 161.0000 - val_loss: 0.6817 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 276/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6092 - binary_accuracy: 0.6797 - false_negatives_3: 167.0000 - val_loss: 0.6732 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 277/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6077 - binary_accuracy: 0.6870 - false_negatives_3: 162.0000 - val_loss: 0.6696 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 278/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6084 - binary_accuracy: 0.6739 - false_negatives_3: 153.0000 - val_loss: 0.6803 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 279/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6156 - binary_accuracy: 0.6681 - false_negatives_3: 171.0000 - val_loss: 0.6707 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 280/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6211 - binary_accuracy: 0.6797 - false_negatives_3: 161.0000 - val_loss: 0.6754 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 281/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6066 - binary_accuracy: 0.6783 - false_negatives_3: 163.0000 - val_loss: 0.6832 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 282/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6025 - binary_accuracy: 0.6855 - false_negatives_3: 165.0000 - val_loss: 0.6834 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 283/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6179 - binary_accuracy: 0.6725 - false_negatives_3: 163.0000 - val_loss: 0.6894 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 284/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6163 - binary_accuracy: 0.6826 - false_negatives_3: 164.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 285/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6153 - binary_accuracy: 0.6710 - false_negatives_3: 170.0000 - val_loss: 0.6755 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 286/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6187 - binary_accuracy: 0.6681 - false_negatives_3: 170.0000 - val_loss: 0.6672 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 287/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6193 - binary_accuracy: 0.6710 - false_negatives_3: 175.0000 - val_loss: 0.6705 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 288/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6097 - binary_accuracy: 0.6739 - false_negatives_3: 152.0000 - val_loss: 0.6773 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 289/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6127 - binary_accuracy: 0.6899 - false_negatives_3: 157.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 290/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6180 - binary_accuracy: 0.6652 - false_negatives_3: 184.0000 - val_loss: 0.6758 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 291/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6186 - binary_accuracy: 0.6754 - false_negatives_3: 165.0000 - val_loss: 0.6727 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 292/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6137 - binary_accuracy: 0.6928 - false_negatives_3: 151.0000 - val_loss: 0.6803 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 293/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6143 - binary_accuracy: 0.6899 - false_negatives_3: 158.0000 - val_loss: 0.6811 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 294/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6112 - binary_accuracy: 0.6841 - false_negatives_3: 164.0000 - val_loss: 0.6846 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 295/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6114 - binary_accuracy: 0.6841 - false_negatives_3: 159.0000 - val_loss: 0.6825 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 296/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6124 - binary_accuracy: 0.6797 - false_negatives_3: 160.0000 - val_loss: 0.6784 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 297/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6079 - binary_accuracy: 0.6812 - false_negatives_3: 162.0000 - val_loss: 0.6823 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 298/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6142 - binary_accuracy: 0.6841 - false_negatives_3: 159.0000 - val_loss: 0.6776 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 299/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6101 - binary_accuracy: 0.6797 - false_negatives_3: 166.0000 - val_loss: 0.6721 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 300/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6089 - binary_accuracy: 0.6870 - false_negatives_3: 157.0000 - val_loss: 0.6883 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 301/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6067 - binary_accuracy: 0.6841 - false_negatives_3: 162.0000 - val_loss: 0.6805 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 302/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6178 - binary_accuracy: 0.6841 - false_negatives_3: 168.0000 - val_loss: 0.6797 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 303/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6148 - binary_accuracy: 0.6768 - false_negatives_3: 160.0000 - val_loss: 0.6904 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 304/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6135 - binary_accuracy: 0.6667 - false_negatives_3: 164.0000 - val_loss: 0.6798 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 305/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6083 - binary_accuracy: 0.6783 - false_negatives_3: 161.0000 - val_loss: 0.6822 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 306/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6171 - binary_accuracy: 0.6754 - false_negatives_3: 164.0000 - val_loss: 0.6757 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 307/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6108 - binary_accuracy: 0.6797 - false_negatives_3: 165.0000 - val_loss: 0.6718 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 308/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6139 - binary_accuracy: 0.6783 - false_negatives_3: 171.0000 - val_loss: 0.6844 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 309/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6131 - binary_accuracy: 0.6841 - false_negatives_3: 164.0000 - val_loss: 0.6756 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 310/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6112 - binary_accuracy: 0.6855 - false_negatives_3: 149.0000 - val_loss: 0.6763 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 311/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6123 - binary_accuracy: 0.6696 - false_negatives_3: 176.0000 - val_loss: 0.6763 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 312/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6226 - binary_accuracy: 0.6681 - false_negatives_3: 158.0000 - val_loss: 0.6778 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 313/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6142 - binary_accuracy: 0.6725 - false_negatives_3: 171.0000 - val_loss: 0.6818 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 314/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6151 - binary_accuracy: 0.6739 - false_negatives_3: 167.0000 - val_loss: 0.6785 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 315/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6157 - binary_accuracy: 0.6913 - false_negatives_3: 160.0000 - val_loss: 0.6747 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 316/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6123 - binary_accuracy: 0.6797 - false_negatives_3: 167.0000 - val_loss: 0.6773 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 317/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6137 - binary_accuracy: 0.6710 - false_negatives_3: 168.0000 - val_loss: 0.6792 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 318/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6240 - binary_accuracy: 0.6652 - false_negatives_3: 167.0000 - val_loss: 0.6732 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 319/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6121 - binary_accuracy: 0.6855 - false_negatives_3: 166.0000 - val_loss: 0.6760 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 320/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6102 - binary_accuracy: 0.7014 - false_negatives_3: 145.0000 - val_loss: 0.6767 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 321/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6189 - binary_accuracy: 0.6797 - false_negatives_3: 159.0000 - val_loss: 0.6831 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 322/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6103 - binary_accuracy: 0.6826 - false_negatives_3: 170.0000 - val_loss: 0.6854 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 323/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6135 - binary_accuracy: 0.6696 - false_negatives_3: 173.0000 - val_loss: 0.6828 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 324/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6184 - binary_accuracy: 0.6681 - false_negatives_3: 163.0000 - val_loss: 0.6862 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 325/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6087 - binary_accuracy: 0.6826 - false_negatives_3: 159.0000 - val_loss: 0.6821 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 326/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6124 - binary_accuracy: 0.6797 - false_negatives_3: 171.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 327/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6043 - binary_accuracy: 0.6884 - false_negatives_3: 157.0000 - val_loss: 0.6860 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 328/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6108 - binary_accuracy: 0.6841 - false_negatives_3: 158.0000 - val_loss: 0.6722 - val_binary_accuracy: 0.6609 - val_false_negatives_3: 78.0000\n",
            "Epoch 329/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6070 - binary_accuracy: 0.6899 - false_negatives_3: 161.0000 - val_loss: 0.6819 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 330/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6149 - binary_accuracy: 0.6594 - false_negatives_3: 163.0000 - val_loss: 0.6754 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 331/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6156 - binary_accuracy: 0.6870 - false_negatives_3: 173.0000 - val_loss: 0.6657 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 332/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6169 - binary_accuracy: 0.6841 - false_negatives_3: 164.0000 - val_loss: 0.6748 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 333/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6101 - binary_accuracy: 0.6783 - false_negatives_3: 154.0000 - val_loss: 0.6737 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 334/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6142 - binary_accuracy: 0.6710 - false_negatives_3: 172.0000 - val_loss: 0.6889 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 335/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6090 - binary_accuracy: 0.6870 - false_negatives_3: 167.0000 - val_loss: 0.6859 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 336/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6137 - binary_accuracy: 0.6783 - false_negatives_3: 158.0000 - val_loss: 0.6939 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 337/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6123 - binary_accuracy: 0.6899 - false_negatives_3: 162.0000 - val_loss: 0.6893 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 338/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6134 - binary_accuracy: 0.6870 - false_negatives_3: 160.0000 - val_loss: 0.6766 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 339/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6132 - binary_accuracy: 0.6797 - false_negatives_3: 161.0000 - val_loss: 0.6797 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 340/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6143 - binary_accuracy: 0.6681 - false_negatives_3: 171.0000 - val_loss: 0.6773 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 341/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6083 - binary_accuracy: 0.6826 - false_negatives_3: 162.0000 - val_loss: 0.6828 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 342/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6078 - binary_accuracy: 0.6826 - false_negatives_3: 162.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 343/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6121 - binary_accuracy: 0.6797 - false_negatives_3: 172.0000 - val_loss: 0.6877 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 344/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6108 - binary_accuracy: 0.6855 - false_negatives_3: 166.0000 - val_loss: 0.6789 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 345/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6126 - binary_accuracy: 0.6797 - false_negatives_3: 176.0000 - val_loss: 0.6830 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 346/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6163 - binary_accuracy: 0.6710 - false_negatives_3: 163.0000 - val_loss: 0.6878 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 347/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6125 - binary_accuracy: 0.6957 - false_negatives_3: 160.0000 - val_loss: 0.6784 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 348/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6156 - binary_accuracy: 0.6754 - false_negatives_3: 175.0000 - val_loss: 0.6791 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 349/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6087 - binary_accuracy: 0.6797 - false_negatives_3: 172.0000 - val_loss: 0.6790 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 350/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6184 - binary_accuracy: 0.6754 - false_negatives_3: 178.0000 - val_loss: 0.6743 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 351/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6109 - binary_accuracy: 0.6768 - false_negatives_3: 156.0000 - val_loss: 0.6819 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 352/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6087 - binary_accuracy: 0.6855 - false_negatives_3: 161.0000 - val_loss: 0.6816 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 353/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6188 - binary_accuracy: 0.6739 - false_negatives_3: 171.0000 - val_loss: 0.6768 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 354/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6124 - binary_accuracy: 0.6652 - false_negatives_3: 170.0000 - val_loss: 0.6865 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 355/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6102 - binary_accuracy: 0.6942 - false_negatives_3: 167.0000 - val_loss: 0.6798 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 356/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6162 - binary_accuracy: 0.6696 - false_negatives_3: 169.0000 - val_loss: 0.6757 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 357/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6060 - binary_accuracy: 0.6899 - false_negatives_3: 155.0000 - val_loss: 0.6790 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 358/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6147 - binary_accuracy: 0.6855 - false_negatives_3: 166.0000 - val_loss: 0.6869 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 359/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6062 - binary_accuracy: 0.6870 - false_negatives_3: 140.0000 - val_loss: 0.6874 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 360/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6102 - binary_accuracy: 0.6797 - false_negatives_3: 172.0000 - val_loss: 0.6993 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 361/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6239 - binary_accuracy: 0.6826 - false_negatives_3: 157.0000 - val_loss: 0.6843 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 362/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6174 - binary_accuracy: 0.6913 - false_negatives_3: 169.0000 - val_loss: 0.6857 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 363/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6086 - binary_accuracy: 0.6768 - false_negatives_3: 168.0000 - val_loss: 0.6742 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 364/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6215 - binary_accuracy: 0.6739 - false_negatives_3: 171.0000 - val_loss: 0.6832 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 365/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6068 - binary_accuracy: 0.6768 - false_negatives_3: 170.0000 - val_loss: 0.6747 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 366/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6219 - binary_accuracy: 0.6667 - false_negatives_3: 174.0000 - val_loss: 0.6836 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 367/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6161 - binary_accuracy: 0.6797 - false_negatives_3: 179.0000 - val_loss: 0.6783 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 368/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6243 - binary_accuracy: 0.6565 - false_negatives_3: 166.0000 - val_loss: 0.6846 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 369/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6117 - binary_accuracy: 0.7000 - false_negatives_3: 168.0000 - val_loss: 0.6775 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 370/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6121 - binary_accuracy: 0.6812 - false_negatives_3: 175.0000 - val_loss: 0.6808 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 371/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6154 - binary_accuracy: 0.6797 - false_negatives_3: 160.0000 - val_loss: 0.6763 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 372/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6136 - binary_accuracy: 0.6783 - false_negatives_3: 162.0000 - val_loss: 0.6763 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 373/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6171 - binary_accuracy: 0.6667 - false_negatives_3: 174.0000 - val_loss: 0.6717 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 374/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6201 - binary_accuracy: 0.6623 - false_negatives_3: 167.0000 - val_loss: 0.6695 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 375/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6142 - binary_accuracy: 0.6710 - false_negatives_3: 174.0000 - val_loss: 0.6730 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 376/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6172 - binary_accuracy: 0.6652 - false_negatives_3: 167.0000 - val_loss: 0.6680 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 377/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6068 - binary_accuracy: 0.6812 - false_negatives_3: 179.0000 - val_loss: 0.6772 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 378/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6148 - binary_accuracy: 0.6652 - false_negatives_3: 161.0000 - val_loss: 0.6733 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 379/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6136 - binary_accuracy: 0.6667 - false_negatives_3: 164.0000 - val_loss: 0.6763 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 380/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6104 - binary_accuracy: 0.6768 - false_negatives_3: 156.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 381/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6179 - binary_accuracy: 0.6681 - false_negatives_3: 174.0000 - val_loss: 0.6708 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 382/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6123 - binary_accuracy: 0.6841 - false_negatives_3: 160.0000 - val_loss: 0.6722 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 383/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6130 - binary_accuracy: 0.6797 - false_negatives_3: 167.0000 - val_loss: 0.6882 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 384/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6194 - binary_accuracy: 0.6812 - false_negatives_3: 153.0000 - val_loss: 0.6773 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 385/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6092 - binary_accuracy: 0.6754 - false_negatives_3: 166.0000 - val_loss: 0.6732 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 386/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6177 - binary_accuracy: 0.6667 - false_negatives_3: 172.0000 - val_loss: 0.6731 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 387/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6150 - binary_accuracy: 0.6768 - false_negatives_3: 168.0000 - val_loss: 0.6682 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 388/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6052 - binary_accuracy: 0.6928 - false_negatives_3: 166.0000 - val_loss: 0.6724 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 389/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6057 - binary_accuracy: 0.6899 - false_negatives_3: 161.0000 - val_loss: 0.6791 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 390/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6103 - binary_accuracy: 0.6884 - false_negatives_3: 156.0000 - val_loss: 0.6770 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 391/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6144 - binary_accuracy: 0.6667 - false_negatives_3: 166.0000 - val_loss: 0.6668 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 392/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6133 - binary_accuracy: 0.6696 - false_negatives_3: 164.0000 - val_loss: 0.6706 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 393/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6155 - binary_accuracy: 0.6797 - false_negatives_3: 168.0000 - val_loss: 0.6661 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 394/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6155 - binary_accuracy: 0.6696 - false_negatives_3: 166.0000 - val_loss: 0.6637 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 395/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6156 - binary_accuracy: 0.6870 - false_negatives_3: 153.0000 - val_loss: 0.6704 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 396/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6151 - binary_accuracy: 0.6754 - false_negatives_3: 177.0000 - val_loss: 0.6681 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 397/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6145 - binary_accuracy: 0.6739 - false_negatives_3: 157.0000 - val_loss: 0.6728 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 398/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6138 - binary_accuracy: 0.6710 - false_negatives_3: 171.0000 - val_loss: 0.6718 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 399/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6147 - binary_accuracy: 0.6826 - false_negatives_3: 173.0000 - val_loss: 0.6709 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 400/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6114 - binary_accuracy: 0.6870 - false_negatives_3: 169.0000 - val_loss: 0.6721 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 401/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6091 - binary_accuracy: 0.6826 - false_negatives_3: 173.0000 - val_loss: 0.6796 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 402/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6234 - binary_accuracy: 0.6652 - false_negatives_3: 178.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 403/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6103 - binary_accuracy: 0.6884 - false_negatives_3: 167.0000 - val_loss: 0.6818 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 404/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6098 - binary_accuracy: 0.6913 - false_negatives_3: 160.0000 - val_loss: 0.6797 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 405/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6105 - binary_accuracy: 0.6812 - false_negatives_3: 169.0000 - val_loss: 0.6834 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 406/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6002 - binary_accuracy: 0.6986 - false_negatives_3: 152.0000 - val_loss: 0.6750 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 407/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6143 - binary_accuracy: 0.6681 - false_negatives_3: 174.0000 - val_loss: 0.6838 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 408/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6211 - binary_accuracy: 0.6565 - false_negatives_3: 176.0000 - val_loss: 0.6806 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 409/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6141 - binary_accuracy: 0.6783 - false_negatives_3: 181.0000 - val_loss: 0.6679 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 410/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6240 - binary_accuracy: 0.6594 - false_negatives_3: 162.0000 - val_loss: 0.6713 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 411/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6118 - binary_accuracy: 0.6841 - false_negatives_3: 165.0000 - val_loss: 0.6668 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 412/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6189 - binary_accuracy: 0.6580 - false_negatives_3: 163.0000 - val_loss: 0.6733 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 413/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6101 - binary_accuracy: 0.6797 - false_negatives_3: 172.0000 - val_loss: 0.6725 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 414/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6186 - binary_accuracy: 0.6826 - false_negatives_3: 172.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 415/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6167 - binary_accuracy: 0.6594 - false_negatives_3: 172.0000 - val_loss: 0.6635 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 416/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6149 - binary_accuracy: 0.6870 - false_negatives_3: 167.0000 - val_loss: 0.6694 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 417/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6166 - binary_accuracy: 0.6855 - false_negatives_3: 150.0000 - val_loss: 0.6705 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 418/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6217 - binary_accuracy: 0.6667 - false_negatives_3: 181.0000 - val_loss: 0.6722 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 419/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6002 - binary_accuracy: 0.7072 - false_negatives_3: 150.0000 - val_loss: 0.6756 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 420/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6066 - binary_accuracy: 0.6768 - false_negatives_3: 152.0000 - val_loss: 0.6706 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 421/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6103 - binary_accuracy: 0.6768 - false_negatives_3: 163.0000 - val_loss: 0.6819 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 422/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6198 - binary_accuracy: 0.6884 - false_negatives_3: 164.0000 - val_loss: 0.6678 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 423/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6067 - binary_accuracy: 0.6826 - false_negatives_3: 152.0000 - val_loss: 0.6734 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 424/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6090 - binary_accuracy: 0.6768 - false_negatives_3: 177.0000 - val_loss: 0.6816 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 425/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6099 - binary_accuracy: 0.6812 - false_negatives_3: 163.0000 - val_loss: 0.6808 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 426/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6121 - binary_accuracy: 0.6768 - false_negatives_3: 167.0000 - val_loss: 0.6795 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 427/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6080 - binary_accuracy: 0.6826 - false_negatives_3: 157.0000 - val_loss: 0.6748 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 428/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6201 - binary_accuracy: 0.6681 - false_negatives_3: 167.0000 - val_loss: 0.6843 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 429/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6118 - binary_accuracy: 0.6884 - false_negatives_3: 178.0000 - val_loss: 0.6738 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 430/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6197 - binary_accuracy: 0.6652 - false_negatives_3: 168.0000 - val_loss: 0.6797 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 431/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6153 - binary_accuracy: 0.6652 - false_negatives_3: 174.0000 - val_loss: 0.6770 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 432/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6114 - binary_accuracy: 0.6841 - false_negatives_3: 168.0000 - val_loss: 20.8265 - val_binary_accuracy: 0.5739 - val_false_negatives_3: 69.0000\n",
            "Epoch 433/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6129 - binary_accuracy: 0.6710 - false_negatives_3: 168.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 434/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6142 - binary_accuracy: 0.6899 - false_negatives_3: 159.0000 - val_loss: 0.6760 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 435/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6136 - binary_accuracy: 0.6884 - false_negatives_3: 169.0000 - val_loss: 0.6710 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 436/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6097 - binary_accuracy: 0.6667 - false_negatives_3: 167.0000 - val_loss: 0.6766 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 437/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6087 - binary_accuracy: 0.7000 - false_negatives_3: 153.0000 - val_loss: 0.6819 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 438/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6240 - binary_accuracy: 0.6551 - false_negatives_3: 176.0000 - val_loss: 0.6664 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 439/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6073 - binary_accuracy: 0.6855 - false_negatives_3: 175.0000 - val_loss: 0.6749 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 440/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6070 - binary_accuracy: 0.6768 - false_negatives_3: 166.0000 - val_loss: 0.6861 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 441/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6048 - binary_accuracy: 0.6971 - false_negatives_3: 155.0000 - val_loss: 0.6864 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 442/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6197 - binary_accuracy: 0.6681 - false_negatives_3: 162.0000 - val_loss: 0.6748 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 443/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6069 - binary_accuracy: 0.6913 - false_negatives_3: 165.0000 - val_loss: 0.6734 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 444/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6125 - binary_accuracy: 0.6797 - false_negatives_3: 161.0000 - val_loss: 0.6770 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 445/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6183 - binary_accuracy: 0.6594 - false_negatives_3: 170.0000 - val_loss: 0.6751 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 446/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6068 - binary_accuracy: 0.6986 - false_negatives_3: 160.0000 - val_loss: 0.6813 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 447/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6099 - binary_accuracy: 0.6768 - false_negatives_3: 164.0000 - val_loss: 0.6840 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 448/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6032 - binary_accuracy: 0.6855 - false_negatives_3: 155.0000 - val_loss: 0.6870 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 449/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6109 - binary_accuracy: 0.6841 - false_negatives_3: 162.0000 - val_loss: 0.6797 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 450/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6095 - binary_accuracy: 0.6884 - false_negatives_3: 174.0000 - val_loss: 0.6803 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 451/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6092 - binary_accuracy: 0.6754 - false_negatives_3: 167.0000 - val_loss: 0.6824 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 452/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6127 - binary_accuracy: 0.6942 - false_negatives_3: 172.0000 - val_loss: 0.6713 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 453/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6122 - binary_accuracy: 0.6768 - false_negatives_3: 170.0000 - val_loss: 0.6723 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 454/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6205 - binary_accuracy: 0.6768 - false_negatives_3: 161.0000 - val_loss: 0.6733 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 455/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6157 - binary_accuracy: 0.6826 - false_negatives_3: 165.0000 - val_loss: 0.6698 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 456/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6116 - binary_accuracy: 0.6855 - false_negatives_3: 155.0000 - val_loss: 0.6637 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 457/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6168 - binary_accuracy: 0.6797 - false_negatives_3: 161.0000 - val_loss: 0.6716 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 458/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6098 - binary_accuracy: 0.6754 - false_negatives_3: 165.0000 - val_loss: 0.6697 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 459/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6172 - binary_accuracy: 0.6638 - false_negatives_3: 160.0000 - val_loss: 0.6768 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 460/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6165 - binary_accuracy: 0.6812 - false_negatives_3: 166.0000 - val_loss: 0.6790 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 461/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6168 - binary_accuracy: 0.6797 - false_negatives_3: 172.0000 - val_loss: 0.6773 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 462/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6120 - binary_accuracy: 0.6667 - false_negatives_3: 164.0000 - val_loss: 0.6785 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 463/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6074 - binary_accuracy: 0.6812 - false_negatives_3: 160.0000 - val_loss: 0.6792 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 464/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6146 - binary_accuracy: 0.6739 - false_negatives_3: 184.0000 - val_loss: 0.6828 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 465/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6110 - binary_accuracy: 0.6826 - false_negatives_3: 169.0000 - val_loss: 0.6840 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 466/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6093 - binary_accuracy: 0.6812 - false_negatives_3: 153.0000 - val_loss: 0.6869 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 467/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6084 - binary_accuracy: 0.6870 - false_negatives_3: 165.0000 - val_loss: 0.6847 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 468/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6113 - binary_accuracy: 0.6841 - false_negatives_3: 170.0000 - val_loss: 0.6770 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 469/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6092 - binary_accuracy: 0.6768 - false_negatives_3: 154.0000 - val_loss: 0.6725 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 470/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6150 - binary_accuracy: 0.6797 - false_negatives_3: 175.0000 - val_loss: 0.6752 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 471/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6182 - binary_accuracy: 0.6754 - false_negatives_3: 159.0000 - val_loss: 0.6722 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 472/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6062 - binary_accuracy: 0.6899 - false_negatives_3: 166.0000 - val_loss: 0.6808 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 473/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6074 - binary_accuracy: 0.6899 - false_negatives_3: 171.0000 - val_loss: 0.6774 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 474/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6159 - binary_accuracy: 0.6754 - false_negatives_3: 163.0000 - val_loss: 0.6743 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 475/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6044 - binary_accuracy: 0.6971 - false_negatives_3: 161.0000 - val_loss: 0.6699 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 476/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6044 - binary_accuracy: 0.6725 - false_negatives_3: 165.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 477/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6174 - binary_accuracy: 0.6739 - false_negatives_3: 172.0000 - val_loss: 0.6787 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 478/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6151 - binary_accuracy: 0.6826 - false_negatives_3: 159.0000 - val_loss: 0.6815 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 479/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6142 - binary_accuracy: 0.6783 - false_negatives_3: 171.0000 - val_loss: 0.6797 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 480/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6149 - binary_accuracy: 0.6768 - false_negatives_3: 168.0000 - val_loss: 0.6865 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 481/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6175 - binary_accuracy: 0.6783 - false_negatives_3: 162.0000 - val_loss: 0.6780 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 482/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6183 - binary_accuracy: 0.6580 - false_negatives_3: 167.0000 - val_loss: 0.6747 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 483/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6103 - binary_accuracy: 0.6710 - false_negatives_3: 175.0000 - val_loss: 0.6742 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 484/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6111 - binary_accuracy: 0.6913 - false_negatives_3: 163.0000 - val_loss: 0.6805 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 485/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6130 - binary_accuracy: 0.6667 - false_negatives_3: 180.0000 - val_loss: 0.6809 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 486/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6143 - binary_accuracy: 0.6652 - false_negatives_3: 168.0000 - val_loss: 0.6743 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 487/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6137 - binary_accuracy: 0.6739 - false_negatives_3: 159.0000 - val_loss: 0.6776 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 488/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6168 - binary_accuracy: 0.6797 - false_negatives_3: 160.0000 - val_loss: 0.6805 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 489/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6076 - binary_accuracy: 0.6681 - false_negatives_3: 170.0000 - val_loss: 0.6783 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 490/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6024 - binary_accuracy: 0.6870 - false_negatives_3: 160.0000 - val_loss: 0.6806 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 491/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6122 - binary_accuracy: 0.6667 - false_negatives_3: 166.0000 - val_loss: 0.6776 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 492/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6114 - binary_accuracy: 0.6768 - false_negatives_3: 159.0000 - val_loss: 0.6819 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 493/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6178 - binary_accuracy: 0.6681 - false_negatives_3: 182.0000 - val_loss: 0.6791 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 494/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6131 - binary_accuracy: 0.6754 - false_negatives_3: 148.0000 - val_loss: 0.6770 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 495/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6113 - binary_accuracy: 0.6725 - false_negatives_3: 167.0000 - val_loss: 0.6784 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 496/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6093 - binary_accuracy: 0.6667 - false_negatives_3: 168.0000 - val_loss: 0.6802 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 497/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6189 - binary_accuracy: 0.6681 - false_negatives_3: 162.0000 - val_loss: 0.6769 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 498/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6143 - binary_accuracy: 0.6797 - false_negatives_3: 164.0000 - val_loss: 0.6835 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 499/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6087 - binary_accuracy: 0.6957 - false_negatives_3: 162.0000 - val_loss: 0.6786 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 500/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6133 - binary_accuracy: 0.6899 - false_negatives_3: 153.0000 - val_loss: 0.6847 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 501/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6197 - binary_accuracy: 0.6609 - false_negatives_3: 175.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 502/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6105 - binary_accuracy: 0.6783 - false_negatives_3: 173.0000 - val_loss: 0.6748 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 503/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6114 - binary_accuracy: 0.6710 - false_negatives_3: 175.0000 - val_loss: 0.6738 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 504/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6087 - binary_accuracy: 0.6841 - false_negatives_3: 154.0000 - val_loss: 0.6692 - val_binary_accuracy: 0.6609 - val_false_negatives_3: 78.0000\n",
            "Epoch 505/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6175 - binary_accuracy: 0.6739 - false_negatives_3: 170.0000 - val_loss: 0.6687 - val_binary_accuracy: 0.6609 - val_false_negatives_3: 78.0000\n",
            "Epoch 506/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6127 - binary_accuracy: 0.6725 - false_negatives_3: 180.0000 - val_loss: 0.6762 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 507/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6152 - binary_accuracy: 0.6768 - false_negatives_3: 183.0000 - val_loss: 0.6806 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 508/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6099 - binary_accuracy: 0.6812 - false_negatives_3: 171.0000 - val_loss: 0.6810 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 509/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6127 - binary_accuracy: 0.6725 - false_negatives_3: 164.0000 - val_loss: 0.6746 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 510/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6194 - binary_accuracy: 0.6609 - false_negatives_3: 158.0000 - val_loss: 0.6697 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 511/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6121 - binary_accuracy: 0.6957 - false_negatives_3: 161.0000 - val_loss: 0.6742 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 512/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6193 - binary_accuracy: 0.6696 - false_negatives_3: 158.0000 - val_loss: 0.6732 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 513/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6147 - binary_accuracy: 0.6696 - false_negatives_3: 174.0000 - val_loss: 0.6668 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 514/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6134 - binary_accuracy: 0.6754 - false_negatives_3: 158.0000 - val_loss: 0.6709 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 515/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6137 - binary_accuracy: 0.6522 - false_negatives_3: 180.0000 - val_loss: 0.6773 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 516/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6099 - binary_accuracy: 0.6826 - false_negatives_3: 159.0000 - val_loss: 0.6751 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 517/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6101 - binary_accuracy: 0.6754 - false_negatives_3: 161.0000 - val_loss: 0.6779 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 518/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6150 - binary_accuracy: 0.6812 - false_negatives_3: 161.0000 - val_loss: 0.6756 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 519/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6220 - binary_accuracy: 0.6551 - false_negatives_3: 170.0000 - val_loss: 0.6720 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 520/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6134 - binary_accuracy: 0.6754 - false_negatives_3: 157.0000 - val_loss: 0.6654 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 521/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6155 - binary_accuracy: 0.6652 - false_negatives_3: 177.0000 - val_loss: 0.6703 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 522/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6171 - binary_accuracy: 0.6623 - false_negatives_3: 169.0000 - val_loss: 0.6705 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 523/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6100 - binary_accuracy: 0.6783 - false_negatives_3: 160.0000 - val_loss: 0.6736 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 524/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6129 - binary_accuracy: 0.6783 - false_negatives_3: 175.0000 - val_loss: 0.6822 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 525/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6128 - binary_accuracy: 0.6739 - false_negatives_3: 157.0000 - val_loss: 0.6742 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 526/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6083 - binary_accuracy: 0.6812 - false_negatives_3: 163.0000 - val_loss: 0.6766 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 527/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6076 - binary_accuracy: 0.6870 - false_negatives_3: 165.0000 - val_loss: 0.6728 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 528/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6195 - binary_accuracy: 0.6681 - false_negatives_3: 163.0000 - val_loss: 0.6743 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 529/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6106 - binary_accuracy: 0.6812 - false_negatives_3: 170.0000 - val_loss: 0.6751 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 530/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6160 - binary_accuracy: 0.6725 - false_negatives_3: 182.0000 - val_loss: 0.6735 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 531/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6153 - binary_accuracy: 0.6768 - false_negatives_3: 157.0000 - val_loss: 0.6792 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 532/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6114 - binary_accuracy: 0.6812 - false_negatives_3: 168.0000 - val_loss: 0.6762 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 533/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6184 - binary_accuracy: 0.6768 - false_negatives_3: 159.0000 - val_loss: 0.6762 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 534/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6150 - binary_accuracy: 0.6652 - false_negatives_3: 180.0000 - val_loss: 0.6845 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 535/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6135 - binary_accuracy: 0.6754 - false_negatives_3: 164.0000 - val_loss: 0.6727 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 536/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6057 - binary_accuracy: 0.6855 - false_negatives_3: 162.0000 - val_loss: 0.6800 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 537/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6111 - binary_accuracy: 0.6725 - false_negatives_3: 163.0000 - val_loss: 0.6839 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 538/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6164 - binary_accuracy: 0.6739 - false_negatives_3: 153.0000 - val_loss: 0.6772 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 539/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6118 - binary_accuracy: 0.6841 - false_negatives_3: 163.0000 - val_loss: 0.6770 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 540/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6208 - binary_accuracy: 0.6594 - false_negatives_3: 162.0000 - val_loss: 0.6641 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 541/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6097 - binary_accuracy: 0.6710 - false_negatives_3: 172.0000 - val_loss: 0.6676 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 542/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6160 - binary_accuracy: 0.6783 - false_negatives_3: 182.0000 - val_loss: 0.6693 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 543/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6131 - binary_accuracy: 0.6739 - false_negatives_3: 154.0000 - val_loss: 0.6777 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 544/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6231 - binary_accuracy: 0.6522 - false_negatives_3: 176.0000 - val_loss: 0.6760 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 545/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6095 - binary_accuracy: 0.6710 - false_negatives_3: 168.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 546/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6112 - binary_accuracy: 0.6696 - false_negatives_3: 165.0000 - val_loss: 0.6767 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 547/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6112 - binary_accuracy: 0.6754 - false_negatives_3: 162.0000 - val_loss: 0.6794 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 548/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6184 - binary_accuracy: 0.6638 - false_negatives_3: 166.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 549/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6144 - binary_accuracy: 0.6667 - false_negatives_3: 170.0000 - val_loss: 0.6723 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 550/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6144 - binary_accuracy: 0.6739 - false_negatives_3: 171.0000 - val_loss: 0.6720 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 551/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6096 - binary_accuracy: 0.6667 - false_negatives_3: 167.0000 - val_loss: 0.6731 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 552/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6126 - binary_accuracy: 0.6797 - false_negatives_3: 171.0000 - val_loss: 0.6809 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 553/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6086 - binary_accuracy: 0.6957 - false_negatives_3: 168.0000 - val_loss: 0.6701 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 554/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6112 - binary_accuracy: 0.6754 - false_negatives_3: 154.0000 - val_loss: 0.6710 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 555/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6122 - binary_accuracy: 0.6768 - false_negatives_3: 171.0000 - val_loss: 0.6701 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 556/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6197 - binary_accuracy: 0.6638 - false_negatives_3: 170.0000 - val_loss: 0.6749 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 557/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6102 - binary_accuracy: 0.6768 - false_negatives_3: 165.0000 - val_loss: 0.6786 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 558/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6253 - binary_accuracy: 0.6580 - false_negatives_3: 171.0000 - val_loss: 0.6749 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 559/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6145 - binary_accuracy: 0.6696 - false_negatives_3: 160.0000 - val_loss: 0.6674 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 560/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6150 - binary_accuracy: 0.6710 - false_negatives_3: 176.0000 - val_loss: 0.6756 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 561/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6188 - binary_accuracy: 0.6536 - false_negatives_3: 174.0000 - val_loss: 0.6644 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 562/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6228 - binary_accuracy: 0.6652 - false_negatives_3: 171.0000 - val_loss: 0.6674 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 563/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6155 - binary_accuracy: 0.6652 - false_negatives_3: 180.0000 - val_loss: 0.6697 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 564/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6134 - binary_accuracy: 0.6638 - false_negatives_3: 163.0000 - val_loss: 0.6692 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 565/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6195 - binary_accuracy: 0.6536 - false_negatives_3: 162.0000 - val_loss: 0.6744 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 566/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6187 - binary_accuracy: 0.6681 - false_negatives_3: 177.0000 - val_loss: 0.6690 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 567/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6163 - binary_accuracy: 0.6609 - false_negatives_3: 171.0000 - val_loss: 0.6849 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 568/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6133 - binary_accuracy: 0.6768 - false_negatives_3: 172.0000 - val_loss: 0.6729 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 569/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6092 - binary_accuracy: 0.6841 - false_negatives_3: 150.0000 - val_loss: 0.6751 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 570/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6071 - binary_accuracy: 0.6826 - false_negatives_3: 161.0000 - val_loss: 0.6778 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 571/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6238 - binary_accuracy: 0.6754 - false_negatives_3: 171.0000 - val_loss: 0.6744 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 572/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6124 - binary_accuracy: 0.6899 - false_negatives_3: 170.0000 - val_loss: 0.6779 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 573/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6139 - binary_accuracy: 0.6899 - false_negatives_3: 167.0000 - val_loss: 0.6734 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 574/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6137 - binary_accuracy: 0.6623 - false_negatives_3: 185.0000 - val_loss: 0.6809 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 575/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6110 - binary_accuracy: 0.6768 - false_negatives_3: 163.0000 - val_loss: 0.6751 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 576/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6162 - binary_accuracy: 0.6710 - false_negatives_3: 170.0000 - val_loss: 0.6737 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 577/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6158 - binary_accuracy: 0.6652 - false_negatives_3: 174.0000 - val_loss: 0.6708 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 578/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6108 - binary_accuracy: 0.6826 - false_negatives_3: 170.0000 - val_loss: 0.6825 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 579/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6079 - binary_accuracy: 0.6768 - false_negatives_3: 161.0000 - val_loss: 0.6807 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 580/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6165 - binary_accuracy: 0.6768 - false_negatives_3: 162.0000 - val_loss: 0.6815 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 581/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6133 - binary_accuracy: 0.6841 - false_negatives_3: 167.0000 - val_loss: 0.6829 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 582/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6195 - binary_accuracy: 0.6739 - false_negatives_3: 176.0000 - val_loss: 0.6810 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 583/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6184 - binary_accuracy: 0.6609 - false_negatives_3: 174.0000 - val_loss: 0.6746 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 584/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6076 - binary_accuracy: 0.6826 - false_negatives_3: 169.0000 - val_loss: 0.6729 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 585/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6171 - binary_accuracy: 0.6667 - false_negatives_3: 172.0000 - val_loss: 0.6781 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 586/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6130 - binary_accuracy: 0.6696 - false_negatives_3: 171.0000 - val_loss: 0.6704 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 587/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6089 - binary_accuracy: 0.6725 - false_negatives_3: 161.0000 - val_loss: 0.6740 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 588/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6134 - binary_accuracy: 0.6696 - false_negatives_3: 165.0000 - val_loss: 0.6712 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 589/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6173 - binary_accuracy: 0.6681 - false_negatives_3: 168.0000 - val_loss: 0.6617 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 590/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6179 - binary_accuracy: 0.6841 - false_negatives_3: 171.0000 - val_loss: 0.6700 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 591/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6105 - binary_accuracy: 0.6797 - false_negatives_3: 168.0000 - val_loss: 0.6712 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 592/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6001 - binary_accuracy: 0.6913 - false_negatives_3: 161.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 593/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6207 - binary_accuracy: 0.6725 - false_negatives_3: 165.0000 - val_loss: 0.6741 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 594/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6212 - binary_accuracy: 0.6681 - false_negatives_3: 175.0000 - val_loss: 0.6708 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 595/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6197 - binary_accuracy: 0.6710 - false_negatives_3: 164.0000 - val_loss: 0.6719 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 596/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6226 - binary_accuracy: 0.6739 - false_negatives_3: 172.0000 - val_loss: 0.6678 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 597/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6089 - binary_accuracy: 0.6855 - false_negatives_3: 176.0000 - val_loss: 0.6645 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 598/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6090 - binary_accuracy: 0.6855 - false_negatives_3: 168.0000 - val_loss: 0.6592 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 599/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6142 - binary_accuracy: 0.6739 - false_negatives_3: 159.0000 - val_loss: 0.6693 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 600/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6209 - binary_accuracy: 0.6797 - false_negatives_3: 168.0000 - val_loss: 0.6610 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 601/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6140 - binary_accuracy: 0.6726 - false_negatives_3: 164.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 131ms/step - loss: 0.6101 - binary_accuracy: 0.6768 - false_negatives_3: 166.0000 - val_loss: 0.6573 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 602/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6110 - binary_accuracy: 0.6913 - false_negatives_3: 171.0000 - val_loss: 0.6638 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 603/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6166 - binary_accuracy: 0.6681 - false_negatives_3: 178.0000 - val_loss: 0.6679 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 604/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6183 - binary_accuracy: 0.6681 - false_negatives_3: 183.0000 - val_loss: 0.6728 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 605/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6105 - binary_accuracy: 0.6826 - false_negatives_3: 170.0000 - val_loss: 0.6712 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 606/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6132 - binary_accuracy: 0.6667 - false_negatives_3: 170.0000 - val_loss: 0.6752 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 607/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6160 - binary_accuracy: 0.6696 - false_negatives_3: 158.0000 - val_loss: 0.6786 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 608/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6195 - binary_accuracy: 0.6623 - false_negatives_3: 178.0000 - val_loss: 0.6769 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 609/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6183 - binary_accuracy: 0.6580 - false_negatives_3: 163.0000 - val_loss: 0.6721 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 610/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6243 - binary_accuracy: 0.6623 - false_negatives_3: 177.0000 - val_loss: 0.6671 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 611/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6165 - binary_accuracy: 0.6768 - false_negatives_3: 169.0000 - val_loss: 0.6700 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 612/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6141 - binary_accuracy: 0.6667 - false_negatives_3: 185.0000 - val_loss: 0.6761 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 613/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6237 - binary_accuracy: 0.6754 - false_negatives_3: 160.0000 - val_loss: 0.6707 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 614/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6147 - binary_accuracy: 0.6710 - false_negatives_3: 180.0000 - val_loss: 0.6736 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 615/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6126 - binary_accuracy: 0.6899 - false_negatives_3: 163.0000 - val_loss: 0.6718 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 616/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6104 - binary_accuracy: 0.6710 - false_negatives_3: 170.0000 - val_loss: 0.6689 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 617/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6111 - binary_accuracy: 0.6768 - false_negatives_3: 173.0000 - val_loss: 0.6693 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 618/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6186 - binary_accuracy: 0.6768 - false_negatives_3: 171.0000 - val_loss: 0.6728 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 619/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6135 - binary_accuracy: 0.6754 - false_negatives_3: 171.0000 - val_loss: 0.6683 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 620/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6171 - binary_accuracy: 0.6710 - false_negatives_3: 182.0000 - val_loss: 0.6637 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 621/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6088 - binary_accuracy: 0.6725 - false_negatives_3: 159.0000 - val_loss: 0.6766 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 622/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6178 - binary_accuracy: 0.6725 - false_negatives_3: 180.0000 - val_loss: 0.6736 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 623/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6199 - binary_accuracy: 0.6638 - false_negatives_3: 168.0000 - val_loss: 0.6682 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 624/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6164 - binary_accuracy: 0.6667 - false_negatives_3: 169.0000 - val_loss: 0.6709 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 625/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6180 - binary_accuracy: 0.6638 - false_negatives_3: 176.0000 - val_loss: 0.6664 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 626/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6180 - binary_accuracy: 0.6739 - false_negatives_3: 172.0000 - val_loss: 0.6679 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 627/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6107 - binary_accuracy: 0.6768 - false_negatives_3: 163.0000 - val_loss: 0.6638 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 628/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6218 - binary_accuracy: 0.6725 - false_negatives_3: 171.0000 - val_loss: 0.6632 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 629/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6268 - binary_accuracy: 0.6667 - false_negatives_3: 175.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 135ms/step - loss: 0.6268 - binary_accuracy: 0.6667 - false_negatives_3: 175.0000 - val_loss: 0.6566 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 630/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6212 - binary_accuracy: 0.6768 - false_negatives_3: 183.0000 - val_loss: 0.6604 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 631/700\n",
            "22/22 [==============================] - 1s 42ms/step - loss: 0.6265 - binary_accuracy: 0.6754 - false_negatives_3: 185.0000 - val_loss: 0.6628 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 632/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6039 - binary_accuracy: 0.6884 - false_negatives_3: 160.0000 - val_loss: 0.6606 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 633/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6180 - binary_accuracy: 0.6797 - false_negatives_3: 169.0000 - val_loss: 0.6705 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 634/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6240 - binary_accuracy: 0.6667 - false_negatives_3: 167.0000 - val_loss: 0.6599 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 635/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6286 - binary_accuracy: 0.6652 - false_negatives_3: 186.0000 - val_loss: 0.6670 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 636/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 0.6290 - binary_accuracy: 0.6660 - false_negatives_3: 137.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 105ms/step - loss: 0.6239 - binary_accuracy: 0.6652 - false_negatives_3: 182.0000 - val_loss: 0.6554 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 637/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6135 - binary_accuracy: 0.6710 - false_negatives_3: 177.0000 - val_loss: 0.6592 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 638/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.6277 - binary_accuracy: 0.6342 - false_negatives_3: 160.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 117ms/step - loss: 0.6251 - binary_accuracy: 0.6449 - false_negatives_3: 199.0000 - val_loss: 0.6534 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 639/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6182 - binary_accuracy: 0.6739 - false_negatives_3: 182.0000 - val_loss: 0.6551 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 640/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6137 - binary_accuracy: 0.6899 - false_negatives_3: 153.0000 - val_loss: 0.6619 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 641/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6131 - binary_accuracy: 0.6841 - false_negatives_3: 174.0000 - val_loss: 0.6643 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 642/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6087 - binary_accuracy: 0.6797 - false_negatives_3: 170.0000 - val_loss: 0.6691 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 643/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6194 - binary_accuracy: 0.6725 - false_negatives_3: 172.0000 - val_loss: 0.6633 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 644/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6214 - binary_accuracy: 0.6826 - false_negatives_3: 163.0000 - val_loss: 0.6628 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 645/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6243 - binary_accuracy: 0.6609 - false_negatives_3: 184.0000 - val_loss: 0.6610 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 646/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6155 - binary_accuracy: 0.6826 - false_negatives_3: 164.0000 - val_loss: 0.6612 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 647/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6121 - binary_accuracy: 0.6710 - false_negatives_3: 179.0000 - val_loss: 0.6636 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 648/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6232 - binary_accuracy: 0.6623 - false_negatives_3: 184.0000 - val_loss: 0.6587 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 649/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6264 - binary_accuracy: 0.6493 - false_negatives_3: 192.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 161ms/step - loss: 0.6264 - binary_accuracy: 0.6493 - false_negatives_3: 192.0000 - val_loss: 0.6495 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 650/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6179 - binary_accuracy: 0.6855 - false_negatives_3: 176.0000 - val_loss: 0.6571 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 651/700\n",
            "22/22 [==============================] - 1s 43ms/step - loss: 0.6251 - binary_accuracy: 0.6696 - false_negatives_3: 174.0000 - val_loss: 0.6511 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 652/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6175 - binary_accuracy: 0.6652 - false_negatives_3: 176.0000 - val_loss: 0.6583 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 653/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6231 - binary_accuracy: 0.6522 - false_negatives_3: 190.0000 - val_loss: 0.6559 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 654/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6215 - binary_accuracy: 0.6580 - false_negatives_3: 187.0000 - val_loss: 0.6607 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 655/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6192 - binary_accuracy: 0.6681 - false_negatives_3: 190.0000 - val_loss: 0.6643 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 656/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6181 - binary_accuracy: 0.6667 - false_negatives_3: 179.0000 - val_loss: 0.6632 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 657/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6198 - binary_accuracy: 0.6449 - false_negatives_3: 184.0000 - val_loss: 0.6611 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 658/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6219 - binary_accuracy: 0.6638 - false_negatives_3: 161.0000 - val_loss: 0.6654 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 659/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6237 - binary_accuracy: 0.6507 - false_negatives_3: 182.0000 - val_loss: 0.6647 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 660/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6118 - binary_accuracy: 0.6812 - false_negatives_3: 176.0000 - val_loss: 0.6633 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 661/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6192 - binary_accuracy: 0.6681 - false_negatives_3: 171.0000 - val_loss: 0.6628 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 662/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6213 - binary_accuracy: 0.6667 - false_negatives_3: 172.0000 - val_loss: 0.6713 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 663/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6230 - binary_accuracy: 0.6565 - false_negatives_3: 191.0000 - val_loss: 0.6570 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 664/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6209 - binary_accuracy: 0.6638 - false_negatives_3: 177.0000 - val_loss: 0.6570 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 665/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6321 - binary_accuracy: 0.6493 - false_negatives_3: 182.0000 - val_loss: 0.6568 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 666/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6207 - binary_accuracy: 0.6638 - false_negatives_3: 191.0000 - val_loss: 0.6553 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 667/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6181 - binary_accuracy: 0.6493 - false_negatives_3: 195.0000 - val_loss: 0.6576 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 668/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6205 - binary_accuracy: 0.6870 - false_negatives_3: 158.0000 - val_loss: 0.6623 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 669/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6182 - binary_accuracy: 0.6638 - false_negatives_3: 182.0000 - val_loss: 0.6685 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 670/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6272 - binary_accuracy: 0.6551 - false_negatives_3: 172.0000 - val_loss: 0.6599 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 671/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6148 - binary_accuracy: 0.6667 - false_negatives_3: 183.0000 - val_loss: 0.6696 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 672/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6205 - binary_accuracy: 0.6725 - false_negatives_3: 175.0000 - val_loss: 0.6605 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 673/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6195 - binary_accuracy: 0.6841 - false_negatives_3: 177.0000 - val_loss: 0.6623 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 674/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6191 - binary_accuracy: 0.6696 - false_negatives_3: 170.0000 - val_loss: 0.6603 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 675/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6136 - binary_accuracy: 0.6826 - false_negatives_3: 165.0000 - val_loss: 0.6571 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 676/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6148 - binary_accuracy: 0.6681 - false_negatives_3: 172.0000 - val_loss: 0.6666 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 677/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6172 - binary_accuracy: 0.6638 - false_negatives_3: 167.0000 - val_loss: 0.6700 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 678/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6232 - binary_accuracy: 0.6565 - false_negatives_3: 185.0000 - val_loss: 0.6691 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 679/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6232 - binary_accuracy: 0.6667 - false_negatives_3: 172.0000 - val_loss: 0.6555 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 680/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6422 - binary_accuracy: 0.6232 - false_negatives_3: 211.0000 - val_loss: 0.6496 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 681/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6382 - binary_accuracy: 0.6398 - false_negatives_3: 189.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 110ms/step - loss: 0.6417 - binary_accuracy: 0.6391 - false_negatives_3: 212.0000 - val_loss: 0.6374 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 682/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6423 - binary_accuracy: 0.6377 - false_negatives_3: 219.0000 - val_loss: 0.6388 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 683/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6482 - binary_accuracy: 0.6116 - false_negatives_3: 226.0000 - val_loss: 0.6398 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 684/700\n",
            "22/22 [==============================] - 1s 40ms/step - loss: 0.6427 - binary_accuracy: 0.6406 - false_negatives_3: 231.0000 - val_loss: 0.6387 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 685/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6339 - binary_accuracy: 0.6290 - false_negatives_3: 226.0000 - val_loss: 0.6385 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 686/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6372 - binary_accuracy: 0.6174 - false_negatives_3: 227.0000 - val_loss: 0.6384 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 687/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6347 - binary_accuracy: 0.6478 - false_negatives_3: 237.0000 - val_loss: 0.6403 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 688/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6378 - binary_accuracy: 0.6261 - false_negatives_3: 238.0000 - val_loss: 0.6436 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 689/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6357 - binary_accuracy: 0.6377 - false_negatives_3: 238.0000 - val_loss: 0.6472 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 690/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6391 - binary_accuracy: 0.6319 - false_negatives_3: 219.0000 - val_loss: 0.6412 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 691/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6515 - binary_accuracy: 0.6348 - false_negatives_3: 240.0000 - val_loss: 0.6480 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 692/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6268 - binary_accuracy: 0.6420 - false_negatives_3: 242.0000 - val_loss: 0.6423 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 693/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6300 - binary_accuracy: 0.6493 - false_negatives_3: 235.0000 - val_loss: 0.6388 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 694/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6290 - binary_accuracy: 0.6281 - false_negatives_3: 219.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 107ms/step - loss: 0.6292 - binary_accuracy: 0.6304 - false_negatives_3: 235.0000 - val_loss: 0.6368 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 695/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6360 - binary_accuracy: 0.6362 - false_negatives_3: 241.0000 - val_loss: 0.6378 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 696/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6360 - binary_accuracy: 0.6464 - false_negatives_3: 231.0000 - val_loss: 0.6373 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 697/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6276 - binary_accuracy: 0.6551 - false_negatives_3: 218.0000 - val_loss: 0.6524 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 698/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6329 - binary_accuracy: 0.6319 - false_negatives_3: 223.0000 - val_loss: 0.6519 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 699/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6203 - binary_accuracy: 0.6435 - false_negatives_3: 224.0000 - val_loss: 0.6370 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n",
            "Epoch 700/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6307 - binary_accuracy: 0.6406 - false_negatives_3: 208.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_130608-ff4koyvd/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 108ms/step - loss: 0.6307 - binary_accuracy: 0.6406 - false_negatives_3: 208.0000 - val_loss: 0.6358 - val_binary_accuracy: 0.6565 - val_false_negatives_3: 79.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c9de8357730>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(model.history.history)[['loss','val_loss']].tail(100).plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "3_GS_HuqWhLn",
        "outputId": "66307e4a-7e7c-4789-ce39-5a61566942fe"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()"
      ],
      "metadata": {
        "id": "NDCkTu7EVOGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.add(Dense(units=35,activation='relu',kernel_initializer='GlorotNormal', kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model2.add(Dense(units=100,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "model2.add(Dense(units=200,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "model2.add(Dense(units=200,activation='relu',kernel_initializer='GlorotNormal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "model2.add(Dense(units=300,activation='relu',kernel_initializer='GlorotNormal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "model2.add(Dense(units=400,activation='relu',kernel_initializer='GlorotNormal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model2.add(Dense(units=1,activation='sigmoid'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mubNEAX-Z0IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy())"
      ],
      "metadata": {
        "id": "_YM-N7YgZ3Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = 'Startups',name = 'Second Trail')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "IGo1h5WKwDNf",
        "outputId": "98895837-a0e1-4a8d-9ebf-3692fafc56e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:j3t34j71) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███▁▁▁▂▂▂▂▃▃</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>472</td></tr><tr><td>best_val_loss</td><td>0.65024</td></tr><tr><td>epoch</td><td>202</td></tr><tr><td>loss</td><td>0.6795</td></tr><tr><td>val_loss</td><td>0.70898</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">desert-sound-1</strong> at: <a href='https://wandb.ai/ossm0394/Startups/runs/j3t34j71' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/j3t34j71</a><br/>Synced 5 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231002_092851-j3t34j71/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:j3t34j71). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231002_093823-asvpswb0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ossm0394/Startups/runs/asvpswb0' target=\"_blank\">Second Trail</a></strong> to <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">https://wandb.ai/ossm0394/Startups</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ossm0394/Startups/runs/asvpswb0' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/asvpswb0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ossm0394/Startups/runs/asvpswb0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c7e5a1aa7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(x = x_train,y = y_train,epochs = 700,validation_data = (x_test,y_test),callbacks = [WandbCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9oMgDiWpgyk",
        "outputId": "8580eaf7-75d8-4e88-a3ca-309c15e8c098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 39.6099"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 13s 371ms/step - loss: 39.5147 - val_loss: 35.5217\n",
            "Epoch 2/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 33.2804"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 261ms/step - loss: 32.8239 - val_loss: 29.6987\n",
            "Epoch 3/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 27.6898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 375ms/step - loss: 27.5298 - val_loss: 25.0633\n",
            "Epoch 4/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 23.4239"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 296ms/step - loss: 23.4239 - val_loss: 21.3662\n",
            "Epoch 5/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 20.1323"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 282ms/step - loss: 20.0094 - val_loss: 18.3232\n",
            "Epoch 6/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 17.3480"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 10s 457ms/step - loss: 17.2600 - val_loss: 15.8091\n",
            "Epoch 7/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 14.9500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 287ms/step - loss: 14.9272 - val_loss: 13.7303\n",
            "Epoch 8/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 13.0316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 300ms/step - loss: 12.9302 - val_loss: 11.9153\n",
            "Epoch 9/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 11.2345"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 351ms/step - loss: 11.2345 - val_loss: 10.3693\n",
            "Epoch 10/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 9.8737"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 285ms/step - loss: 9.7806 - val_loss: 9.0126\n",
            "Epoch 11/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 8.5128"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 307ms/step - loss: 8.4961 - val_loss: 7.8740\n",
            "Epoch 12/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 7.3990"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 358ms/step - loss: 7.3990 - val_loss: 6.9334\n",
            "Epoch 13/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 6.4640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 246ms/step - loss: 6.4254 - val_loss: 5.9505\n",
            "Epoch 14/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 5.6634"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 388ms/step - loss: 5.6026 - val_loss: 5.2110\n",
            "Epoch 15/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 4.8638"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 292ms/step - loss: 4.8638 - val_loss: 4.5355\n",
            "Epoch 16/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 4.2849"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 281ms/step - loss: 4.2632 - val_loss: 4.0045\n",
            "Epoch 17/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 3.7618"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 390ms/step - loss: 3.7562 - val_loss: 3.4988\n",
            "Epoch 18/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 3.3092"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 257ms/step - loss: 3.3023 - val_loss: 3.0967\n",
            "Epoch 19/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 2.9736"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 315ms/step - loss: 2.9362 - val_loss: 2.7564\n",
            "Epoch 20/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 2.6074"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 380ms/step - loss: 2.5997 - val_loss: 2.4510\n",
            "Epoch 21/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 2.3269"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 279ms/step - loss: 2.3200 - val_loss: 2.2089\n",
            "Epoch 22/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.1058"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 356ms/step - loss: 2.1058 - val_loss: 1.9990\n",
            "Epoch 23/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.8976"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 362ms/step - loss: 1.8993 - val_loss: 1.8440\n",
            "Epoch 24/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.7475"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 252ms/step - loss: 1.7518 - val_loss: 1.7042\n",
            "Epoch 25/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.6279"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 342ms/step - loss: 1.6302 - val_loss: 1.5913\n",
            "Epoch 26/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.5371"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 343ms/step - loss: 1.5303 - val_loss: 1.5014\n",
            "Epoch 27/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.4287"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 256ms/step - loss: 1.4287 - val_loss: 1.3936\n",
            "Epoch 28/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.3432"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 9s 428ms/step - loss: 1.3215 - val_loss: 1.3051\n",
            "Epoch 29/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.2720"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 252ms/step - loss: 1.2635 - val_loss: 1.2203\n",
            "Epoch 30/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.1785"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 337ms/step - loss: 1.1774 - val_loss: 1.1860\n",
            "Epoch 31/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.1309"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 375ms/step - loss: 1.1328 - val_loss: 1.1165\n",
            "Epoch 32/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.1033"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 300ms/step - loss: 1.0954 - val_loss: 1.0924\n",
            "Epoch 33/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.0872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 332ms/step - loss: 1.0855 - val_loss: 1.0654\n",
            "Epoch 34/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.0324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 320ms/step - loss: 1.0312 - val_loss: 1.0261\n",
            "Epoch 35/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.9962"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 295ms/step - loss: 0.9899 - val_loss: 0.9857\n",
            "Epoch 36/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 9s 432ms/step - loss: 0.9643 - val_loss: 0.9583\n",
            "Epoch 37/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.9433"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 316ms/step - loss: 0.9423 - val_loss: 0.9437\n",
            "Epoch 38/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.9239 - val_loss: 0.9754\n",
            "Epoch 39/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.9170 - val_loss: 0.9554\n",
            "Epoch 40/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.9295 - val_loss: 0.9646\n",
            "Epoch 41/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.9038"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 292ms/step - loss: 0.9071 - val_loss: 0.9187\n",
            "Epoch 42/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.8603"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 393ms/step - loss: 0.8614 - val_loss: 0.8695\n",
            "Epoch 43/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.8360 - val_loss: 0.8746\n",
            "Epoch 44/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.8338"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 252ms/step - loss: 0.8336 - val_loss: 0.8396\n",
            "Epoch 45/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.8305 - val_loss: 0.8467\n",
            "Epoch 46/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.8120 - val_loss: 0.8447\n",
            "Epoch 47/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.8218 - val_loss: 0.8695\n",
            "Epoch 48/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.7942 - val_loss: 0.8651\n",
            "Epoch 49/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8033"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 374ms/step - loss: 0.8033 - val_loss: 0.8330\n",
            "Epoch 50/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 309ms/step - loss: 0.8037 - val_loss: 0.8153\n",
            "Epoch 51/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7980"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 282ms/step - loss: 0.7975 - val_loss: 0.8081\n",
            "Epoch 52/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7730"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 400ms/step - loss: 0.7730 - val_loss: 0.7868\n",
            "Epoch 53/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.7699 - val_loss: 0.8077\n",
            "Epoch 54/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7826"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 255ms/step - loss: 0.7826 - val_loss: 0.7852\n",
            "Epoch 55/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.7641 - val_loss: 0.8145\n",
            "Epoch 56/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7462"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 373ms/step - loss: 0.7462 - val_loss: 0.7758\n",
            "Epoch 57/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7495"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 319ms/step - loss: 0.7495 - val_loss: 0.7599\n",
            "Epoch 58/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7442"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 252ms/step - loss: 0.7409 - val_loss: 0.7593\n",
            "Epoch 59/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.7262"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 403ms/step - loss: 0.7311 - val_loss: 0.7518\n",
            "Epoch 60/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.7360 - val_loss: 0.7548\n",
            "Epoch 61/700\n",
            "22/22 [==============================] - 1s 45ms/step - loss: 0.7268 - val_loss: 0.8018\n",
            "Epoch 62/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 245ms/step - loss: 0.7243 - val_loss: 0.7439\n",
            "Epoch 63/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7261 - val_loss: 0.7551\n",
            "Epoch 64/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.7357 - val_loss: 0.7944\n",
            "Epoch 65/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7304 - val_loss: 0.7860\n",
            "Epoch 66/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.7561 - val_loss: 0.7621\n",
            "Epoch 67/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.7354 - val_loss: 0.7514\n",
            "Epoch 68/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.7397 - val_loss: 0.7576\n",
            "Epoch 69/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.7342 - val_loss: 0.7866\n",
            "Epoch 70/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7239 - val_loss: 0.7515\n",
            "Epoch 71/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7320"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 375ms/step - loss: 0.7253 - val_loss: 0.7399\n",
            "Epoch 72/700\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.7233 - val_loss: 0.7773\n",
            "Epoch 73/700\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.7197 - val_loss: 0.7687\n",
            "Epoch 74/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.7118 - val_loss: 0.7457\n",
            "Epoch 75/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.7281 - val_loss: 0.7442\n",
            "Epoch 76/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7112 - val_loss: 0.7538\n",
            "Epoch 77/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7035"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 234ms/step - loss: 0.7035 - val_loss: 0.7271\n",
            "Epoch 78/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.7335 - val_loss: 0.7424\n",
            "Epoch 79/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.7324 - val_loss: 0.7448\n",
            "Epoch 80/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.7098 - val_loss: 0.7401\n",
            "Epoch 81/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6980 - val_loss: 0.7739\n",
            "Epoch 82/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.7080 - val_loss: 0.8041\n",
            "Epoch 83/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.7139 - val_loss: 0.7335\n",
            "Epoch 84/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7225 - val_loss: 0.7343\n",
            "Epoch 85/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.7152 - val_loss: 0.7441\n",
            "Epoch 86/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 385ms/step - loss: 0.7110 - val_loss: 0.7198\n",
            "Epoch 87/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.7035 - val_loss: 0.7292\n",
            "Epoch 88/700\n",
            "22/22 [==============================] - 1s 40ms/step - loss: 0.6856 - val_loss: 0.7464\n",
            "Epoch 89/700\n",
            "22/22 [==============================] - 1s 38ms/step - loss: 0.6919 - val_loss: 0.7622\n",
            "Epoch 90/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.7041 - val_loss: 0.7551\n",
            "Epoch 91/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.7067 - val_loss: 0.7666\n",
            "Epoch 92/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6938 - val_loss: 0.7254\n",
            "Epoch 93/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6861 - val_loss: 0.7457\n",
            "Epoch 94/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 240ms/step - loss: 0.6866 - val_loss: 0.7171\n",
            "Epoch 95/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6939"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 344ms/step - loss: 0.6888 - val_loss: 0.7071\n",
            "Epoch 96/700\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6773 - val_loss: 0.7111\n",
            "Epoch 97/700\n",
            "22/22 [==============================] - 1s 46ms/step - loss: 0.6864 - val_loss: 0.7141\n",
            "Epoch 98/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6984 - val_loss: 0.7653\n",
            "Epoch 99/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.7039 - val_loss: 0.7522\n",
            "Epoch 100/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6965 - val_loss: 0.7122\n",
            "Epoch 101/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6881 - val_loss: 0.7193\n",
            "Epoch 102/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.7020 - val_loss: 0.7375\n",
            "Epoch 103/700\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6940 - val_loss: 0.7262\n",
            "Epoch 104/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6785 - val_loss: 0.7180\n",
            "Epoch 105/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6912 - val_loss: 0.8257\n",
            "Epoch 106/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7057 - val_loss: 0.7211\n",
            "Epoch 107/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6929 - val_loss: 0.7082\n",
            "Epoch 108/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6829 - val_loss: 0.7073\n",
            "Epoch 109/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6855 - val_loss: 0.7214\n",
            "Epoch 110/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6805 - val_loss: 0.7135\n",
            "Epoch 111/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6766 - val_loss: 0.7210\n",
            "Epoch 112/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6825"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 253ms/step - loss: 0.6757 - val_loss: 0.6954\n",
            "Epoch 113/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6775 - val_loss: 0.7159\n",
            "Epoch 114/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6996 - val_loss: 0.7231\n",
            "Epoch 115/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6810 - val_loss: 0.7315\n",
            "Epoch 116/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6808 - val_loss: 0.7061\n",
            "Epoch 117/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6808 - val_loss: 0.7162\n",
            "Epoch 118/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6761 - val_loss: 0.7097\n",
            "Epoch 119/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6657 - val_loss: 0.7386\n",
            "Epoch 120/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6827 - val_loss: 0.7707\n",
            "Epoch 121/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6780 - val_loss: 0.7487\n",
            "Epoch 122/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6784 - val_loss: 0.7589\n",
            "Epoch 123/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6778 - val_loss: 0.7966\n",
            "Epoch 124/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6695 - val_loss: 0.7210\n",
            "Epoch 125/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6786 - val_loss: 0.7174\n",
            "Epoch 126/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6706 - val_loss: 0.7349\n",
            "Epoch 127/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6666 - val_loss: 0.7161\n",
            "Epoch 128/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6704 - val_loss: 0.7179\n",
            "Epoch 129/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6764 - val_loss: 0.7488\n",
            "Epoch 130/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6741 - val_loss: 0.8157\n",
            "Epoch 131/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6743 - val_loss: 0.7344\n",
            "Epoch 132/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6756 - val_loss: 0.7114\n",
            "Epoch 133/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6729 - val_loss: 0.7086\n",
            "Epoch 134/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6679"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 261ms/step - loss: 0.6679 - val_loss: 0.6943\n",
            "Epoch 135/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6882 - val_loss: 0.7352\n",
            "Epoch 136/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6794 - val_loss: 0.7792\n",
            "Epoch 137/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6791 - val_loss: 0.7625\n",
            "Epoch 138/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6806 - val_loss: 0.7207\n",
            "Epoch 139/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6691 - val_loss: 0.7508\n",
            "Epoch 140/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6678 - val_loss: 0.7056\n",
            "Epoch 141/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6807 - val_loss: 0.7200\n",
            "Epoch 142/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6884 - val_loss: 0.7448\n",
            "Epoch 143/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6876 - val_loss: 0.7298\n",
            "Epoch 144/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6733 - val_loss: 0.7030\n",
            "Epoch 145/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6731 - val_loss: 0.7326\n",
            "Epoch 146/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6755 - val_loss: 0.7062\n",
            "Epoch 147/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6827 - val_loss: 0.7517\n",
            "Epoch 148/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6749 - val_loss: 0.7492\n",
            "Epoch 149/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6892 - val_loss: 0.7418\n",
            "Epoch 150/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6869 - val_loss: 0.7347\n",
            "Epoch 151/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6814 - val_loss: 0.7006\n",
            "Epoch 152/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6870 - val_loss: 0.7132\n",
            "Epoch 153/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6816 - val_loss: 0.7024\n",
            "Epoch 154/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6829 - val_loss: 0.7345\n",
            "Epoch 155/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6831 - val_loss: 0.6975\n",
            "Epoch 156/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6692 - val_loss: 0.7279\n",
            "Epoch 157/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6741 - val_loss: 0.7233\n",
            "Epoch 158/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6683 - val_loss: 0.7140\n",
            "Epoch 159/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6884 - val_loss: 0.7463\n",
            "Epoch 160/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6723 - val_loss: 0.7546\n",
            "Epoch 161/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6856 - val_loss: 0.7203\n",
            "Epoch 162/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6742 - val_loss: 0.7576\n",
            "Epoch 163/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6722 - val_loss: 0.7449\n",
            "Epoch 164/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6899 - val_loss: 0.7204\n",
            "Epoch 165/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6771 - val_loss: 0.7181\n",
            "Epoch 166/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6727 - val_loss: 0.7001\n",
            "Epoch 167/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6632 - val_loss: 0.7959\n",
            "Epoch 168/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6757 - val_loss: 0.7643\n",
            "Epoch 169/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6877 - val_loss: 0.7128\n",
            "Epoch 170/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6778 - val_loss: 0.7038\n",
            "Epoch 171/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6745 - val_loss: 0.7248\n",
            "Epoch 172/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6767 - val_loss: 0.7432\n",
            "Epoch 173/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6848 - val_loss: 0.7631\n",
            "Epoch 174/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6934 - val_loss: 0.7397\n",
            "Epoch 175/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6895 - val_loss: 0.7664\n",
            "Epoch 176/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6689 - val_loss: 0.7072\n",
            "Epoch 177/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6710 - val_loss: 0.7103\n",
            "Epoch 178/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 0.6762"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 275ms/step - loss: 0.6721 - val_loss: 0.6940\n",
            "Epoch 179/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6649"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 361ms/step - loss: 0.6680 - val_loss: 0.6939\n",
            "Epoch 180/700\n",
            "22/22 [==============================] - 1s 39ms/step - loss: 0.6825 - val_loss: 0.7178\n",
            "Epoch 181/700\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.6802 - val_loss: 0.7113\n",
            "Epoch 182/700\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6775 - val_loss: 0.7166\n",
            "Epoch 183/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6846 - val_loss: 0.7563\n",
            "Epoch 184/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6678 - val_loss: 0.7002\n",
            "Epoch 185/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6958 - val_loss: 0.7449\n",
            "Epoch 186/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6872 - val_loss: 0.7229\n",
            "Epoch 187/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6664 - val_loss: 0.7010\n",
            "Epoch 188/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6695 - val_loss: 0.7218\n",
            "Epoch 189/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6870 - val_loss: 0.7273\n",
            "Epoch 190/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6901 - val_loss: 0.7037\n",
            "Epoch 191/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6712 - val_loss: 0.7045\n",
            "Epoch 192/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6606 - val_loss: 0.7040\n",
            "Epoch 193/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6753 - val_loss: 0.7723\n",
            "Epoch 194/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.7091 - val_loss: 0.7335\n",
            "Epoch 195/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7044 - val_loss: 0.7411\n",
            "Epoch 196/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6821 - val_loss: 0.7359\n",
            "Epoch 197/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6871 - val_loss: 0.7310\n",
            "Epoch 198/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6786 - val_loss: 0.7077\n",
            "Epoch 199/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6817 - val_loss: 0.7027\n",
            "Epoch 200/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6743 - val_loss: 0.6980\n",
            "Epoch 201/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6800 - val_loss: 0.7153\n",
            "Epoch 202/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6886 - val_loss: 0.7222\n",
            "Epoch 203/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6817 - val_loss: 0.6997\n",
            "Epoch 204/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6778 - val_loss: 0.7441\n",
            "Epoch 205/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6783 - val_loss: 0.7004\n",
            "Epoch 206/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6695 - val_loss: 0.7279\n",
            "Epoch 207/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6906 - val_loss: 0.7159\n",
            "Epoch 208/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6745 - val_loss: 0.6994\n",
            "Epoch 209/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6884 - val_loss: 0.7661\n",
            "Epoch 210/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6915 - val_loss: 0.7180\n",
            "Epoch 211/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6812 - val_loss: 0.7059\n",
            "Epoch 212/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6796 - val_loss: 0.7488\n",
            "Epoch 213/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6701 - val_loss: 0.7016\n",
            "Epoch 214/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6795 - val_loss: 0.7318\n",
            "Epoch 215/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6734 - val_loss: 0.6971\n",
            "Epoch 216/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6662 - val_loss: 0.7004\n",
            "Epoch 217/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6535"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 356ms/step - loss: 0.6568 - val_loss: 0.6907\n",
            "Epoch 218/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6758 - val_loss: 0.7348\n",
            "Epoch 219/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6808 - val_loss: 0.7361\n",
            "Epoch 220/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6819 - val_loss: 0.7076\n",
            "Epoch 221/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6685 - val_loss: 0.7037\n",
            "Epoch 222/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6519 - val_loss: 0.7198\n",
            "Epoch 223/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6818 - val_loss: 0.6985\n",
            "Epoch 224/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6863 - val_loss: 0.7164\n",
            "Epoch 225/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6736 - val_loss: 0.7303\n",
            "Epoch 226/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6854 - val_loss: 0.6994\n",
            "Epoch 227/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6759 - val_loss: 0.7059\n",
            "Epoch 228/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6615 - val_loss: 0.7282\n",
            "Epoch 229/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6771 - val_loss: 0.7105\n",
            "Epoch 230/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6849 - val_loss: 0.7069\n",
            "Epoch 231/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6841 - val_loss: 0.7256\n",
            "Epoch 232/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6749 - val_loss: 0.7041\n",
            "Epoch 233/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6762 - val_loss: 0.7043\n",
            "Epoch 234/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6762 - val_loss: 0.7068\n",
            "Epoch 235/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6751 - val_loss: 0.7158\n",
            "Epoch 236/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6706 - val_loss: 0.7041\n",
            "Epoch 237/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6944 - val_loss: 0.7259\n",
            "Epoch 238/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6775 - val_loss: 0.7204\n",
            "Epoch 239/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6708 - val_loss: 0.7065\n",
            "Epoch 240/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6722 - val_loss: 0.7123\n",
            "Epoch 241/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6725 - val_loss: 0.7289\n",
            "Epoch 242/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6785 - val_loss: 0.7064\n",
            "Epoch 243/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6860 - val_loss: 0.7036\n",
            "Epoch 244/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6663 - val_loss: 0.7258\n",
            "Epoch 245/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6741 - val_loss: 0.7103\n",
            "Epoch 246/700\n",
            "22/22 [==============================] - 1s 40ms/step - loss: 0.6851 - val_loss: 0.7168\n",
            "Epoch 247/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6721 - val_loss: 0.7250\n",
            "Epoch 248/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6720 - val_loss: 0.7117\n",
            "Epoch 249/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6844 - val_loss: 0.7780\n",
            "Epoch 250/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6795 - val_loss: 0.7266\n",
            "Epoch 251/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6687"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 288ms/step - loss: 0.6687 - val_loss: 0.6907\n",
            "Epoch 252/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6698 - val_loss: 0.7043\n",
            "Epoch 253/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6705 - val_loss: 0.6940\n",
            "Epoch 254/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6794 - val_loss: 0.7049\n",
            "Epoch 255/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6711 - val_loss: 0.7158\n",
            "Epoch 256/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6665 - val_loss: 0.6952\n",
            "Epoch 257/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6704 - val_loss: 0.7198\n",
            "Epoch 258/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6693 - val_loss: 0.7204\n",
            "Epoch 259/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6773 - val_loss: 0.7095\n",
            "Epoch 260/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6742 - val_loss: 0.7224\n",
            "Epoch 261/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6804 - val_loss: 0.7406\n",
            "Epoch 262/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6836 - val_loss: 0.7105\n",
            "Epoch 263/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6667 - val_loss: 0.6962\n",
            "Epoch 264/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6769 - val_loss: 0.6995\n",
            "Epoch 265/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6822 - val_loss: 0.7357\n",
            "Epoch 266/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6584 - val_loss: 0.7023\n",
            "Epoch 267/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6890 - val_loss: 0.7094\n",
            "Epoch 268/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6644 - val_loss: 0.7185\n",
            "Epoch 269/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6705 - val_loss: 0.7118\n",
            "Epoch 270/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6784 - val_loss: 0.7619\n",
            "Epoch 271/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6793 - val_loss: 0.6947\n",
            "Epoch 272/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6739 - val_loss: 0.7087\n",
            "Epoch 273/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6637 - val_loss: 0.6981\n",
            "Epoch 274/700\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6702 - val_loss: 0.7103\n",
            "Epoch 275/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6551 - val_loss: 0.7023\n",
            "Epoch 276/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6645 - val_loss: 0.6922\n",
            "Epoch 277/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6651 - val_loss: 0.7169\n",
            "Epoch 278/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6809 - val_loss: 0.6935\n",
            "Epoch 279/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6716 - val_loss: 0.7032\n",
            "Epoch 280/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6650 - val_loss: 0.7159\n",
            "Epoch 281/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6615 - val_loss: 0.7069\n",
            "Epoch 282/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6740 - val_loss: 0.7006\n",
            "Epoch 283/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6895 - val_loss: 0.7243\n",
            "Epoch 284/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6965 - val_loss: 0.7450\n",
            "Epoch 285/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6673 - val_loss: 0.7103\n",
            "Epoch 286/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6735 - val_loss: 0.7158\n",
            "Epoch 287/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6765 - val_loss: 0.6951\n",
            "Epoch 288/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6718 - val_loss: 0.7209\n",
            "Epoch 289/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6628 - val_loss: 0.7131\n",
            "Epoch 290/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6656 - val_loss: 0.7269\n",
            "Epoch 291/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6772 - val_loss: 0.7783\n",
            "Epoch 292/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6678 - val_loss: 0.7344\n",
            "Epoch 293/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6810 - val_loss: 0.7315\n",
            "Epoch 294/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6744 - val_loss: 0.7044\n",
            "Epoch 295/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6686 - val_loss: 0.6977\n",
            "Epoch 296/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6687 - val_loss: 0.7169\n",
            "Epoch 297/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6619 - val_loss: 0.7018\n",
            "Epoch 298/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6738 - val_loss: 0.6952\n",
            "Epoch 299/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6693 - val_loss: 0.6999\n",
            "Epoch 300/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6777 - val_loss: 0.7543\n",
            "Epoch 301/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6818 - val_loss: 0.7223\n",
            "Epoch 302/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6661 - val_loss: 0.7187\n",
            "Epoch 303/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6672 - val_loss: 0.7558\n",
            "Epoch 304/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6724 - val_loss: 0.7298\n",
            "Epoch 305/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6760 - val_loss: 0.7037\n",
            "Epoch 306/700\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6592 - val_loss: 0.7355\n",
            "Epoch 307/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6709 - val_loss: 0.7413\n",
            "Epoch 308/700\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6755 - val_loss: 0.7040\n",
            "Epoch 309/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6528 - val_loss: 0.7380\n",
            "Epoch 310/700\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6693 - val_loss: 0.7128\n",
            "Epoch 311/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 12s 564ms/step - loss: 0.6665 - val_loss: 0.6896\n",
            "Epoch 312/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6680 - val_loss: 0.7068\n",
            "Epoch 313/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6522 - val_loss: 0.6917\n",
            "Epoch 314/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6591 - val_loss: 0.7027\n",
            "Epoch 315/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6568 - val_loss: 0.7148\n",
            "Epoch 316/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6823 - val_loss: 0.7129\n",
            "Epoch 317/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6600 - val_loss: 0.7243\n",
            "Epoch 318/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6664 - val_loss: 0.7511\n",
            "Epoch 319/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6730 - val_loss: 0.7261\n",
            "Epoch 320/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6726 - val_loss: 0.6980\n",
            "Epoch 321/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6589 - val_loss: 0.7185\n",
            "Epoch 322/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6783 - val_loss: 0.7066\n",
            "Epoch 323/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6706 - val_loss: 0.7101\n",
            "Epoch 324/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6826 - val_loss: 0.6959\n",
            "Epoch 325/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6824 - val_loss: 0.7153\n",
            "Epoch 326/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6530 - val_loss: 0.7238\n",
            "Epoch 327/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6794 - val_loss: 0.6996\n",
            "Epoch 328/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6767 - val_loss: 0.7085\n",
            "Epoch 329/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6644 - val_loss: 0.7107\n",
            "Epoch 330/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6700 - val_loss: 0.6909\n",
            "Epoch 331/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6727 - val_loss: 0.7032\n",
            "Epoch 332/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6574 - val_loss: 0.6985\n",
            "Epoch 333/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6635 - val_loss: 0.7010\n",
            "Epoch 334/700\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6645 - val_loss: 0.7005\n",
            "Epoch 335/700\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6645 - val_loss: 0.6964\n",
            "Epoch 336/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6790 - val_loss: 0.7006\n",
            "Epoch 337/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6684 - val_loss: 0.7014\n",
            "Epoch 338/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6623 - val_loss: 0.7275\n",
            "Epoch 339/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6639 - val_loss: 0.7041\n",
            "Epoch 340/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6633 - val_loss: 0.7054\n",
            "Epoch 341/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6584 - val_loss: 0.7004\n",
            "Epoch 342/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6621 - val_loss: 0.7032\n",
            "Epoch 343/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6693 - val_loss: 0.7148\n",
            "Epoch 344/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6622 - val_loss: 0.6915\n",
            "Epoch 345/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6688 - val_loss: 0.7033\n",
            "Epoch 346/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6629 - val_loss: 0.7224\n",
            "Epoch 347/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6631 - val_loss: 0.7192\n",
            "Epoch 348/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6685 - val_loss: 0.7069\n",
            "Epoch 349/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6555 - val_loss: 0.7233\n",
            "Epoch 350/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6806 - val_loss: 0.7233\n",
            "Epoch 351/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6709 - val_loss: 0.7025\n",
            "Epoch 352/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6712 - val_loss: 0.7237\n",
            "Epoch 353/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6514 - val_loss: 0.7219\n",
            "Epoch 354/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6728 - val_loss: 0.7116\n",
            "Epoch 355/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6559 - val_loss: 0.7225\n",
            "Epoch 356/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6641 - val_loss: 0.7097\n",
            "Epoch 357/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6659 - val_loss: 0.6972\n",
            "Epoch 358/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6900 - val_loss: 0.7087\n",
            "Epoch 359/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6625 - val_loss: 0.6934\n",
            "Epoch 360/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6686 - val_loss: 0.7560\n",
            "Epoch 361/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6628 - val_loss: 0.6917\n",
            "Epoch 362/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6568 - val_loss: 0.7242\n",
            "Epoch 363/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6632 - val_loss: 0.7090\n",
            "Epoch 364/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6758 - val_loss: 0.7023\n",
            "Epoch 365/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6700 - val_loss: 0.7085\n",
            "Epoch 366/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 0.6626"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 311ms/step - loss: 0.6577 - val_loss: 0.6796\n",
            "Epoch 367/700\n",
            "22/22 [==============================] - 1s 44ms/step - loss: 0.6487 - val_loss: 0.6844\n",
            "Epoch 368/700\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.6677 - val_loss: 0.7038\n",
            "Epoch 369/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6538 - val_loss: 0.6864\n",
            "Epoch 370/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6693 - val_loss: 0.7378\n",
            "Epoch 371/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6691 - val_loss: 0.6966\n",
            "Epoch 372/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6683 - val_loss: 0.7128\n",
            "Epoch 373/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6708 - val_loss: 0.7076\n",
            "Epoch 374/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6737 - val_loss: 0.7211\n",
            "Epoch 375/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6806 - val_loss: 0.7204\n",
            "Epoch 376/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6627 - val_loss: 0.7020\n",
            "Epoch 377/700\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6660 - val_loss: 0.6977\n",
            "Epoch 378/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6663 - val_loss: 0.6960\n",
            "Epoch 379/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6578 - val_loss: 0.6943\n",
            "Epoch 380/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6718 - val_loss: 0.7423\n",
            "Epoch 381/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6722 - val_loss: 0.6955\n",
            "Epoch 382/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6714 - val_loss: 0.6986\n",
            "Epoch 383/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6661 - val_loss: 0.6886\n",
            "Epoch 384/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6682 - val_loss: 0.7646\n",
            "Epoch 385/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6615 - val_loss: 0.7188\n",
            "Epoch 386/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6622 - val_loss: 0.7347\n",
            "Epoch 387/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6673 - val_loss: 0.7029\n",
            "Epoch 388/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6607 - val_loss: 0.7045\n",
            "Epoch 389/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6635 - val_loss: 0.7272\n",
            "Epoch 390/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6728 - val_loss: 0.6994\n",
            "Epoch 391/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6853 - val_loss: 0.7300\n",
            "Epoch 392/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6776 - val_loss: 0.6905\n",
            "Epoch 393/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6746 - val_loss: 0.7114\n",
            "Epoch 394/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6693 - val_loss: 0.7114\n",
            "Epoch 395/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6625 - val_loss: 0.6903\n",
            "Epoch 396/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6668 - val_loss: 0.7693\n",
            "Epoch 397/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6540 - val_loss: 0.7005\n",
            "Epoch 398/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6686 - val_loss: 0.6946\n",
            "Epoch 399/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6582 - val_loss: 0.6950\n",
            "Epoch 400/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6457 - val_loss: 0.7043\n",
            "Epoch 401/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6640 - val_loss: 0.7119\n",
            "Epoch 402/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6558 - val_loss: 0.6990\n",
            "Epoch 403/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6661 - val_loss: 0.7164\n",
            "Epoch 404/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6574 - val_loss: 0.7062\n",
            "Epoch 405/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6562 - val_loss: 0.7040\n",
            "Epoch 406/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6627 - val_loss: 0.7115\n",
            "Epoch 407/700\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6562 - val_loss: 0.7112\n",
            "Epoch 408/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6743 - val_loss: 0.6993\n",
            "Epoch 409/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6660 - val_loss: 0.6912\n",
            "Epoch 410/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6594 - val_loss: 0.7242\n",
            "Epoch 411/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6754 - val_loss: 0.6985\n",
            "Epoch 412/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6670 - val_loss: 0.7000\n",
            "Epoch 413/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6601 - val_loss: 0.7304\n",
            "Epoch 414/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6694 - val_loss: 0.7027\n",
            "Epoch 415/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6742 - val_loss: 0.7012\n",
            "Epoch 416/700\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6551 - val_loss: 0.6917\n",
            "Epoch 417/700\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6643 - val_loss: 0.7001\n",
            "Epoch 418/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6763 - val_loss: 0.6983\n",
            "Epoch 419/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6588 - val_loss: 0.6801\n",
            "Epoch 420/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6678 - val_loss: 0.7001\n",
            "Epoch 421/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6624 - val_loss: 0.7108\n",
            "Epoch 422/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6602 - val_loss: 0.6941\n",
            "Epoch 423/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6780 - val_loss: 0.7263\n",
            "Epoch 424/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6739 - val_loss: 0.7149\n",
            "Epoch 425/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6686 - val_loss: 0.6997\n",
            "Epoch 426/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6674 - val_loss: 0.6933\n",
            "Epoch 427/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6743 - val_loss: 0.7230\n",
            "Epoch 428/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6561 - val_loss: 0.6834\n",
            "Epoch 429/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6663 - val_loss: 0.6965\n",
            "Epoch 430/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6674 - val_loss: 0.7127\n",
            "Epoch 431/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6649 - val_loss: 0.6852\n",
            "Epoch 432/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6542 - val_loss: 0.6850\n",
            "Epoch 433/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6626 - val_loss: 0.7045\n",
            "Epoch 434/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6666 - val_loss: 0.6957\n",
            "Epoch 435/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6627 - val_loss: 0.7015\n",
            "Epoch 436/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6652 - val_loss: 0.7146\n",
            "Epoch 437/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6565 - val_loss: 0.6916\n",
            "Epoch 438/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6724 - val_loss: 0.7232\n",
            "Epoch 439/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6641 - val_loss: 0.6933\n",
            "Epoch 440/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6604 - val_loss: 0.6901\n",
            "Epoch 441/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6562 - val_loss: 0.6889\n",
            "Epoch 442/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6624 - val_loss: 0.7153\n",
            "Epoch 443/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6702 - val_loss: 0.7042\n",
            "Epoch 444/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6528 - val_loss: 0.6889\n",
            "Epoch 445/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6549 - val_loss: 0.7085\n",
            "Epoch 446/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6657 - val_loss: 0.7187\n",
            "Epoch 447/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6762 - val_loss: 0.7023\n",
            "Epoch 448/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6675 - val_loss: 0.7239\n",
            "Epoch 449/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6645 - val_loss: 0.7019\n",
            "Epoch 450/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6631 - val_loss: 0.7120\n",
            "Epoch 451/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6570 - val_loss: 0.7084\n",
            "Epoch 452/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6548 - val_loss: 0.7151\n",
            "Epoch 453/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6630 - val_loss: 0.7005\n",
            "Epoch 454/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6687 - val_loss: 0.7075\n",
            "Epoch 455/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6489 - val_loss: 0.6837\n",
            "Epoch 456/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6660 - val_loss: 0.7332\n",
            "Epoch 457/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6672 - val_loss: 0.6937\n",
            "Epoch 458/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6541 - val_loss: 0.6903\n",
            "Epoch 459/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6530 - val_loss: 0.6955\n",
            "Epoch 460/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6569 - val_loss: 0.7348\n",
            "Epoch 461/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6731 - val_loss: 0.6871\n",
            "Epoch 462/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6646 - val_loss: 0.7021\n",
            "Epoch 463/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6645 - val_loss: 0.7409\n",
            "Epoch 464/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6646 - val_loss: 0.7211\n",
            "Epoch 465/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6614 - val_loss: 0.7269\n",
            "Epoch 466/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6693 - val_loss: 0.6931\n",
            "Epoch 467/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6446 - val_loss: 0.7138\n",
            "Epoch 468/700\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6522 - val_loss: 0.6819\n",
            "Epoch 469/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6562 - val_loss: 0.7046\n",
            "Epoch 470/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6715 - val_loss: 0.7110\n",
            "Epoch 471/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6547 - val_loss: 0.7140\n",
            "Epoch 472/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6642 - val_loss: 0.6906\n",
            "Epoch 473/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6683 - val_loss: 0.7006\n",
            "Epoch 474/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6568 - val_loss: 0.7162\n",
            "Epoch 475/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6606 - val_loss: 0.6969\n",
            "Epoch 476/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6691 - val_loss: 0.7355\n",
            "Epoch 477/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6571 - val_loss: 0.6938\n",
            "Epoch 478/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6665 - val_loss: 0.7197\n",
            "Epoch 479/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6581 - val_loss: 0.6878\n",
            "Epoch 480/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6670 - val_loss: 0.7035\n",
            "Epoch 481/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6570 - val_loss: 0.6924\n",
            "Epoch 482/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6668 - val_loss: 0.7071\n",
            "Epoch 483/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6688 - val_loss: 0.6900\n",
            "Epoch 484/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6483 - val_loss: 0.6860\n",
            "Epoch 485/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6586 - val_loss: 0.7004\n",
            "Epoch 486/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6575 - val_loss: 0.7020\n",
            "Epoch 487/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6562 - val_loss: 0.6959\n",
            "Epoch 488/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6630 - val_loss: 0.6921\n",
            "Epoch 489/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6685 - val_loss: 0.7558\n",
            "Epoch 490/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6723 - val_loss: 0.6957\n",
            "Epoch 491/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6507 - val_loss: 0.7107\n",
            "Epoch 492/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6533 - val_loss: 0.7267\n",
            "Epoch 493/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6604 - val_loss: 0.6929\n",
            "Epoch 494/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6543 - val_loss: 0.6814\n",
            "Epoch 495/700\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6478 - val_loss: 0.7103\n",
            "Epoch 496/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6534 - val_loss: 0.6932\n",
            "Epoch 497/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6529 - val_loss: 0.6926\n",
            "Epoch 498/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6487 - val_loss: 0.6855\n",
            "Epoch 499/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6586 - val_loss: 0.7063\n",
            "Epoch 500/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6548 - val_loss: 0.6851\n",
            "Epoch 501/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6567 - val_loss: 0.6802\n",
            "Epoch 502/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6548 - val_loss: 0.6982\n",
            "Epoch 503/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6487 - val_loss: 0.6866\n",
            "Epoch 504/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6441 - val_loss: 0.7052\n",
            "Epoch 505/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6542 - val_loss: 0.7159\n",
            "Epoch 506/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6505 - val_loss: 0.7241\n",
            "Epoch 507/700\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6590 - val_loss: 0.6994\n",
            "Epoch 508/700\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6484 - val_loss: 0.6836\n",
            "Epoch 509/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6470 - val_loss: 0.7194\n",
            "Epoch 510/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6518 - val_loss: 0.7348\n",
            "Epoch 511/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6520 - val_loss: 0.6926\n",
            "Epoch 512/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6567 - val_loss: 0.6892\n",
            "Epoch 513/700\n",
            "22/22 [==============================] - 1s 69ms/step - loss: 0.6608 - val_loss: 0.7008\n",
            "Epoch 514/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6462 - val_loss: 0.7055\n",
            "Epoch 515/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6483 - val_loss: 0.6836\n",
            "Epoch 516/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6617 - val_loss: 0.6978\n",
            "Epoch 517/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6646 - val_loss: 0.7156\n",
            "Epoch 518/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6594 - val_loss: 0.6896\n",
            "Epoch 519/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6592 - val_loss: 0.7362\n",
            "Epoch 520/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6576 - val_loss: 0.6855\n",
            "Epoch 521/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6590 - val_loss: 0.7055\n",
            "Epoch 522/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6674 - val_loss: 0.6865\n",
            "Epoch 523/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6550 - val_loss: 0.6922\n",
            "Epoch 524/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6723 - val_loss: 0.6888\n",
            "Epoch 525/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6541 - val_loss: 0.6951\n",
            "Epoch 526/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6558 - val_loss: 0.6881\n",
            "Epoch 527/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6539 - val_loss: 0.7000\n",
            "Epoch 528/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6446 - val_loss: 0.7092\n",
            "Epoch 529/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6607 - val_loss: 0.6818\n",
            "Epoch 530/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6446 - val_loss: 0.7366\n",
            "Epoch 531/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6531 - val_loss: 0.6856\n",
            "Epoch 532/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6465 - val_loss: 0.6919\n",
            "Epoch 533/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6540 - val_loss: 0.7068\n",
            "Epoch 534/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6583 - val_loss: 0.7094\n",
            "Epoch 535/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6514 - val_loss: 0.7027\n",
            "Epoch 536/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6549 - val_loss: 0.6968\n",
            "Epoch 537/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6608 - val_loss: 0.6917\n",
            "Epoch 538/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6477 - val_loss: 0.6912\n",
            "Epoch 539/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6505 - val_loss: 0.7064\n",
            "Epoch 540/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6631 - val_loss: 0.7331\n",
            "Epoch 541/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6623 - val_loss: 0.7012\n",
            "Epoch 542/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6456 - val_loss: 0.6892\n",
            "Epoch 543/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6464 - val_loss: 0.7388\n",
            "Epoch 544/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6665 - val_loss: 0.7105\n",
            "Epoch 545/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6599 - val_loss: 0.7174\n",
            "Epoch 546/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6561 - val_loss: 0.6821\n",
            "Epoch 547/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6707 - val_loss: 0.6978\n",
            "Epoch 548/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6646 - val_loss: 0.7222\n",
            "Epoch 549/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6555 - val_loss: 0.6968\n",
            "Epoch 550/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6595 - val_loss: 0.6985\n",
            "Epoch 551/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6473 - val_loss: 0.7062\n",
            "Epoch 552/700\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6603 - val_loss: 0.6802\n",
            "Epoch 553/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6646 - val_loss: 0.6851\n",
            "Epoch 554/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6553 - val_loss: 0.6893\n",
            "Epoch 555/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6621 - val_loss: 0.6885\n",
            "Epoch 556/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6515 - val_loss: 0.7009\n",
            "Epoch 557/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6615 - val_loss: 0.6907\n",
            "Epoch 558/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6497 - val_loss: 0.6864\n",
            "Epoch 559/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6654 - val_loss: 0.7100\n",
            "Epoch 560/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6617 - val_loss: 0.7004\n",
            "Epoch 561/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6485 - val_loss: 0.6844\n",
            "Epoch 562/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6610 - val_loss: 0.6866\n",
            "Epoch 563/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6679 - val_loss: 0.6928\n",
            "Epoch 564/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6491 - val_loss: 0.6964\n",
            "Epoch 565/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6581 - val_loss: 0.6977\n",
            "Epoch 566/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6494 - val_loss: 0.7047\n",
            "Epoch 567/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6505 - val_loss: 0.6968\n",
            "Epoch 568/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6598 - val_loss: 0.6975\n",
            "Epoch 569/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6438 - val_loss: 0.7031\n",
            "Epoch 570/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6454 - val_loss: 0.6963\n",
            "Epoch 571/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6400 - val_loss: 0.6914\n",
            "Epoch 572/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6512 - val_loss: 0.7028\n",
            "Epoch 573/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6461 - val_loss: 0.6991\n",
            "Epoch 574/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6500 - val_loss: 0.6941\n",
            "Epoch 575/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6365 - val_loss: 0.6817\n",
            "Epoch 576/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6579 - val_loss: 0.6946\n",
            "Epoch 577/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6486 - val_loss: 0.6963\n",
            "Epoch 578/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6514 - val_loss: 0.6943\n",
            "Epoch 579/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6545 - val_loss: 0.7086\n",
            "Epoch 580/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6507"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 347ms/step - loss: 0.6590 - val_loss: 0.6767\n",
            "Epoch 581/700\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.6586 - val_loss: 0.6823\n",
            "Epoch 582/700\n",
            "22/22 [==============================] - 1s 42ms/step - loss: 0.6445 - val_loss: 0.6949\n",
            "Epoch 583/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6478 - val_loss: 0.6862\n",
            "Epoch 584/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6606 - val_loss: 0.7005\n",
            "Epoch 585/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6463 - val_loss: 0.7057\n",
            "Epoch 586/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6564 - val_loss: 0.6904\n",
            "Epoch 587/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6439 - val_loss: 0.6924\n",
            "Epoch 588/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6505 - val_loss: 0.6906\n",
            "Epoch 589/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6519 - val_loss: 0.6969\n",
            "Epoch 590/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6486 - val_loss: 0.6900\n",
            "Epoch 591/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6545 - val_loss: 0.7285\n",
            "Epoch 592/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6524 - val_loss: 0.7035\n",
            "Epoch 593/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6486 - val_loss: 0.7197\n",
            "Epoch 594/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6584 - val_loss: 0.6835\n",
            "Epoch 595/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6575 - val_loss: 0.6819\n",
            "Epoch 596/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6464 - val_loss: 0.7262\n",
            "Epoch 597/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6572 - val_loss: 0.6825\n",
            "Epoch 598/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6557 - val_loss: 0.7111\n",
            "Epoch 599/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6366 - val_loss: 0.6956\n",
            "Epoch 600/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6656 - val_loss: 0.6914\n",
            "Epoch 601/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6606 - val_loss: 0.6915\n",
            "Epoch 602/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6572 - val_loss: 0.6928\n",
            "Epoch 603/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6512 - val_loss: 0.7004\n",
            "Epoch 604/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6437"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 331ms/step - loss: 0.6449 - val_loss: 0.6759\n",
            "Epoch 605/700\n",
            "22/22 [==============================] - 1s 41ms/step - loss: 0.6572 - val_loss: 0.7072\n",
            "Epoch 606/700\n",
            "22/22 [==============================] - 1s 40ms/step - loss: 0.6559 - val_loss: 0.7025\n",
            "Epoch 607/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6570 - val_loss: 0.6916\n",
            "Epoch 608/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6563 - val_loss: 0.7103\n",
            "Epoch 609/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6558 - val_loss: 0.7009\n",
            "Epoch 610/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6481 - val_loss: 0.6900\n",
            "Epoch 611/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6627 - val_loss: 0.6879\n",
            "Epoch 612/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6568 - val_loss: 0.6898\n",
            "Epoch 613/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6523 - val_loss: 0.6955\n",
            "Epoch 614/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6621 - val_loss: 0.7274\n",
            "Epoch 615/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6597 - val_loss: 0.7020\n",
            "Epoch 616/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6597 - val_loss: 0.6845\n",
            "Epoch 617/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6541 - val_loss: 0.6912\n",
            "Epoch 618/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6569 - val_loss: 0.6855\n",
            "Epoch 619/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6586 - val_loss: 0.6907\n",
            "Epoch 620/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6633 - val_loss: 0.6906\n",
            "Epoch 621/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6566 - val_loss: 0.6882\n",
            "Epoch 622/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6441 - val_loss: 0.6952\n",
            "Epoch 623/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6534 - val_loss: 0.6781\n",
            "Epoch 624/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6540 - val_loss: 0.6788\n",
            "Epoch 625/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6474 - val_loss: 0.6943\n",
            "Epoch 626/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6467 - val_loss: 0.6882\n",
            "Epoch 627/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6518 - val_loss: 0.6887\n",
            "Epoch 628/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6488 - val_loss: 0.6942\n",
            "Epoch 629/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6564 - val_loss: 0.7085\n",
            "Epoch 630/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6613 - val_loss: 0.6843\n",
            "Epoch 631/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6456 - val_loss: 0.6808\n",
            "Epoch 632/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6468 - val_loss: 0.6822\n",
            "Epoch 633/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6561 - val_loss: 0.6774\n",
            "Epoch 634/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6428 - val_loss: 0.6878\n",
            "Epoch 635/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6386 - val_loss: 0.6880\n",
            "Epoch 636/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6454 - val_loss: 0.6950\n",
            "Epoch 637/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6544 - val_loss: 0.6762\n",
            "Epoch 638/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6528 - val_loss: 0.7067\n",
            "Epoch 639/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6548 - val_loss: 0.6920\n",
            "Epoch 640/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6463 - val_loss: 0.6812\n",
            "Epoch 641/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6650 - val_loss: 0.6837\n",
            "Epoch 642/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6521 - val_loss: 0.7013\n",
            "Epoch 643/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6477 - val_loss: 0.6886\n",
            "Epoch 644/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6638 - val_loss: 0.6990\n",
            "Epoch 645/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6595 - val_loss: 0.6855\n",
            "Epoch 646/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6526 - val_loss: 0.6838\n",
            "Epoch 647/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6579 - val_loss: 0.6909\n",
            "Epoch 648/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6443 - val_loss: 0.6927\n",
            "Epoch 649/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6568 - val_loss: 0.6779\n",
            "Epoch 650/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6552 - val_loss: 0.6863\n",
            "Epoch 651/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6517 - val_loss: 0.6905\n",
            "Epoch 652/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6540 - val_loss: 0.6901\n",
            "Epoch 653/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6596 - val_loss: 0.6838\n",
            "Epoch 654/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6550 - val_loss: 0.6913\n",
            "Epoch 655/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_093823-asvpswb0/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 303ms/step - loss: 0.6502 - val_loss: 0.6757\n",
            "Epoch 656/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6437 - val_loss: 0.7091\n",
            "Epoch 657/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6437 - val_loss: 0.6847\n",
            "Epoch 658/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6487 - val_loss: 0.6940\n",
            "Epoch 659/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6607 - val_loss: 0.6813\n",
            "Epoch 660/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6568 - val_loss: 0.6846\n",
            "Epoch 661/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6470 - val_loss: 0.7018\n",
            "Epoch 662/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6481 - val_loss: 0.6840\n",
            "Epoch 663/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6574 - val_loss: 0.6838\n",
            "Epoch 664/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6557 - val_loss: 0.7032\n",
            "Epoch 665/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6588 - val_loss: 0.6937\n",
            "Epoch 666/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6515 - val_loss: 0.6836\n",
            "Epoch 667/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6395 - val_loss: 0.6907\n",
            "Epoch 668/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6488 - val_loss: 0.7229\n",
            "Epoch 669/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6567 - val_loss: 0.6860\n",
            "Epoch 670/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6487 - val_loss: 0.6869\n",
            "Epoch 671/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6467 - val_loss: 0.7196\n",
            "Epoch 672/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6651 - val_loss: 0.6788\n",
            "Epoch 673/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6606 - val_loss: 0.6832\n",
            "Epoch 674/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6501 - val_loss: 0.6800\n",
            "Epoch 675/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6602 - val_loss: 0.6759\n",
            "Epoch 676/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6498 - val_loss: 0.6886\n",
            "Epoch 677/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6461 - val_loss: 0.6889\n",
            "Epoch 678/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6276 - val_loss: 0.6818\n",
            "Epoch 679/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6580 - val_loss: 0.6916\n",
            "Epoch 680/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6468 - val_loss: 0.6946\n",
            "Epoch 681/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6498 - val_loss: 0.6788\n",
            "Epoch 682/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6496 - val_loss: 0.6862\n",
            "Epoch 683/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6482 - val_loss: 0.7034\n",
            "Epoch 684/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6538 - val_loss: 0.6911\n",
            "Epoch 685/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6435 - val_loss: 0.6953\n",
            "Epoch 686/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6567 - val_loss: 0.6830\n",
            "Epoch 687/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6683 - val_loss: 0.6975\n",
            "Epoch 688/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6486 - val_loss: 0.6787\n",
            "Epoch 689/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6443 - val_loss: 0.6848\n",
            "Epoch 690/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6464 - val_loss: 0.6788\n",
            "Epoch 691/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6482 - val_loss: 0.6923\n",
            "Epoch 692/700\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6482 - val_loss: 0.6959\n",
            "Epoch 693/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6425 - val_loss: 0.6757\n",
            "Epoch 694/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6463 - val_loss: 0.7075\n",
            "Epoch 695/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6461 - val_loss: 0.6855\n",
            "Epoch 696/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6616 - val_loss: 0.6909\n",
            "Epoch 697/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6476 - val_loss: 0.6853\n",
            "Epoch 698/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6463 - val_loss: 0.6971\n",
            "Epoch 699/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6476 - val_loss: 0.6900\n",
            "Epoch 700/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6380 - val_loss: 0.6864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c7e59fd89d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41sRID7UsE8S",
        "outputId": "f7b005d6-efc5-4eca-9d01-1ae390a3b52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6864194869995117"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential()"
      ],
      "metadata": {
        "id": "q6IwSg31sIq_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.add(Dense(units=35,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model3.add(Dense(units=500,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model3.add(Dropout(0.2))\n",
        "\n",
        "model3.add(BatchNormalization())\n",
        "\n",
        "model3.add(Dense(units=500,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model3.add(Dropout(0.2))\n",
        "\n",
        "model3.add(BatchNormalization())\n",
        "\n",
        "model3.add(Dense(units=500,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model3.add(Dropout(0.2))\n",
        "\n",
        "model3.add(BatchNormalization())\n",
        "\n",
        "model3.add(Dense(units=300,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model3.add(Dropout(0.2))\n",
        "\n",
        "model3.add(BatchNormalization())\n",
        "\n",
        "model3.add(Dense(units=200,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model3.add(Dense(units=200,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model3.add(Dropout(0.2))\n",
        "\n",
        "model3.add(BatchNormalization())\n",
        "\n",
        "model3.add(Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "0zZT3hmU53sl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy())"
      ],
      "metadata": {
        "id": "kwvZu-bf6m7h"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = 'Startups',name = 'Third Trail')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "42YSm4ko7Ash",
        "outputId": "443a1fef-0c99-40cb-d8c3-262ef90019ad"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mossm0394\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231002_113130-yslxf29b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ossm0394/Startups/runs/yslxf29b' target=\"_blank\">Third Trail</a></strong> to <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">https://wandb.ai/ossm0394/Startups</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ossm0394/Startups/runs/yslxf29b' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/yslxf29b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ossm0394/Startups/runs/yslxf29b?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c9ea1f36ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(x = x_train,y = y_train,epochs = 1000,validation_data = (x_test,y_test),callbacks = [WandbCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQwscmlN7JZy",
        "outputId": "1b4c681a-1385-435a-c1da-083736af8121"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 132.1455"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 13s 179ms/step - loss: 131.8802 - val_loss: 130.0353\n",
            "Epoch 2/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 128.7999"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 167ms/step - loss: 128.5343 - val_loss: 126.5917\n",
            "Epoch 3/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 125.1909"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 7s 335ms/step - loss: 125.1462 - val_loss: 123.3099\n",
            "Epoch 4/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 122.1550"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 121.8998 - val_loss: 120.1069\n",
            "Epoch 5/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 119.0654"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 189ms/step - loss: 118.7255 - val_loss: 117.0056\n",
            "Epoch 6/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 115.7692"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 280ms/step - loss: 115.6607 - val_loss: 113.9760\n",
            "Epoch 7/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 112.6903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 176ms/step - loss: 112.6504 - val_loss: 111.0275\n",
            "Epoch 8/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 109.9604"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 181ms/step - loss: 109.7270 - val_loss: 108.1553\n",
            "Epoch 9/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 107.1166"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 167ms/step - loss: 106.8709 - val_loss: 105.3573\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 104.1051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 242ms/step - loss: 104.1051 - val_loss: 102.6337\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 101.4064"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 101.4064 - val_loss: 99.9825\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 98.7753"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 98.7753 - val_loss: 97.3976\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 96.2108"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 237ms/step - loss: 96.2108 - val_loss: 94.8807\n",
            "Epoch 14/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 93.9360"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 161ms/step - loss: 93.7562 - val_loss: 92.4310\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 91.3305"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 161ms/step - loss: 91.3305 - val_loss: 90.0426\n",
            "Epoch 16/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 89.1246"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 206ms/step - loss: 88.9373 - val_loss: 87.7155\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 86.6425"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 208ms/step - loss: 86.6425 - val_loss: 85.4497\n",
            "Epoch 18/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 84.6513"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 184ms/step - loss: 84.4136 - val_loss: 83.2440\n",
            "Epoch 19/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 82.4425"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 82.2168 - val_loss: 81.0875\n",
            "Epoch 20/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 80.1208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 228ms/step - loss: 80.0898 - val_loss: 78.9968\n",
            "Epoch 21/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 78.0489"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 183ms/step - loss: 78.0321 - val_loss: 76.9589\n",
            "Epoch 22/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 76.1823"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 76.0194 - val_loss: 74.9709\n",
            "Epoch 23/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 74.0718"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 193ms/step - loss: 74.0432 - val_loss: 73.0378\n",
            "Epoch 24/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 72.2350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 219ms/step - loss: 72.1293 - val_loss: 71.1531\n",
            "Epoch 25/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 70.4307"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 160ms/step - loss: 70.2824 - val_loss: 69.3215\n",
            "Epoch 26/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 68.6085"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 182ms/step - loss: 68.4534 - val_loss: 67.5293\n",
            "Epoch 27/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 66.7942"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 229ms/step - loss: 66.6967 - val_loss: 65.7790\n",
            "Epoch 28/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 65.1380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 64.9806 - val_loss: 64.0871\n",
            "Epoch 29/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 63.4348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 179ms/step - loss: 63.3006 - val_loss: 62.4319\n",
            "Epoch 30/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 61.7426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 205ms/step - loss: 61.6467 - val_loss: 60.8219\n",
            "Epoch 31/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 60.1766"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 195ms/step - loss: 60.0742 - val_loss: 59.2543\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 58.4991"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 58.4991 - val_loss: 57.7334\n",
            "Epoch 33/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 57.1026"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 160ms/step - loss: 57.0088 - val_loss: 56.2457\n",
            "Epoch 34/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 55.5556"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 243ms/step - loss: 55.5398 - val_loss: 54.8083\n",
            "Epoch 35/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 54.2337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 54.1138 - val_loss: 53.4020\n",
            "Epoch 36/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 52.8137"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 52.7069 - val_loss: 52.0234\n",
            "Epoch 37/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 51.4778"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 236ms/step - loss: 51.3677 - val_loss: 50.6821\n",
            "Epoch 38/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 50.1132"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 50.0406 - val_loss: 49.3793\n",
            "Epoch 39/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 48.8458"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 182ms/step - loss: 48.7536 - val_loss: 48.1068\n",
            "Epoch 40/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 47.5968"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 178ms/step - loss: 47.4984 - val_loss: 46.8741\n",
            "Epoch 41/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 46.2787"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 213ms/step - loss: 46.2634 - val_loss: 45.6667\n",
            "Epoch 42/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 45.1475"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 178ms/step - loss: 45.0803 - val_loss: 44.4942\n",
            "Epoch 43/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 43.9456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 43.9345 - val_loss: 43.3527\n",
            "Epoch 44/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 42.8783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 219ms/step - loss: 42.7892 - val_loss: 42.2555\n",
            "Epoch 45/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 41.8048"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 177ms/step - loss: 41.7197 - val_loss: 41.1700\n",
            "Epoch 46/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 40.6475"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 166ms/step - loss: 40.6408 - val_loss: 40.1042\n",
            "Epoch 47/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 39.6578"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 210ms/step - loss: 39.5843 - val_loss: 39.0855\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 38.5901"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 199ms/step - loss: 38.5901 - val_loss: 38.0821\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 37.5827"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 161ms/step - loss: 37.5827 - val_loss: 37.1048\n",
            "Epoch 50/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 36.7065"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 183ms/step - loss: 36.6247 - val_loss: 36.1619\n",
            "Epoch 51/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 35.7611"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 231ms/step - loss: 35.6840 - val_loss: 35.2449\n",
            "Epoch 52/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 34.8559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 34.7576 - val_loss: 34.3400\n",
            "Epoch 53/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 33.9808"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 184ms/step - loss: 33.8857 - val_loss: 33.4587\n",
            "Epoch 54/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 33.1037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 199ms/step - loss: 33.0241 - val_loss: 32.5989\n",
            "Epoch 55/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 32.2112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 211ms/step - loss: 32.1820 - val_loss: 31.7765\n",
            "Epoch 56/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 31.4190"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 166ms/step - loss: 31.3568 - val_loss: 30.9599\n",
            "Epoch 57/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 30.6178"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 160ms/step - loss: 30.5461 - val_loss: 30.1772\n",
            "Epoch 58/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 29.8313"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 247ms/step - loss: 29.7676 - val_loss: 29.4148\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 29.0120"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 237ms/step - loss: 29.0120 - val_loss: 28.6540\n",
            "Epoch 60/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 28.3140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 160ms/step - loss: 28.2670 - val_loss: 27.9240\n",
            "Epoch 61/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 27.5847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 247ms/step - loss: 27.5537 - val_loss: 27.2082\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 26.8407"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 26.8407 - val_loss: 26.5267\n",
            "Epoch 63/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 26.2269"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 183ms/step - loss: 26.1627 - val_loss: 25.8627\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 25.5086"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 214ms/step - loss: 25.5086 - val_loss: 25.1982\n",
            "Epoch 65/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 24.8678"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 167ms/step - loss: 24.8566 - val_loss: 24.5576\n",
            "Epoch 66/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 24.2959"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 182ms/step - loss: 24.2314 - val_loss: 23.9373\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 23.6081"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 177ms/step - loss: 23.6081 - val_loss: 23.3256\n",
            "Epoch 68/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 23.0246"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 220ms/step - loss: 23.0049 - val_loss: 22.7446\n",
            "Epoch 69/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 22.4649"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 182ms/step - loss: 22.4123 - val_loss: 22.1759\n",
            "Epoch 70/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 21.8825"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 21.8514 - val_loss: 21.6119\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 21.3088"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 235ms/step - loss: 21.3088 - val_loss: 21.0684\n",
            "Epoch 72/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 20.7683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 20.7607 - val_loss: 20.5428\n",
            "Epoch 73/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 20.2517"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 20.2432 - val_loss: 20.0199\n",
            "Epoch 74/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 19.7517"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 210ms/step - loss: 19.7205 - val_loss: 19.5171\n",
            "Epoch 75/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 19.2391"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 194ms/step - loss: 19.2324 - val_loss: 19.0270\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 18.7488"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 18.7488 - val_loss: 18.5424\n",
            "Epoch 77/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 18.3090"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 183ms/step - loss: 18.2742 - val_loss: 18.0697\n",
            "Epoch 78/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 17.8474"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 229ms/step - loss: 17.8210 - val_loss: 17.6094\n",
            "Epoch 79/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 17.4070"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 179ms/step - loss: 17.3791 - val_loss: 17.1753\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 16.9319"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 16.9319 - val_loss: 16.7485\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 16.5070"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 196ms/step - loss: 16.5070 - val_loss: 16.3376\n",
            "Epoch 82/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 16.1118"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 220ms/step - loss: 16.0973 - val_loss: 15.9234\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 15.6936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 167ms/step - loss: 15.6936 - val_loss: 15.5223\n",
            "Epoch 84/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 15.3150"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 15.2900 - val_loss: 15.1418\n",
            "Epoch 85/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 14.9279"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 248ms/step - loss: 14.9247 - val_loss: 14.7591\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 14.5388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 14.5388 - val_loss: 14.3933\n",
            "Epoch 87/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 14.2163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 14.1807 - val_loss: 14.0455\n",
            "Epoch 88/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 13.8538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 234ms/step - loss: 13.8282 - val_loss: 13.6972\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 13.4825"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 13.4825 - val_loss: 13.3664\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 13.1420"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 180ms/step - loss: 13.1420 - val_loss: 13.0255\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 12.8330"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 181ms/step - loss: 12.8330 - val_loss: 12.7063\n",
            "Epoch 92/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 12.5162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 218ms/step - loss: 12.5116 - val_loss: 12.3989\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 12.2037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 186ms/step - loss: 12.2037 - val_loss: 12.0932\n",
            "Epoch 94/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 11.8877"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 11.8830 - val_loss: 11.8045\n",
            "Epoch 95/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 11.6040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 246ms/step - loss: 11.6013 - val_loss: 11.5104\n",
            "Epoch 96/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 11.3438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 11.3192 - val_loss: 11.2244\n",
            "Epoch 97/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 11.0445"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 169ms/step - loss: 11.0431 - val_loss: 10.9466\n",
            "Epoch 98/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 10.7694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 228ms/step - loss: 10.7650 - val_loss: 10.6740\n",
            "Epoch 99/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 10.5062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 191ms/step - loss: 10.5041 - val_loss: 10.4193\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 10.2496"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 10.2496 - val_loss: 10.1678\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 9.9956 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 188ms/step - loss: 9.9956 - val_loss: 9.9281\n",
            "Epoch 102/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 9.7501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 227ms/step - loss: 9.7443 - val_loss: 9.6809\n",
            "Epoch 103/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 9.5242"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 183ms/step - loss: 9.5198 - val_loss: 9.4379\n",
            "Epoch 104/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 9.2873"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 9.2811 - val_loss: 9.2156\n",
            "Epoch 105/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 9.0517"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 214ms/step - loss: 9.0490 - val_loss: 8.9910\n",
            "Epoch 106/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 8.8528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 197ms/step - loss: 8.8457 - val_loss: 8.7713\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 8.6168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 8.6168 - val_loss: 8.5671\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 8.4124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 180ms/step - loss: 8.4124 - val_loss: 8.3597\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 8.2118"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 235ms/step - loss: 8.2118 - val_loss: 8.1682\n",
            "Epoch 110/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 8.0521"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 169ms/step - loss: 8.0240 - val_loss: 7.9671\n",
            "Epoch 111/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 7.8270"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 170ms/step - loss: 7.8225 - val_loss: 7.7781\n",
            "Epoch 112/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 7.6420"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 284ms/step - loss: 7.6362 - val_loss: 7.5905\n",
            "Epoch 113/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 7.4509"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 202ms/step - loss: 7.4461 - val_loss: 7.4198\n",
            "Epoch 114/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 7.2667"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 182ms/step - loss: 7.2648 - val_loss: 7.2564\n",
            "Epoch 115/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 7.1105"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 174ms/step - loss: 7.1075 - val_loss: 7.0792\n",
            "Epoch 116/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 6.9314"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 223ms/step - loss: 6.9259 - val_loss: 6.9177\n",
            "Epoch 117/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 6.7600"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 187ms/step - loss: 6.7616 - val_loss: 6.7507\n",
            "Epoch 118/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 6.6158"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 165ms/step - loss: 6.6044 - val_loss: 6.5904\n",
            "Epoch 119/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 6.4598"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 227ms/step - loss: 6.4572 - val_loss: 6.4423\n",
            "Epoch 120/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 6.2902"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 188ms/step - loss: 6.2902 - val_loss: 6.3000\n",
            "Epoch 121/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 6.1556"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 170ms/step - loss: 6.1474 - val_loss: 6.1538\n",
            "Epoch 122/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 6.0038"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 198ms/step - loss: 6.0038 - val_loss: 6.0131\n",
            "Epoch 123/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 5.8684"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 217ms/step - loss: 5.8650 - val_loss: 5.8672\n",
            "Epoch 124/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 5.7359"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 5.7329 - val_loss: 5.7302\n",
            "Epoch 125/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 5.6014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 181ms/step - loss: 5.5999 - val_loss: 5.6033\n",
            "Epoch 126/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 5.4876"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 230ms/step - loss: 5.4722 - val_loss: 5.4632\n",
            "Epoch 127/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 5.3445"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 5.3367 - val_loss: 5.3394\n",
            "Epoch 128/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 5.2231"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 186ms/step - loss: 5.2231 - val_loss: 5.2287\n",
            "Epoch 129/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 5.0946"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 209ms/step - loss: 5.0946 - val_loss: 5.1105\n",
            "Epoch 130/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 4.9842"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 178ms/step - loss: 4.9772 - val_loss: 5.0008\n",
            "Epoch 131/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 4.8979"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 186ms/step - loss: 4.8718 - val_loss: 4.8618\n",
            "Epoch 132/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 4.7748"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 172ms/step - loss: 4.7568 - val_loss: 4.7574\n",
            "Epoch 133/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 4.6642"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 244ms/step - loss: 4.6581 - val_loss: 4.6435\n",
            "Epoch 134/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 4.5483"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 4.5483 - val_loss: 4.5430\n",
            "Epoch 135/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 4.4428"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 170ms/step - loss: 4.4428 - val_loss: 4.4529\n",
            "Epoch 136/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 4.3350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 246ms/step - loss: 4.3350 - val_loss: 4.3460\n",
            "Epoch 137/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 4.2423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 167ms/step - loss: 4.2436 - val_loss: 4.2548\n",
            "Epoch 138/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 4.1624"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 169ms/step - loss: 4.1620 - val_loss: 4.1638\n",
            "Epoch 139/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 4.0586"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 230ms/step - loss: 4.0586 - val_loss: 4.0812\n",
            "Epoch 140/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 3.9725"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 185ms/step - loss: 3.9703 - val_loss: 3.9974\n",
            "Epoch 141/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 3.8888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 189ms/step - loss: 3.8851 - val_loss: 3.9082\n",
            "Epoch 142/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 3.8102"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 175ms/step - loss: 3.7983 - val_loss: 3.8227\n",
            "Epoch 143/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 3.7161"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 225ms/step - loss: 3.7163 - val_loss: 3.7451\n",
            "Epoch 144/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 3.6348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 190ms/step - loss: 3.6326 - val_loss: 3.6514\n",
            "Epoch 145/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 3.5565"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 171ms/step - loss: 3.5546 - val_loss: 3.5818\n",
            "Epoch 146/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 3.4757"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 229ms/step - loss: 3.4738 - val_loss: 3.5119\n",
            "Epoch 147/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 3.4096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 186ms/step - loss: 3.4097 - val_loss: 3.4278\n",
            "Epoch 148/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 3.3321"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 3.3303 - val_loss: 3.3525\n",
            "Epoch 149/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 3.2666"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 195ms/step - loss: 3.2576 - val_loss: 3.2934\n",
            "Epoch 150/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 3.1916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 224ms/step - loss: 3.1910 - val_loss: 3.2361\n",
            "Epoch 151/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 3.1268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 166ms/step - loss: 3.1257 - val_loss: 3.1604\n",
            "Epoch 152/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 3.0629"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 183ms/step - loss: 3.0577 - val_loss: 3.1008\n",
            "Epoch 153/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 3.0115"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 226ms/step - loss: 3.0050 - val_loss: 3.0387\n",
            "Epoch 154/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.9310"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 167ms/step - loss: 2.9310 - val_loss: 2.9758\n",
            "Epoch 155/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 2.8840"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 185ms/step - loss: 2.8759 - val_loss: 2.9077\n",
            "Epoch 156/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.8208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 216ms/step - loss: 2.8208 - val_loss: 2.8502\n",
            "Epoch 157/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.7508"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 2.7508 - val_loss: 2.8062\n",
            "Epoch 158/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 2.7036"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 187ms/step - loss: 2.7030 - val_loss: 2.7517\n",
            "Epoch 159/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.6406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 181ms/step - loss: 2.6406 - val_loss: 2.6998\n",
            "Epoch 160/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.5944"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 213ms/step - loss: 2.5944 - val_loss: 2.6500\n",
            "Epoch 161/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 2.5419"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 189ms/step - loss: 2.5409 - val_loss: 2.5883\n",
            "Epoch 162/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 2.5004"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 165ms/step - loss: 2.4965 - val_loss: 2.5414\n",
            "Epoch 163/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.4444"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 223ms/step - loss: 2.4444 - val_loss: 2.4953\n",
            "Epoch 164/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 2.4009"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 207ms/step - loss: 2.3931 - val_loss: 2.4423\n",
            "Epoch 165/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 2.3407"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 200ms/step - loss: 2.3496 - val_loss: 2.3897\n",
            "Epoch 166/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.3031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 236ms/step - loss: 2.3031 - val_loss: 2.3435\n",
            "Epoch 167/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 2.2540"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 166ms/step - loss: 2.2612 - val_loss: 2.2993\n",
            "Epoch 168/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 2.2393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 2.2210 - val_loss: 2.2687\n",
            "Epoch 169/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 2.1797"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 220ms/step - loss: 2.1777 - val_loss: 2.2276\n",
            "Epoch 170/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 2.1398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 198ms/step - loss: 2.1318 - val_loss: 2.1904\n",
            "Epoch 171/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.0929"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 2.0929 - val_loss: 2.1427\n",
            "Epoch 172/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 2.0625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 185ms/step - loss: 2.0625 - val_loss: 2.0950\n",
            "Epoch 173/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 2.0148"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 233ms/step - loss: 2.0139 - val_loss: 2.0662\n",
            "Epoch 174/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.9849"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 184ms/step - loss: 1.9813 - val_loss: 2.0379\n",
            "Epoch 175/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.9492"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 165ms/step - loss: 1.9539 - val_loss: 1.9927\n",
            "Epoch 176/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.9201"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 214ms/step - loss: 1.9163 - val_loss: 1.9583\n",
            "Epoch 177/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.8763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 207ms/step - loss: 1.8767 - val_loss: 1.9346\n",
            "Epoch 178/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.8453"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 167ms/step - loss: 1.8453 - val_loss: 1.9056\n",
            "Epoch 179/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.8181"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 204ms/step - loss: 1.8181 - val_loss: 1.8656\n",
            "Epoch 180/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.7828"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 218ms/step - loss: 1.7829 - val_loss: 1.8368\n",
            "Epoch 181/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.7491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 169ms/step - loss: 1.7526 - val_loss: 1.8093\n",
            "Epoch 182/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.7237"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 191ms/step - loss: 1.7236 - val_loss: 1.7885\n",
            "Epoch 183/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.6927"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 233ms/step - loss: 1.6927 - val_loss: 1.7454\n",
            "Epoch 184/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.6748"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 165ms/step - loss: 1.6659 - val_loss: 1.7203\n",
            "Epoch 185/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.6375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 186ms/step - loss: 1.6375 - val_loss: 1.6994\n",
            "Epoch 186/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.6134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 204ms/step - loss: 1.6134 - val_loss: 1.6807\n",
            "Epoch 187/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.5921"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 192ms/step - loss: 1.5894 - val_loss: 1.6620\n",
            "Epoch 188/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.5614"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 184ms/step - loss: 1.5612 - val_loss: 1.6406\n",
            "Epoch 189/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.5385"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 1.5395 - val_loss: 1.5808\n",
            "Epoch 190/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.5167"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 245ms/step - loss: 1.5149 - val_loss: 1.5598\n",
            "Epoch 191/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 1.4807"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 1.4872 - val_loss: 1.5409\n",
            "Epoch 192/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.4799"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 1.4721 - val_loss: 1.5163\n",
            "Epoch 193/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.4448"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 232ms/step - loss: 1.4406 - val_loss: 1.4983\n",
            "Epoch 194/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.4146"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 1.4187 - val_loss: 1.4757\n",
            "Epoch 195/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 1.4039"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 166ms/step - loss: 1.3974 - val_loss: 1.4494\n",
            "Epoch 196/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.3797"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 208ms/step - loss: 1.3801 - val_loss: 1.4336\n",
            "Epoch 197/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.3663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 211ms/step - loss: 1.3652 - val_loss: 1.4142\n",
            "Epoch 198/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.3522"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 183ms/step - loss: 1.3481 - val_loss: 1.4037\n",
            "Epoch 199/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 1.3246"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 161ms/step - loss: 1.3198 - val_loss: 1.3976\n",
            "Epoch 200/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.3112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 224ms/step - loss: 1.3031 - val_loss: 1.3741\n",
            "Epoch 201/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.2848"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 189ms/step - loss: 1.2860 - val_loss: 1.3497\n",
            "Epoch 202/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.2637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 170ms/step - loss: 1.2622 - val_loss: 1.3403\n",
            "Epoch 203/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 1.2550"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 196ms/step - loss: 1.2544 - val_loss: 1.3095\n",
            "Epoch 204/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.2431"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 215ms/step - loss: 1.2390 - val_loss: 1.2918\n",
            "Epoch 205/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.2282 - val_loss: 1.3086\n",
            "Epoch 206/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.2516"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 166ms/step - loss: 1.2444 - val_loss: 1.2918\n",
            "Epoch 207/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.2254"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 165ms/step - loss: 1.2275 - val_loss: 1.2711\n",
            "Epoch 208/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.2089"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 249ms/step - loss: 1.2069 - val_loss: 1.2621\n",
            "Epoch 209/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.2079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 171ms/step - loss: 1.1981 - val_loss: 1.2480\n",
            "Epoch 210/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.1796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 188ms/step - loss: 1.1791 - val_loss: 1.2336\n",
            "Epoch 211/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.1667"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 225ms/step - loss: 1.1692 - val_loss: 1.2212\n",
            "Epoch 212/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.1414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 165ms/step - loss: 1.1374 - val_loss: 1.2194\n",
            "Epoch 213/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.1303"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 186ms/step - loss: 1.1325 - val_loss: 1.2031\n",
            "Epoch 214/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.1181"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 194ms/step - loss: 1.1181 - val_loss: 1.2015\n",
            "Epoch 215/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.1136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 204ms/step - loss: 1.1090 - val_loss: 1.1815\n",
            "Epoch 216/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0950"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 182ms/step - loss: 1.0950 - val_loss: 1.1609\n",
            "Epoch 217/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.0899"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 1.0859 - val_loss: 1.1514\n",
            "Epoch 218/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.0695"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 284ms/step - loss: 1.0731 - val_loss: 1.1271\n",
            "Epoch 219/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.0529"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 195ms/step - loss: 1.0580 - val_loss: 1.1147\n",
            "Epoch 220/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.0504"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 165ms/step - loss: 1.0519 - val_loss: 1.0993\n",
            "Epoch 221/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 1.0433"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 223ms/step - loss: 1.0394 - val_loss: 1.0939\n",
            "Epoch 222/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.0245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 188ms/step - loss: 1.0291 - val_loss: 1.0832\n",
            "Epoch 223/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.0150"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 161ms/step - loss: 1.0133 - val_loss: 1.0707\n",
            "Epoch 224/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 182ms/step - loss: 1.0031 - val_loss: 1.0655\n",
            "Epoch 225/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.0031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 229ms/step - loss: 0.9962 - val_loss: 1.0534\n",
            "Epoch 226/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.9833"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 183ms/step - loss: 0.9877 - val_loss: 1.0396\n",
            "Epoch 227/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.9789"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 164ms/step - loss: 0.9798 - val_loss: 1.0327\n",
            "Epoch 228/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.9632 - val_loss: 1.0333\n",
            "Epoch 229/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.9637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 214ms/step - loss: 0.9621 - val_loss: 1.0215\n",
            "Epoch 230/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9444"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 199ms/step - loss: 0.9444 - val_loss: 1.0125\n",
            "Epoch 231/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.9378"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 166ms/step - loss: 0.9399 - val_loss: 0.9968\n",
            "Epoch 232/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9329 - val_loss: 1.0026\n",
            "Epoch 233/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.9317"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 187ms/step - loss: 0.9299 - val_loss: 0.9884\n",
            "Epoch 234/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.9229"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 231ms/step - loss: 0.9220 - val_loss: 0.9700\n",
            "Epoch 235/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.9047 - val_loss: 0.9703\n",
            "Epoch 236/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9035"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 165ms/step - loss: 0.9035 - val_loss: 0.9608\n",
            "Epoch 237/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.8839"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 0.8842 - val_loss: 0.9524\n",
            "Epoch 238/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.8746"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 249ms/step - loss: 0.8819 - val_loss: 0.9415\n",
            "Epoch 239/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.8692 - val_loss: 0.9445\n",
            "Epoch 240/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.8793"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 0.8744 - val_loss: 0.9270\n",
            "Epoch 241/1000\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.8658"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 182ms/step - loss: 0.8676 - val_loss: 0.9157\n",
            "Epoch 242/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.8536"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 220ms/step - loss: 0.8586 - val_loss: 0.9121\n",
            "Epoch 243/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.8563"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 166ms/step - loss: 0.8537 - val_loss: 0.9098\n",
            "Epoch 244/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.8498"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 192ms/step - loss: 0.8462 - val_loss: 0.9064\n",
            "Epoch 245/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 195ms/step - loss: 0.8398 - val_loss: 0.9059\n",
            "Epoch 246/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.8389"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 202ms/step - loss: 0.8366 - val_loss: 0.8929\n",
            "Epoch 247/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.8239"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 188ms/step - loss: 0.8260 - val_loss: 0.8808\n",
            "Epoch 248/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.8218"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 173ms/step - loss: 0.8189 - val_loss: 0.8770\n",
            "Epoch 249/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.8164 - val_loss: 0.8866\n",
            "Epoch 250/1000\n",
            "22/22 [==============================] - 1s 43ms/step - loss: 0.8071 - val_loss: 0.8804\n",
            "Epoch 251/1000\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.8032 - val_loss: 0.8775\n",
            "Epoch 252/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.7973"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 186ms/step - loss: 0.7987 - val_loss: 0.8577\n",
            "Epoch 253/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.7945 - val_loss: 0.8603\n",
            "Epoch 254/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7966"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 185ms/step - loss: 0.7966 - val_loss: 0.8430\n",
            "Epoch 255/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7866"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 169ms/step - loss: 0.7891 - val_loss: 0.8345\n",
            "Epoch 256/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7794 - val_loss: 0.8359\n",
            "Epoch 257/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.7793"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 246ms/step - loss: 0.7827 - val_loss: 0.8303\n",
            "Epoch 258/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7724"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 167ms/step - loss: 0.7753 - val_loss: 0.8280\n",
            "Epoch 259/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.7693"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 165ms/step - loss: 0.7726 - val_loss: 0.8224\n",
            "Epoch 260/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7698 - val_loss: 0.8236\n",
            "Epoch 261/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.7577"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 241ms/step - loss: 0.7657 - val_loss: 0.8183\n",
            "Epoch 262/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7545 - val_loss: 0.8233\n",
            "Epoch 263/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.7567 - val_loss: 0.8217\n",
            "Epoch 264/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 154ms/step - loss: 0.7474 - val_loss: 0.8176\n",
            "Epoch 265/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7505"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 161ms/step - loss: 0.7505 - val_loss: 0.8062\n",
            "Epoch 266/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7435 - val_loss: 0.8123\n",
            "Epoch 267/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7571"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 232ms/step - loss: 0.7485 - val_loss: 0.7936\n",
            "Epoch 268/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.7400 - val_loss: 0.7959\n",
            "Epoch 269/1000\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.7387 - val_loss: 0.7957\n",
            "Epoch 270/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.7394"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 0.7370 - val_loss: 0.7907\n",
            "Epoch 271/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7267 - val_loss: 0.7980\n",
            "Epoch 272/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7188 - val_loss: 0.7952\n",
            "Epoch 273/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7234"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 186ms/step - loss: 0.7234 - val_loss: 0.7899\n",
            "Epoch 274/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7132"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 206ms/step - loss: 0.7129 - val_loss: 0.7836\n",
            "Epoch 275/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7198"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 192ms/step - loss: 0.7198 - val_loss: 0.7808\n",
            "Epoch 276/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7104"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 190ms/step - loss: 0.7078 - val_loss: 0.7767\n",
            "Epoch 277/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.7063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 176ms/step - loss: 0.7093 - val_loss: 0.7761\n",
            "Epoch 278/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.7116"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 221ms/step - loss: 0.7060 - val_loss: 0.7726\n",
            "Epoch 279/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.7044"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 187ms/step - loss: 0.7063 - val_loss: 0.7659\n",
            "Epoch 280/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.7017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 170ms/step - loss: 0.7055 - val_loss: 0.7603\n",
            "Epoch 281/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.7048"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 224ms/step - loss: 0.7048 - val_loss: 0.7592\n",
            "Epoch 282/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6944 - val_loss: 0.7683\n",
            "Epoch 283/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6937 - val_loss: 0.7682\n",
            "Epoch 284/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6917 - val_loss: 0.7602\n",
            "Epoch 285/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6928"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 177ms/step - loss: 0.6944 - val_loss: 0.7556\n",
            "Epoch 286/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6895 - val_loss: 0.7566\n",
            "Epoch 287/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6866 - val_loss: 0.7573\n",
            "Epoch 288/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6856"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 158ms/step - loss: 0.6847 - val_loss: 0.7466\n",
            "Epoch 289/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6855 - val_loss: 0.7470\n",
            "Epoch 290/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6829 - val_loss: 0.7508\n",
            "Epoch 291/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6815"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 241ms/step - loss: 0.6863 - val_loss: 0.7378\n",
            "Epoch 292/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6770 - val_loss: 0.7405\n",
            "Epoch 293/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6773 - val_loss: 0.7476\n",
            "Epoch 294/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6816 - val_loss: 0.7412\n",
            "Epoch 295/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6720 - val_loss: 0.7448\n",
            "Epoch 296/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6751"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 155ms/step - loss: 0.6750 - val_loss: 0.7378\n",
            "Epoch 297/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6700"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 234ms/step - loss: 0.6725 - val_loss: 0.7310\n",
            "Epoch 298/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6661"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 251ms/step - loss: 0.6660 - val_loss: 0.7281\n",
            "Epoch 299/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6768"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 0.6768 - val_loss: 0.7278\n",
            "Epoch 300/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6698 - val_loss: 0.7355\n",
            "Epoch 301/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6658 - val_loss: 0.7297\n",
            "Epoch 302/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6637 - val_loss: 0.7286\n",
            "Epoch 303/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6721 - val_loss: 0.7295\n",
            "Epoch 304/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6573 - val_loss: 0.7317\n",
            "Epoch 305/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6549 - val_loss: 0.7307\n",
            "Epoch 306/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6597 - val_loss: 0.7323\n",
            "Epoch 307/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6600 - val_loss: 0.7390\n",
            "Epoch 308/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6545 - val_loss: 0.7482\n",
            "Epoch 309/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6700 - val_loss: 0.7301\n",
            "Epoch 310/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6598"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 209ms/step - loss: 0.6598 - val_loss: 0.7238\n",
            "Epoch 311/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6662"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 183ms/step - loss: 0.6625 - val_loss: 0.7193\n",
            "Epoch 312/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6577 - val_loss: 0.7276\n",
            "Epoch 313/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6519 - val_loss: 0.7311\n",
            "Epoch 314/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6443"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 0.6443 - val_loss: 0.7184\n",
            "Epoch 315/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6478 - val_loss: 0.7217\n",
            "Epoch 316/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6480"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 234ms/step - loss: 0.6448 - val_loss: 0.7147\n",
            "Epoch 317/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6486"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 170ms/step - loss: 0.6486 - val_loss: 0.7108\n",
            "Epoch 318/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6495 - val_loss: 0.7114\n",
            "Epoch 319/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6486 - val_loss: 0.7161\n",
            "Epoch 320/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6499 - val_loss: 0.7124\n",
            "Epoch 321/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6372"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 156ms/step - loss: 0.6415 - val_loss: 0.6986\n",
            "Epoch 322/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6533 - val_loss: 0.7038\n",
            "Epoch 323/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6422 - val_loss: 0.7019\n",
            "Epoch 324/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6421 - val_loss: 0.7029\n",
            "Epoch 325/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6404 - val_loss: 0.7002\n",
            "Epoch 326/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6406 - val_loss: 0.7065\n",
            "Epoch 327/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6428 - val_loss: 0.7037\n",
            "Epoch 328/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6367 - val_loss: 0.7172\n",
            "Epoch 329/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 227ms/step - loss: 0.6456 - val_loss: 0.6980\n",
            "Epoch 330/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6429"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 166ms/step - loss: 0.6443 - val_loss: 0.6967\n",
            "Epoch 331/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6347 - val_loss: 0.7092\n",
            "Epoch 332/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6382 - val_loss: 0.7053\n",
            "Epoch 333/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6381 - val_loss: 0.7052\n",
            "Epoch 334/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6310 - val_loss: 0.7083\n",
            "Epoch 335/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6354 - val_loss: 0.7000\n",
            "Epoch 336/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6314"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 155ms/step - loss: 0.6331 - val_loss: 0.6892\n",
            "Epoch 337/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6391 - val_loss: 0.6917\n",
            "Epoch 338/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 246ms/step - loss: 0.6366 - val_loss: 0.6882\n",
            "Epoch 339/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6386 - val_loss: 0.6992\n",
            "Epoch 340/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6281 - val_loss: 0.7130\n",
            "Epoch 341/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6317 - val_loss: 0.6981\n",
            "Epoch 342/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6331 - val_loss: 0.6982\n",
            "Epoch 343/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6341 - val_loss: 0.7055\n",
            "Epoch 344/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6321 - val_loss: 0.6945\n",
            "Epoch 345/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6294 - val_loss: 0.6958\n",
            "Epoch 346/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6300 - val_loss: 0.6974\n",
            "Epoch 347/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6261 - val_loss: 0.7076\n",
            "Epoch 348/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6268 - val_loss: 0.7213\n",
            "Epoch 349/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6260 - val_loss: 0.7261\n",
            "Epoch 350/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6289 - val_loss: 0.7126\n",
            "Epoch 351/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6303 - val_loss: 0.7063\n",
            "Epoch 352/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6312 - val_loss: 0.7066\n",
            "Epoch 353/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6286 - val_loss: 0.6936\n",
            "Epoch 354/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6303 - val_loss: 0.6903\n",
            "Epoch 355/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 0.6283 - val_loss: 0.6880\n",
            "Epoch 356/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6255 - val_loss: 0.6930\n",
            "Epoch 357/1000\n",
            "22/22 [==============================] - 1s 48ms/step - loss: 0.6217 - val_loss: 0.6976\n",
            "Epoch 358/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6315 - val_loss: 0.6889\n",
            "Epoch 359/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6291"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 173ms/step - loss: 0.6343 - val_loss: 0.6851\n",
            "Epoch 360/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6293 - val_loss: 0.6871\n",
            "Epoch 361/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6251 - val_loss: 0.6889\n",
            "Epoch 362/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 185ms/step - loss: 0.6231 - val_loss: 0.6753\n",
            "Epoch 363/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6300 - val_loss: 0.6776\n",
            "Epoch 364/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6145 - val_loss: 0.6774\n",
            "Epoch 365/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6204 - val_loss: 0.6772\n",
            "Epoch 366/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6251 - val_loss: 0.6797\n",
            "Epoch 367/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6210 - val_loss: 0.6966\n",
            "Epoch 368/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6248 - val_loss: 0.6828\n",
            "Epoch 369/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6277 - val_loss: 0.6789\n",
            "Epoch 370/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6255 - val_loss: 0.6775\n",
            "Epoch 371/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6242 - val_loss: 0.6906\n",
            "Epoch 372/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6170 - val_loss: 0.6993\n",
            "Epoch 373/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6269 - val_loss: 0.6895\n",
            "Epoch 374/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6272 - val_loss: 0.6892\n",
            "Epoch 375/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6252 - val_loss: 0.6969\n",
            "Epoch 376/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6263 - val_loss: 0.6914\n",
            "Epoch 377/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6283 - val_loss: 0.6858\n",
            "Epoch 378/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6190 - val_loss: 0.6792\n",
            "Epoch 379/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6261 - val_loss: 0.6822\n",
            "Epoch 380/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6161 - val_loss: 0.6846\n",
            "Epoch 381/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6229 - val_loss: 0.6851\n",
            "Epoch 382/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6294 - val_loss: 0.6846\n",
            "Epoch 383/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6176 - val_loss: 0.6845\n",
            "Epoch 384/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6240 - val_loss: 0.6856\n",
            "Epoch 385/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6238 - val_loss: 0.6795\n",
            "Epoch 386/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.6302"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 153ms/step - loss: 0.6221 - val_loss: 0.6749\n",
            "Epoch 387/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6249 - val_loss: 0.6768\n",
            "Epoch 388/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6208 - val_loss: 0.6769\n",
            "Epoch 389/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6224 - val_loss: 0.6797\n",
            "Epoch 390/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6198 - val_loss: 0.6870\n",
            "Epoch 391/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6156 - val_loss: 0.6893\n",
            "Epoch 392/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6212 - val_loss: 0.6824\n",
            "Epoch 393/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6205 - val_loss: 0.6861\n",
            "Epoch 394/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6244 - val_loss: 0.6752\n",
            "Epoch 395/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6290"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 181ms/step - loss: 0.6302 - val_loss: 0.6740\n",
            "Epoch 396/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6242 - val_loss: 0.6875\n",
            "Epoch 397/1000\n",
            "22/22 [==============================] - 1s 44ms/step - loss: 0.6190 - val_loss: 0.6887\n",
            "Epoch 398/1000\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 0.6283 - val_loss: 0.6770\n",
            "Epoch 399/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6125 - val_loss: 0.6760\n",
            "Epoch 400/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6235 - val_loss: 0.6790\n",
            "Epoch 401/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6230 - val_loss: 0.6812\n",
            "Epoch 402/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 170ms/step - loss: 0.6305 - val_loss: 0.6721\n",
            "Epoch 403/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6157 - val_loss: 0.6787\n",
            "Epoch 404/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6173 - val_loss: 0.6791\n",
            "Epoch 405/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6208 - val_loss: 0.6853\n",
            "Epoch 406/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6205 - val_loss: 0.6861\n",
            "Epoch 407/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6265 - val_loss: 0.6846\n",
            "Epoch 408/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6250 - val_loss: 0.6829\n",
            "Epoch 409/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6193 - val_loss: 0.6781\n",
            "Epoch 410/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6212 - val_loss: 0.6793\n",
            "Epoch 411/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6191 - val_loss: 0.6728\n",
            "Epoch 412/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6211 - val_loss: 0.6769\n",
            "Epoch 413/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6208 - val_loss: 0.6907\n",
            "Epoch 414/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6145 - val_loss: 0.6835\n",
            "Epoch 415/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6230 - val_loss: 0.6791\n",
            "Epoch 416/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6225 - val_loss: 0.6801\n",
            "Epoch 417/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6184 - val_loss: 0.6749\n",
            "Epoch 418/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6211 - val_loss: 0.6745\n",
            "Epoch 419/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6155 - val_loss: 0.6749\n",
            "Epoch 420/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6205 - val_loss: 0.6786\n",
            "Epoch 421/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6190 - val_loss: 0.6809\n",
            "Epoch 422/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6166 - val_loss: 0.6871\n",
            "Epoch 423/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6207 - val_loss: 0.6817\n",
            "Epoch 424/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6184 - val_loss: 0.6890\n",
            "Epoch 425/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6178 - val_loss: 0.6761\n",
            "Epoch 426/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6199 - val_loss: 0.6782\n",
            "Epoch 427/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6176 - val_loss: 0.6877\n",
            "Epoch 428/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6201 - val_loss: 0.7004\n",
            "Epoch 429/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6159 - val_loss: 0.6840\n",
            "Epoch 430/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6156 - val_loss: 0.6947\n",
            "Epoch 431/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6190 - val_loss: 0.6973\n",
            "Epoch 432/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6181 - val_loss: 0.6765\n",
            "Epoch 433/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6142 - val_loss: 0.6848\n",
            "Epoch 434/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6204 - val_loss: 0.6789\n",
            "Epoch 435/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6228 - val_loss: 0.6886\n",
            "Epoch 436/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6185 - val_loss: 0.6808\n",
            "Epoch 437/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6174 - val_loss: 0.6846\n",
            "Epoch 438/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6148 - val_loss: 0.6804\n",
            "Epoch 439/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6242 - val_loss: 0.6744\n",
            "Epoch 440/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6175 - val_loss: 0.6790\n",
            "Epoch 441/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6240 - val_loss: 0.6814\n",
            "Epoch 442/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6140 - val_loss: 0.6783\n",
            "Epoch 443/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6169 - val_loss: 0.6990\n",
            "Epoch 444/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6146 - val_loss: 0.7016\n",
            "Epoch 445/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6144 - val_loss: 0.7012\n",
            "Epoch 446/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6203 - val_loss: 0.6949\n",
            "Epoch 447/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6214 - val_loss: 0.6796\n",
            "Epoch 448/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6157 - val_loss: 0.6854\n",
            "Epoch 449/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6116 - val_loss: 0.6765\n",
            "Epoch 450/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6186 - val_loss: 0.6731\n",
            "Epoch 451/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6179 - val_loss: 0.6773\n",
            "Epoch 452/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6289 - val_loss: 0.6750\n",
            "Epoch 453/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6128 - val_loss: 0.6747\n",
            "Epoch 454/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6217 - val_loss: 0.6808\n",
            "Epoch 455/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6201 - val_loss: 0.6812\n",
            "Epoch 456/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6202 - val_loss: 0.6801\n",
            "Epoch 457/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6065 - val_loss: 0.6866\n",
            "Epoch 458/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6216 - val_loss: 0.6760\n",
            "Epoch 459/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6198 - val_loss: 0.6744\n",
            "Epoch 460/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6156 - val_loss: 0.6812\n",
            "Epoch 461/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6202 - val_loss: 0.6856\n",
            "Epoch 462/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6115 - val_loss: 0.6938\n",
            "Epoch 463/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6206 - val_loss: 0.6843\n",
            "Epoch 464/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6171 - val_loss: 0.6795\n",
            "Epoch 465/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6130 - val_loss: 0.6759\n",
            "Epoch 466/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6210"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 180ms/step - loss: 0.6202 - val_loss: 0.6709\n",
            "Epoch 467/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6126 - val_loss: 0.6728\n",
            "Epoch 468/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6307"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 184ms/step - loss: 0.6252 - val_loss: 0.6668\n",
            "Epoch 469/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6133 - val_loss: 0.6761\n",
            "Epoch 470/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6186 - val_loss: 0.6781\n",
            "Epoch 471/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6184 - val_loss: 0.6825\n",
            "Epoch 472/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6200 - val_loss: 0.6767\n",
            "Epoch 473/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6208 - val_loss: 0.6766\n",
            "Epoch 474/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6154 - val_loss: 0.6841\n",
            "Epoch 475/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6227 - val_loss: 0.6746\n",
            "Epoch 476/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6212 - val_loss: 0.6736\n",
            "Epoch 477/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6224 - val_loss: 0.6782\n",
            "Epoch 478/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6210 - val_loss: 0.6797\n",
            "Epoch 479/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6197 - val_loss: 0.6720\n",
            "Epoch 480/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6107 - val_loss: 0.6762\n",
            "Epoch 481/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6239 - val_loss: 0.6682\n",
            "Epoch 482/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6090 - val_loss: 0.6710\n",
            "Epoch 483/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6099 - val_loss: 0.6717\n",
            "Epoch 484/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6158 - val_loss: 0.6827\n",
            "Epoch 485/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6247 - val_loss: 0.6820\n",
            "Epoch 486/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6171 - val_loss: 0.6815\n",
            "Epoch 487/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6200 - val_loss: 0.6844\n",
            "Epoch 488/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6167 - val_loss: 0.6789\n",
            "Epoch 489/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6207 - val_loss: 0.6705\n",
            "Epoch 490/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6129 - val_loss: 0.6858\n",
            "Epoch 491/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6163 - val_loss: 0.6827\n",
            "Epoch 492/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6204 - val_loss: 0.6835\n",
            "Epoch 493/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6109 - val_loss: 0.6900\n",
            "Epoch 494/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6124 - val_loss: 0.6926\n",
            "Epoch 495/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6136 - val_loss: 0.6850\n",
            "Epoch 496/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6232 - val_loss: 0.6711\n",
            "Epoch 497/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6179 - val_loss: 0.6745\n",
            "Epoch 498/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6101 - val_loss: 0.6750\n",
            "Epoch 499/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6232 - val_loss: 0.6774\n",
            "Epoch 500/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6266 - val_loss: 0.6676\n",
            "Epoch 501/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6191 - val_loss: 0.6733\n",
            "Epoch 502/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6166 - val_loss: 0.6795\n",
            "Epoch 503/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6162 - val_loss: 0.6819\n",
            "Epoch 504/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6238 - val_loss: 0.6739\n",
            "Epoch 505/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6228 - val_loss: 0.6781\n",
            "Epoch 506/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6155 - val_loss: 0.6824\n",
            "Epoch 507/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6186 - val_loss: 0.6791\n",
            "Epoch 508/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6191 - val_loss: 0.6782\n",
            "Epoch 509/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6217 - val_loss: 0.6844\n",
            "Epoch 510/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6176 - val_loss: 0.6877\n",
            "Epoch 511/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6152 - val_loss: 0.6750\n",
            "Epoch 512/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6173 - val_loss: 0.6761\n",
            "Epoch 513/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6185 - val_loss: 0.6836\n",
            "Epoch 514/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6160 - val_loss: 0.6914\n",
            "Epoch 515/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6207 - val_loss: 0.6812\n",
            "Epoch 516/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6245 - val_loss: 0.6744\n",
            "Epoch 517/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6169 - val_loss: 0.6868\n",
            "Epoch 518/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6225 - val_loss: 0.6748\n",
            "Epoch 519/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6162 - val_loss: 0.6889\n",
            "Epoch 520/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6216 - val_loss: 0.6681\n",
            "Epoch 521/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6180 - val_loss: 0.6776\n",
            "Epoch 522/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6203 - val_loss: 0.6701\n",
            "Epoch 523/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6132 - val_loss: 0.6825\n",
            "Epoch 524/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6246 - val_loss: 0.6690\n",
            "Epoch 525/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6196 - val_loss: 0.6736\n",
            "Epoch 526/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6059 - val_loss: 0.6812\n",
            "Epoch 527/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6171 - val_loss: 0.6861\n",
            "Epoch 528/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6154 - val_loss: 0.6785\n",
            "Epoch 529/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6207 - val_loss: 0.6777\n",
            "Epoch 530/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6198 - val_loss: 0.6792\n",
            "Epoch 531/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6189 - val_loss: 0.6762\n",
            "Epoch 532/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6227 - val_loss: 0.6778\n",
            "Epoch 533/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6161 - val_loss: 0.6776\n",
            "Epoch 534/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6178 - val_loss: 0.6820\n",
            "Epoch 535/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5689 - val_loss: 1.8953\n",
            "Epoch 536/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.8254 - val_loss: 1.8623\n",
            "Epoch 537/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.7892 - val_loss: 1.8316\n",
            "Epoch 538/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.7594 - val_loss: 1.8001\n",
            "Epoch 539/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.7275 - val_loss: 1.7850\n",
            "Epoch 540/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.7101 - val_loss: 1.7533\n",
            "Epoch 541/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.6732 - val_loss: 1.7295\n",
            "Epoch 542/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.6612 - val_loss: 1.6952\n",
            "Epoch 543/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.6184 - val_loss: 1.6763\n",
            "Epoch 544/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.5930 - val_loss: 1.6565\n",
            "Epoch 545/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.5653 - val_loss: 1.6258\n",
            "Epoch 546/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.5519 - val_loss: 1.5907\n",
            "Epoch 547/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.5196 - val_loss: 1.5676\n",
            "Epoch 548/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.4940 - val_loss: 1.5418\n",
            "Epoch 549/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4735 - val_loss: 1.5194\n",
            "Epoch 550/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.4517 - val_loss: 1.4994\n",
            "Epoch 551/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.4299 - val_loss: 1.4815\n",
            "Epoch 552/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.4055 - val_loss: 1.4614\n",
            "Epoch 553/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.3890 - val_loss: 1.4390\n",
            "Epoch 554/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.3608 - val_loss: 1.4240\n",
            "Epoch 555/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.3441 - val_loss: 1.4111\n",
            "Epoch 556/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.3310 - val_loss: 1.3987\n",
            "Epoch 557/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.3222 - val_loss: 1.3727\n",
            "Epoch 558/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.2872 - val_loss: 1.3609\n",
            "Epoch 559/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.2780 - val_loss: 1.3268\n",
            "Epoch 560/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.2542 - val_loss: 1.3053\n",
            "Epoch 561/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2465 - val_loss: 1.2895\n",
            "Epoch 562/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.2185 - val_loss: 1.2752\n",
            "Epoch 563/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.2076 - val_loss: 1.2632\n",
            "Epoch 564/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.1894 - val_loss: 1.2554\n",
            "Epoch 565/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.1807 - val_loss: 1.2267\n",
            "Epoch 566/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.1646 - val_loss: 1.2301\n",
            "Epoch 567/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.1467 - val_loss: 1.2187\n",
            "Epoch 568/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.1374 - val_loss: 1.1873\n",
            "Epoch 569/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.1239 - val_loss: 1.1819\n",
            "Epoch 570/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.1080 - val_loss: 1.1730\n",
            "Epoch 571/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.0990 - val_loss: 1.1544\n",
            "Epoch 572/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0844 - val_loss: 1.1456\n",
            "Epoch 573/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0794 - val_loss: 1.1308\n",
            "Epoch 574/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.0609 - val_loss: 1.1230\n",
            "Epoch 575/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0472 - val_loss: 1.1060\n",
            "Epoch 576/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0364 - val_loss: 1.0968\n",
            "Epoch 577/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0202 - val_loss: 1.0888\n",
            "Epoch 578/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.0154 - val_loss: 1.0809\n",
            "Epoch 579/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0058 - val_loss: 1.0731\n",
            "Epoch 580/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9858 - val_loss: 1.0620\n",
            "Epoch 581/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9865 - val_loss: 1.0431\n",
            "Epoch 582/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.9745 - val_loss: 1.0343\n",
            "Epoch 583/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9678 - val_loss: 1.0240\n",
            "Epoch 584/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.9567 - val_loss: 1.0037\n",
            "Epoch 585/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9500 - val_loss: 1.0013\n",
            "Epoch 586/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.9418 - val_loss: 0.9923\n",
            "Epoch 587/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.9286 - val_loss: 0.9970\n",
            "Epoch 588/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9200 - val_loss: 0.9914\n",
            "Epoch 589/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9070 - val_loss: 0.9772\n",
            "Epoch 590/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9019 - val_loss: 0.9722\n",
            "Epoch 591/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.9073 - val_loss: 0.9592\n",
            "Epoch 592/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.8958 - val_loss: 0.9542\n",
            "Epoch 593/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.8821 - val_loss: 0.9445\n",
            "Epoch 594/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.8759 - val_loss: 0.9349\n",
            "Epoch 595/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.8814 - val_loss: 0.9219\n",
            "Epoch 596/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.8655 - val_loss: 0.9242\n",
            "Epoch 597/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.8592 - val_loss: 0.9206\n",
            "Epoch 598/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.8479 - val_loss: 0.9124\n",
            "Epoch 599/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.8455 - val_loss: 0.9093\n",
            "Epoch 600/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.8468 - val_loss: 0.8956\n",
            "Epoch 601/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.8408 - val_loss: 0.8853\n",
            "Epoch 602/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.8276 - val_loss: 0.8886\n",
            "Epoch 603/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.8186 - val_loss: 0.8826\n",
            "Epoch 604/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.8155 - val_loss: 0.8829\n",
            "Epoch 605/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.8080 - val_loss: 0.8752\n",
            "Epoch 606/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.8118 - val_loss: 0.8727\n",
            "Epoch 607/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.8013 - val_loss: 4.6051\n",
            "Epoch 608/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 4.4924 - val_loss: 4.4998\n",
            "Epoch 609/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 4.3903 - val_loss: 4.3996\n",
            "Epoch 610/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.3004 - val_loss: 4.2992\n",
            "Epoch 611/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 4.1976 - val_loss: 26.2510\n",
            "Epoch 612/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 10.6657 - val_loss: 10.5925\n",
            "Epoch 613/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.4149 - val_loss: 10.3317\n",
            "Epoch 614/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.1561 - val_loss: 10.0697\n",
            "Epoch 615/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 9.9089 - val_loss: 9.8352\n",
            "Epoch 616/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 9.6694 - val_loss: 9.5983\n",
            "Epoch 617/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 9.4191 - val_loss: 9.3695\n",
            "Epoch 618/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 9.1984 - val_loss: 9.1568\n",
            "Epoch 619/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.9767 - val_loss: 8.9229\n",
            "Epoch 620/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 8.7559 - val_loss: 8.7097\n",
            "Epoch 621/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 8.5496 - val_loss: 8.5009\n",
            "Epoch 622/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 8.3476 - val_loss: 8.2979\n",
            "Epoch 623/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.1341 - val_loss: 8.1198\n",
            "Epoch 624/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 7.9463 - val_loss: 7.9077\n",
            "Epoch 625/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 7.7547 - val_loss: 7.7134\n",
            "Epoch 626/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.5719 - val_loss: 7.5286\n",
            "Epoch 627/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.3894 - val_loss: 7.3510\n",
            "Epoch 628/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 7.2139 - val_loss: 7.1753\n",
            "Epoch 629/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 7.0398 - val_loss: 7.0119\n",
            "Epoch 630/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.8735 - val_loss: 6.8444\n",
            "Epoch 631/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 6.7097 - val_loss: 6.6807\n",
            "Epoch 632/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.5534 - val_loss: 6.5212\n",
            "Epoch 633/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.3943 - val_loss: 6.3757\n",
            "Epoch 634/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.2502 - val_loss: 6.2252\n",
            "Epoch 635/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 6.0976 - val_loss: 6.0825\n",
            "Epoch 636/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.9515 - val_loss: 5.9400\n",
            "Epoch 637/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.8099 - val_loss: 5.8086\n",
            "Epoch 638/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 5.6812 - val_loss: 5.6696\n",
            "Epoch 639/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 5.5495 - val_loss: 5.5425\n",
            "Epoch 640/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 5.4279 - val_loss: 5.4093\n",
            "Epoch 641/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 5.2975 - val_loss: 5.2980\n",
            "Epoch 642/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 5.1784 - val_loss: 5.1749\n",
            "Epoch 643/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 5.0505 - val_loss: 5.0606\n",
            "Epoch 644/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 4.9474 - val_loss: 4.9395\n",
            "Epoch 645/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 4.8309 - val_loss: 4.8268\n",
            "Epoch 646/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 4.7209 - val_loss: 4.7217\n",
            "Epoch 647/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 4.6168 - val_loss: 4.6171\n",
            "Epoch 648/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 4.5042 - val_loss: 4.5317\n",
            "Epoch 649/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 4.4071 - val_loss: 4.4200\n",
            "Epoch 650/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 4.3127 - val_loss: 4.3048\n",
            "Epoch 651/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.2203 - val_loss: 4.2133\n",
            "Epoch 652/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 4.1311 - val_loss: 4.1167\n",
            "Epoch 653/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.0230 - val_loss: 4.0311\n",
            "Epoch 654/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.9452 - val_loss: 3.9448\n",
            "Epoch 655/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 3.8667 - val_loss: 3.8476\n",
            "Epoch 656/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.7655 - val_loss: 3.7718\n",
            "Epoch 657/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.6899 - val_loss: 3.6983\n",
            "Epoch 658/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 3.6040 - val_loss: 3.6234\n",
            "Epoch 659/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.5297 - val_loss: 3.5344\n",
            "Epoch 660/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 3.4548 - val_loss: 3.4611\n",
            "Epoch 661/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.3786 - val_loss: 3.3930\n",
            "Epoch 662/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.3182 - val_loss: 3.3162\n",
            "Epoch 663/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.2366 - val_loss: 3.2458\n",
            "Epoch 664/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 3.1713 - val_loss: 3.1867\n",
            "Epoch 665/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.1009 - val_loss: 3.1141\n",
            "Epoch 666/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.0467 - val_loss: 3.0486\n",
            "Epoch 667/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.9749 - val_loss: 2.9818\n",
            "Epoch 668/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.9182 - val_loss: 2.9288\n",
            "Epoch 669/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.8562 - val_loss: 2.8743\n",
            "Epoch 670/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.8016 - val_loss: 2.8130\n",
            "Epoch 671/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.7395 - val_loss: 2.7623\n",
            "Epoch 672/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.6894 - val_loss: 2.7041\n",
            "Epoch 673/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 2.6304 - val_loss: 2.6583\n",
            "Epoch 674/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.5747 - val_loss: 2.6023\n",
            "Epoch 675/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.5271 - val_loss: 2.5476\n",
            "Epoch 676/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.4740 - val_loss: 2.5000\n",
            "Epoch 677/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.4416 - val_loss: 2.4479\n",
            "Epoch 678/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.3848 - val_loss: 2.4113\n",
            "Epoch 679/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.3269 - val_loss: 2.3740\n",
            "Epoch 680/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.2887 - val_loss: 2.3256\n",
            "Epoch 681/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 2.2511 - val_loss: 2.2762\n",
            "Epoch 682/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.2042 - val_loss: 2.2371\n",
            "Epoch 683/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 2.1643 - val_loss: 2.1978\n",
            "Epoch 684/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.1283 - val_loss: 2.1550\n",
            "Epoch 685/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.0917 - val_loss: 2.1085\n",
            "Epoch 686/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.0460 - val_loss: 2.0726\n",
            "Epoch 687/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.0120 - val_loss: 2.0358\n",
            "Epoch 688/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 1.9705 - val_loss: 2.0021\n",
            "Epoch 689/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.9397 - val_loss: 1.9671\n",
            "Epoch 690/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.9039 - val_loss: 1.9327\n",
            "Epoch 691/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.8671 - val_loss: 1.8972\n",
            "Epoch 692/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.8267 - val_loss: 1.8715\n",
            "Epoch 693/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.8017 - val_loss: 1.8389\n",
            "Epoch 694/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.7793 - val_loss: 1.8063\n",
            "Epoch 695/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 1.7441 - val_loss: 1.7712\n",
            "Epoch 696/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.7185 - val_loss: 1.7407\n",
            "Epoch 697/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.6902 - val_loss: 1.7170\n",
            "Epoch 698/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.6574 - val_loss: 1.6908\n",
            "Epoch 699/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.6307 - val_loss: 1.6700\n",
            "Epoch 700/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.6050 - val_loss: 1.6435\n",
            "Epoch 701/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.5761 - val_loss: 1.6191\n",
            "Epoch 702/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.5601 - val_loss: 1.5968\n",
            "Epoch 703/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.5285 - val_loss: 1.5695\n",
            "Epoch 704/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.5067 - val_loss: 1.5434\n",
            "Epoch 705/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.4769 - val_loss: 1.5264\n",
            "Epoch 706/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.4645 - val_loss: 1.5009\n",
            "Epoch 707/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4428 - val_loss: 1.4800\n",
            "Epoch 708/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.4262 - val_loss: 1.4634\n",
            "Epoch 709/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.4033 - val_loss: 1.4447\n",
            "Epoch 710/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.3744 - val_loss: 1.4184\n",
            "Epoch 711/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.3541 - val_loss: 1.3981\n",
            "Epoch 712/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.3340 - val_loss: 1.3758\n",
            "Epoch 713/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3206 - val_loss: 1.3588\n",
            "Epoch 714/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.2995 - val_loss: 1.3379\n",
            "Epoch 715/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.2828 - val_loss: 1.3229\n",
            "Epoch 716/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.2649 - val_loss: 1.3076\n",
            "Epoch 717/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.2519 - val_loss: 1.2901\n",
            "Epoch 718/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.2365 - val_loss: 1.2789\n",
            "Epoch 719/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2175 - val_loss: 1.2617\n",
            "Epoch 720/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.2033 - val_loss: 1.2443\n",
            "Epoch 721/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.1877 - val_loss: 1.2325\n",
            "Epoch 722/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.1713 - val_loss: 1.2173\n",
            "Epoch 723/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.1504 - val_loss: 1.1989\n",
            "Epoch 724/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.1391 - val_loss: 1.1853\n",
            "Epoch 725/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.1295 - val_loss: 1.1728\n",
            "Epoch 726/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.1167 - val_loss: 1.1623\n",
            "Epoch 727/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.1095 - val_loss: 1.1423\n",
            "Epoch 728/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0988 - val_loss: 1.1284\n",
            "Epoch 729/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.0757 - val_loss: 1.1219\n",
            "Epoch 730/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.0707 - val_loss: 1.1114\n",
            "Epoch 731/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0571 - val_loss: 1.0975\n",
            "Epoch 732/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0432 - val_loss: 1.0877\n",
            "Epoch 733/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0284 - val_loss: 1.0812\n",
            "Epoch 734/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0200 - val_loss: 1.0722\n",
            "Epoch 735/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0063 - val_loss: 1.0591\n",
            "Epoch 736/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0050 - val_loss: 1.0524\n",
            "Epoch 737/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9972 - val_loss: 1.0400\n",
            "Epoch 738/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.9827 - val_loss: 1.0301\n",
            "Epoch 739/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.9609 - val_loss: 1.0251\n",
            "Epoch 740/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9614 - val_loss: 1.0115\n",
            "Epoch 741/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.9590 - val_loss: 1.0009\n",
            "Epoch 742/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9473 - val_loss: 0.9928\n",
            "Epoch 743/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9337 - val_loss: 0.9906\n",
            "Epoch 744/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9272 - val_loss: 0.9875\n",
            "Epoch 745/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.9209 - val_loss: 0.9713\n",
            "Epoch 746/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.9079 - val_loss: 0.9698\n",
            "Epoch 747/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.9021 - val_loss: 0.9620\n",
            "Epoch 748/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.8975 - val_loss: 0.9490\n",
            "Epoch 749/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.8843 - val_loss: 0.9436\n",
            "Epoch 750/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.8866 - val_loss: 0.9290\n",
            "Epoch 751/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.8758 - val_loss: 0.9197\n",
            "Epoch 752/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.8685 - val_loss: 0.9100\n",
            "Epoch 753/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.8589 - val_loss: 0.9037\n",
            "Epoch 754/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.8571 - val_loss: 0.8955\n",
            "Epoch 755/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.8483 - val_loss: 0.8987\n",
            "Epoch 756/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.8367 - val_loss: 0.9011\n",
            "Epoch 757/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.8405 - val_loss: 0.8929\n",
            "Epoch 758/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.8317 - val_loss: 0.8893\n",
            "Epoch 759/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.8285 - val_loss: 0.8875\n",
            "Epoch 760/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.8225 - val_loss: 0.8767\n",
            "Epoch 761/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.8236 - val_loss: 0.8706\n",
            "Epoch 762/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.8111 - val_loss: 0.8685\n",
            "Epoch 763/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.8071 - val_loss: 0.8720\n",
            "Epoch 764/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.8011 - val_loss: 0.8578\n",
            "Epoch 765/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.7969 - val_loss: 0.8571\n",
            "Epoch 766/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7938 - val_loss: 0.8450\n",
            "Epoch 767/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7780 - val_loss: 0.8468\n",
            "Epoch 768/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7854 - val_loss: 0.8314\n",
            "Epoch 769/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.7758 - val_loss: 0.8278\n",
            "Epoch 770/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7771 - val_loss: 0.8280\n",
            "Epoch 771/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7653 - val_loss: 0.8246\n",
            "Epoch 772/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7813 - val_loss: 0.8166\n",
            "Epoch 773/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7597 - val_loss: 0.8203\n",
            "Epoch 774/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7593 - val_loss: 0.8143\n",
            "Epoch 775/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7638 - val_loss: 0.8010\n",
            "Epoch 776/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7450 - val_loss: 0.8079\n",
            "Epoch 777/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7536 - val_loss: 0.8024\n",
            "Epoch 778/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7452 - val_loss: 0.7961\n",
            "Epoch 779/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.7449 - val_loss: 0.8023\n",
            "Epoch 780/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.7336 - val_loss: 0.7986\n",
            "Epoch 781/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7291 - val_loss: 0.7979\n",
            "Epoch 782/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7312 - val_loss: 0.7823\n",
            "Epoch 783/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7263 - val_loss: 0.7767\n",
            "Epoch 784/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7269 - val_loss: 0.7744\n",
            "Epoch 785/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7182 - val_loss: 0.7765\n",
            "Epoch 786/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7214 - val_loss: 0.7703\n",
            "Epoch 787/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7127 - val_loss: 0.7777\n",
            "Epoch 788/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7162 - val_loss: 0.7709\n",
            "Epoch 789/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7166 - val_loss: 0.7659\n",
            "Epoch 790/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7168 - val_loss: 0.7623\n",
            "Epoch 791/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7058 - val_loss: 0.7651\n",
            "Epoch 792/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.7142 - val_loss: 0.7587\n",
            "Epoch 793/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7081 - val_loss: 0.7534\n",
            "Epoch 794/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.7097 - val_loss: 0.7504\n",
            "Epoch 795/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6951 - val_loss: 0.7536\n",
            "Epoch 796/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6958 - val_loss: 0.7544\n",
            "Epoch 797/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6993 - val_loss: 0.7530\n",
            "Epoch 798/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6892 - val_loss: 0.7466\n",
            "Epoch 799/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6939 - val_loss: 0.7434\n",
            "Epoch 800/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6928 - val_loss: 0.7349\n",
            "Epoch 801/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6906 - val_loss: 0.7356\n",
            "Epoch 802/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6804 - val_loss: 0.7347\n",
            "Epoch 803/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6858 - val_loss: 0.7313\n",
            "Epoch 804/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6872 - val_loss: 0.7341\n",
            "Epoch 805/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6765 - val_loss: 0.7336\n",
            "Epoch 806/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6797 - val_loss: 0.7270\n",
            "Epoch 807/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6835 - val_loss: 0.7249\n",
            "Epoch 808/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6737 - val_loss: 0.7282\n",
            "Epoch 809/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6835 - val_loss: 0.7220\n",
            "Epoch 810/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6798 - val_loss: 0.7211\n",
            "Epoch 811/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6702 - val_loss: 0.7211\n",
            "Epoch 812/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6707 - val_loss: 0.7213\n",
            "Epoch 813/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6752 - val_loss: 0.7153\n",
            "Epoch 814/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6686 - val_loss: 0.7178\n",
            "Epoch 815/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6667 - val_loss: 0.7179\n",
            "Epoch 816/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6596 - val_loss: 0.7159\n",
            "Epoch 817/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6621 - val_loss: 0.7188\n",
            "Epoch 818/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6637 - val_loss: 0.7184\n",
            "Epoch 819/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6601 - val_loss: 0.7259\n",
            "Epoch 820/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6585 - val_loss: 0.7270\n",
            "Epoch 821/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6644 - val_loss: 0.7201\n",
            "Epoch 822/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6536 - val_loss: 0.7127\n",
            "Epoch 823/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6578 - val_loss: 0.7082\n",
            "Epoch 824/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6619 - val_loss: 0.7028\n",
            "Epoch 825/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6649 - val_loss: 0.7022\n",
            "Epoch 826/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6538 - val_loss: 0.7060\n",
            "Epoch 827/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6572 - val_loss: 0.7029\n",
            "Epoch 828/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6516 - val_loss: 0.7061\n",
            "Epoch 829/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6533 - val_loss: 0.7014\n",
            "Epoch 830/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6501 - val_loss: 0.7053\n",
            "Epoch 831/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6499 - val_loss: 0.7025\n",
            "Epoch 832/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6489 - val_loss: 0.7010\n",
            "Epoch 833/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6456 - val_loss: 0.7078\n",
            "Epoch 834/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6540 - val_loss: 0.6991\n",
            "Epoch 835/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6472 - val_loss: 0.7068\n",
            "Epoch 836/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6451 - val_loss: 0.7059\n",
            "Epoch 837/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6442 - val_loss: 0.7024\n",
            "Epoch 838/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6476 - val_loss: 0.6981\n",
            "Epoch 839/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6508 - val_loss: 0.7021\n",
            "Epoch 840/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6496 - val_loss: 0.6982\n",
            "Epoch 841/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6423 - val_loss: 0.6955\n",
            "Epoch 842/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6477 - val_loss: 0.6949\n",
            "Epoch 843/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6534 - val_loss: 0.6948\n",
            "Epoch 844/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6387 - val_loss: 0.6970\n",
            "Epoch 845/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6377 - val_loss: 0.6976\n",
            "Epoch 846/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6460 - val_loss: 0.6885\n",
            "Epoch 847/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6370 - val_loss: 0.6965\n",
            "Epoch 848/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6459 - val_loss: 0.6888\n",
            "Epoch 849/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6473 - val_loss: 0.6840\n",
            "Epoch 850/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6407 - val_loss: 0.6865\n",
            "Epoch 851/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6404 - val_loss: 0.6813\n",
            "Epoch 852/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6380 - val_loss: 0.6842\n",
            "Epoch 853/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6251 - val_loss: 0.6846\n",
            "Epoch 854/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6398 - val_loss: 0.6820\n",
            "Epoch 855/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6348 - val_loss: 0.6875\n",
            "Epoch 856/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6328 - val_loss: 0.6904\n",
            "Epoch 857/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6411 - val_loss: 0.6913\n",
            "Epoch 858/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6339 - val_loss: 0.6941\n",
            "Epoch 859/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6397 - val_loss: 0.6826\n",
            "Epoch 860/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6412 - val_loss: 0.6885\n",
            "Epoch 861/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6385 - val_loss: 0.6910\n",
            "Epoch 862/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6335 - val_loss: 0.6851\n",
            "Epoch 863/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6298 - val_loss: 0.6854\n",
            "Epoch 864/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6327 - val_loss: 0.6778\n",
            "Epoch 865/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6365 - val_loss: 0.6779\n",
            "Epoch 866/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6306 - val_loss: 0.6776\n",
            "Epoch 867/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6346 - val_loss: 0.6767\n",
            "Epoch 868/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6354 - val_loss: 0.6759\n",
            "Epoch 869/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6342 - val_loss: 0.6796\n",
            "Epoch 870/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6334 - val_loss: 0.6798\n",
            "Epoch 871/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6337 - val_loss: 0.6803\n",
            "Epoch 872/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6286 - val_loss: 0.6760\n",
            "Epoch 873/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6280 - val_loss: 0.6768\n",
            "Epoch 874/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6315 - val_loss: 0.6833\n",
            "Epoch 875/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6297 - val_loss: 0.6858\n",
            "Epoch 876/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6282 - val_loss: 0.6822\n",
            "Epoch 877/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6351 - val_loss: 0.6747\n",
            "Epoch 878/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6252 - val_loss: 0.6736\n",
            "Epoch 879/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6344 - val_loss: 0.6793\n",
            "Epoch 880/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6315 - val_loss: 0.6826\n",
            "Epoch 881/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6211 - val_loss: 0.6910\n",
            "Epoch 882/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6256 - val_loss: 0.6840\n",
            "Epoch 883/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6311 - val_loss: 0.6805\n",
            "Epoch 884/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6237 - val_loss: 0.6807\n",
            "Epoch 885/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6318 - val_loss: 0.6779\n",
            "Epoch 886/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6313 - val_loss: 0.6751\n",
            "Epoch 887/1000\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6291 - val_loss: 0.6768\n",
            "Epoch 888/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6227 - val_loss: 0.6777\n",
            "Epoch 889/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6222 - val_loss: 0.6792\n",
            "Epoch 890/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6218 - val_loss: 0.6834\n",
            "Epoch 891/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6254 - val_loss: 0.6811\n",
            "Epoch 892/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6188 - val_loss: 0.6828\n",
            "Epoch 893/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6159 - val_loss: 0.6871\n",
            "Epoch 894/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6339 - val_loss: 0.6729\n",
            "Epoch 895/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6237 - val_loss: 0.6781\n",
            "Epoch 896/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6301 - val_loss: 0.6757\n",
            "Epoch 897/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6298 - val_loss: 0.6820\n",
            "Epoch 898/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6267 - val_loss: 0.6765\n",
            "Epoch 899/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6246 - val_loss: 0.6757\n",
            "Epoch 900/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6304 - val_loss: 0.6746\n",
            "Epoch 901/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6346 - val_loss: 0.6723\n",
            "Epoch 902/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6247 - val_loss: 0.6702\n",
            "Epoch 903/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6260 - val_loss: 0.6728\n",
            "Epoch 904/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6233 - val_loss: 0.6731\n",
            "Epoch 905/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6120 - val_loss: 0.6829\n",
            "Epoch 906/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6239 - val_loss: 0.6823\n",
            "Epoch 907/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6166 - val_loss: 0.6799\n",
            "Epoch 908/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6265 - val_loss: 0.6738\n",
            "Epoch 909/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6230 - val_loss: 0.6751\n",
            "Epoch 910/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6213 - val_loss: 0.6722\n",
            "Epoch 911/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6242 - val_loss: 0.6683\n",
            "Epoch 912/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6311"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 180ms/step - loss: 0.6291 - val_loss: 0.6659\n",
            "Epoch 913/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6293 - val_loss: 0.6671\n",
            "Epoch 914/1000\n",
            "22/22 [==============================] - 1s 45ms/step - loss: 0.6329 - val_loss: 0.6694\n",
            "Epoch 915/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6235 - val_loss: 0.6722\n",
            "Epoch 916/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6195 - val_loss: 0.6750\n",
            "Epoch 917/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6219 - val_loss: 0.6736\n",
            "Epoch 918/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6269 - val_loss: 0.6725\n",
            "Epoch 919/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6264 - val_loss: 0.6745\n",
            "Epoch 920/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6241 - val_loss: 0.6770\n",
            "Epoch 921/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6231 - val_loss: 0.6737\n",
            "Epoch 922/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6251 - val_loss: 0.6744\n",
            "Epoch 923/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6242 - val_loss: 0.6763\n",
            "Epoch 924/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6196 - val_loss: 0.6768\n",
            "Epoch 925/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6199 - val_loss: 0.6749\n",
            "Epoch 926/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6282 - val_loss: 0.6712\n",
            "Epoch 927/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6214 - val_loss: 0.6744\n",
            "Epoch 928/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6288 - val_loss: 0.6713\n",
            "Epoch 929/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6270 - val_loss: 0.6703\n",
            "Epoch 930/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6266 - val_loss: 0.6725\n",
            "Epoch 931/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6273 - val_loss: 0.6717\n",
            "Epoch 932/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6249 - val_loss: 0.6751\n",
            "Epoch 933/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6199 - val_loss: 0.6727\n",
            "Epoch 934/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6201 - val_loss: 0.6738\n",
            "Epoch 935/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6309 - val_loss: 0.6709\n",
            "Epoch 936/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6262 - val_loss: 0.6746\n",
            "Epoch 937/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6266 - val_loss: 0.6699\n",
            "Epoch 938/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6285 - val_loss: 0.6665\n",
            "Epoch 939/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6242 - val_loss: 0.6715\n",
            "Epoch 940/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6231 - val_loss: 0.6732\n",
            "Epoch 941/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6212 - val_loss: 0.6666\n",
            "Epoch 942/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6105 - val_loss: 0.6749\n",
            "Epoch 943/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6190 - val_loss: 0.6705\n",
            "Epoch 944/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6218 - val_loss: 0.6732\n",
            "Epoch 945/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6168 - val_loss: 0.6723\n",
            "Epoch 946/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6288 - val_loss: 0.6702\n",
            "Epoch 947/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6173 - val_loss: 0.6725\n",
            "Epoch 948/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6265 - val_loss: 0.6699\n",
            "Epoch 949/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6189 - val_loss: 0.6713\n",
            "Epoch 950/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6251 - val_loss: 0.6710\n",
            "Epoch 951/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6171 - val_loss: 0.6755\n",
            "Epoch 952/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6211 - val_loss: 0.6717\n",
            "Epoch 953/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6280"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 179ms/step - loss: 0.6264 - val_loss: 0.6653\n",
            "Epoch 954/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6207 - val_loss: 0.6668\n",
            "Epoch 955/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6295 - val_loss: 0.6670\n",
            "Epoch 956/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6223 - val_loss: 0.6718\n",
            "Epoch 957/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6251 - val_loss: 0.6708\n",
            "Epoch 958/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6198 - val_loss: 0.6704\n",
            "Epoch 959/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6217 - val_loss: 0.6700\n",
            "Epoch 960/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6243 - val_loss: 0.6689\n",
            "Epoch 961/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6181 - val_loss: 0.6692\n",
            "Epoch 962/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6179 - val_loss: 0.6707\n",
            "Epoch 963/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6276"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 176ms/step - loss: 0.6276 - val_loss: 0.6617\n",
            "Epoch 964/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6188 - val_loss: 0.6639\n",
            "Epoch 965/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6308 - val_loss: 0.6660\n",
            "Epoch 966/1000\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.6209 - val_loss: 0.6687\n",
            "Epoch 967/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6204 - val_loss: 0.6673\n",
            "Epoch 968/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6199 - val_loss: 0.6684\n",
            "Epoch 969/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6267 - val_loss: 0.6672\n",
            "Epoch 970/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6275 - val_loss: 0.6692\n",
            "Epoch 971/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6219 - val_loss: 0.6745\n",
            "Epoch 972/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6199 - val_loss: 0.6748\n",
            "Epoch 973/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6251 - val_loss: 0.6727\n",
            "Epoch 974/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6239 - val_loss: 0.6710\n",
            "Epoch 975/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6281 - val_loss: 0.6645\n",
            "Epoch 976/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6217 - val_loss: 0.6680\n",
            "Epoch 977/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6182 - val_loss: 0.6707\n",
            "Epoch 978/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6302 - val_loss: 0.6720\n",
            "Epoch 979/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6253 - val_loss: 0.6747\n",
            "Epoch 980/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6270 - val_loss: 0.6741\n",
            "Epoch 981/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6207 - val_loss: 0.6709\n",
            "Epoch 982/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6266 - val_loss: 0.6681\n",
            "Epoch 983/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_113130-yslxf29b/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 156ms/step - loss: 0.6313 - val_loss: 0.6617\n",
            "Epoch 984/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6186 - val_loss: 0.6706\n",
            "Epoch 985/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6150 - val_loss: 0.6738\n",
            "Epoch 986/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6210 - val_loss: 0.6731\n",
            "Epoch 987/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6298 - val_loss: 0.6705\n",
            "Epoch 988/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6248 - val_loss: 0.6742\n",
            "Epoch 989/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6078 - val_loss: 0.6803\n",
            "Epoch 990/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6187 - val_loss: 0.6644\n",
            "Epoch 991/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6233 - val_loss: 0.6635\n",
            "Epoch 992/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6207 - val_loss: 0.6685\n",
            "Epoch 993/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6193 - val_loss: 0.6678\n",
            "Epoch 994/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6267 - val_loss: 0.6713\n",
            "Epoch 995/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6201 - val_loss: 0.6748\n",
            "Epoch 996/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6230 - val_loss: 0.6712\n",
            "Epoch 997/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6230 - val_loss: 0.6712\n",
            "Epoch 998/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6204 - val_loss: 0.6676\n",
            "Epoch 999/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6172 - val_loss: 0.6725\n",
            "Epoch 1000/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6100 - val_loss: 0.6693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c9f509df910>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Sequential()"
      ],
      "metadata": {
        "id": "xUBZasLBQVC5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.add(Dense(units=35,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model4.add(Dense(units=100,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model4.add(Dropout(0.2))\n",
        "\n",
        "model4.add(BatchNormalization())\n",
        "\n",
        "model4.add(Dense(units=100,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model4.add(Dropout(0.2))\n",
        "\n",
        "model4.add(BatchNormalization())\n",
        "\n",
        "model4.add(Dense(units=50,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model4.add(Dropout(0.2))\n",
        "\n",
        "model4.add(BatchNormalization())\n",
        "\n",
        "model4.add(Dense(units=50,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model4.add(Dropout(0.2))\n",
        "\n",
        "model4.add(BatchNormalization())\n",
        "\n",
        "model4.add(Dense(units=50,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model4.add(Dense(units=50,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model4.add(Dropout(0.2))\n",
        "\n",
        "model4.add(BatchNormalization())\n",
        "\n",
        "model4.add(Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "9jh-KAOE7VSF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
        "              tf.keras.metrics.FalseNegatives()])"
      ],
      "metadata": {
        "id": "mWgJUTNmRca4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = 'Startups',name = 'Fourth Trail')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "kIXi0MazR1hQ",
        "outputId": "9acdab20-c06b-48f8-e150-2befb4999c5a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:yslxf29b) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>982</td></tr><tr><td>best_val_loss</td><td>0.66167</td></tr><tr><td>epoch</td><td>999</td></tr><tr><td>loss</td><td>0.61004</td></tr><tr><td>val_loss</td><td>0.66929</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Third Trail</strong> at: <a href='https://wandb.ai/ossm0394/Startups/runs/yslxf29b' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/yslxf29b</a><br/>Synced 5 W&B file(s), 1 media file(s), 1460 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231002_113130-yslxf29b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:yslxf29b). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231002_120546-iwi4ofzb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ossm0394/Startups/runs/iwi4ofzb' target=\"_blank\">Fourth Trail</a></strong> to <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">https://wandb.ai/ossm0394/Startups</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ossm0394/Startups/runs/iwi4ofzb' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/iwi4ofzb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ossm0394/Startups/runs/iwi4ofzb?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c9e3e392140>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.fit(x = x_train,y = y_train,epochs = 600,validation_data = (x_test,y_test),callbacks = [WandbCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDygZR5PR7tP",
        "outputId": "17e3d870-1ac9-40f2-9791-307972ad38f3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.7644 - binary_accuracy: 0.5714 - false_negatives: 156.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_120546-iwi4ofzb/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 12s 198ms/step - loss: 0.7612 - binary_accuracy: 0.5754 - false_negatives: 161.0000 - val_loss: 0.9097 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 2/600\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6857 - binary_accuracy: 0.6275 - false_negatives: 187.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_120546-iwi4ofzb/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 6s 290ms/step - loss: 0.6857 - binary_accuracy: 0.6275 - false_negatives: 187.0000 - val_loss: 0.6577 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 3/600\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6595 - binary_accuracy: 0.6562 - false_negatives: 157.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_120546-iwi4ofzb/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 219ms/step - loss: 0.6537 - binary_accuracy: 0.6609 - false_negatives: 170.0000 - val_loss: 0.6363 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 4/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6470 - binary_accuracy: 0.6420 - false_negatives: 178.0000 - val_loss: 0.6535 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 5/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6327 - binary_accuracy: 0.6696 - false_negatives: 165.0000 - val_loss: 0.6561 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 6/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6211 - binary_accuracy: 0.6493 - false_negatives: 177.0000 - val_loss: 0.7879 - val_binary_accuracy: 0.6261 - val_false_negatives: 65.0000\n",
            "Epoch 7/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6252 - binary_accuracy: 0.6580 - false_negatives: 187.0000 - val_loss: 0.6878 - val_binary_accuracy: 0.6609 - val_false_negatives: 76.0000\n",
            "Epoch 8/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6247 - binary_accuracy: 0.6609 - false_negatives: 179.0000 - val_loss: 0.7393 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 9/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6249 - binary_accuracy: 0.6536 - false_negatives: 178.0000 - val_loss: 0.7434 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 10/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6332 - binary_accuracy: 0.6507 - false_negatives: 212.0000 - val_loss: 0.7489 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 11/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6234 - binary_accuracy: 0.6609 - false_negatives: 163.0000 - val_loss: 0.6932 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 12/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6238 - binary_accuracy: 0.6565 - false_negatives: 175.0000 - val_loss: 0.6987 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 13/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6243 - binary_accuracy: 0.6594 - false_negatives: 190.0000 - val_loss: 0.7176 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 14/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6384 - binary_accuracy: 0.6406 - false_negatives: 179.0000 - val_loss: 0.6980 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 15/600\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6303 - binary_accuracy: 0.6406 - false_negatives: 206.0000 - val_loss: 0.7199 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 16/600\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6129 - binary_accuracy: 0.6899 - false_negatives: 163.0000 - val_loss: 0.7261 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 17/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6070 - binary_accuracy: 0.6783 - false_negatives: 158.0000 - val_loss: 0.7230 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 18/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6267 - binary_accuracy: 0.6594 - false_negatives: 168.0000 - val_loss: 0.6687 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 19/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6186 - binary_accuracy: 0.6768 - false_negatives: 181.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 20/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6019 - binary_accuracy: 0.6884 - false_negatives: 175.0000 - val_loss: 0.7100 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 21/600\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6166 - binary_accuracy: 0.6710 - false_negatives: 162.0000 - val_loss: 0.6706 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 22/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6287 - binary_accuracy: 0.6565 - false_negatives: 198.0000 - val_loss: 0.6832 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 23/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6239 - binary_accuracy: 0.6797 - false_negatives: 155.0000 - val_loss: 0.6768 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 24/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6121 - binary_accuracy: 0.6797 - false_negatives: 162.0000 - val_loss: 0.6977 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 25/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6190 - binary_accuracy: 0.6522 - false_negatives: 188.0000 - val_loss: 0.6829 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 26/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6168 - binary_accuracy: 0.6754 - false_negatives: 180.0000 - val_loss: 0.7189 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 27/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6174 - binary_accuracy: 0.6667 - false_negatives: 172.0000 - val_loss: 0.7093 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 28/600\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6245 - binary_accuracy: 0.6696 - false_negatives: 176.0000 - val_loss: 0.7055 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 29/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6099 - binary_accuracy: 0.6783 - false_negatives: 168.0000 - val_loss: 0.7384 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 30/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6087 - binary_accuracy: 0.6870 - false_negatives: 158.0000 - val_loss: 0.7017 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 31/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6239 - binary_accuracy: 0.6594 - false_negatives: 197.0000 - val_loss: 0.7353 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 32/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6094 - binary_accuracy: 0.6696 - false_negatives: 168.0000 - val_loss: 0.7070 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 33/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6174 - binary_accuracy: 0.6609 - false_negatives: 181.0000 - val_loss: 0.7027 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 34/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6149 - binary_accuracy: 0.6623 - false_negatives: 187.0000 - val_loss: 0.7060 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 35/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6227 - binary_accuracy: 0.6565 - false_negatives: 172.0000 - val_loss: 0.6659 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 36/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6247 - binary_accuracy: 0.6609 - false_negatives: 187.0000 - val_loss: 0.6624 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 37/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6143 - binary_accuracy: 0.6812 - false_negatives: 164.0000 - val_loss: 0.6869 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 38/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6295 - binary_accuracy: 0.6420 - false_negatives: 183.0000 - val_loss: 0.6654 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 39/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6256 - binary_accuracy: 0.6449 - false_negatives: 220.0000 - val_loss: 0.6546 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 40/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6251 - binary_accuracy: 0.6594 - false_negatives: 171.0000 - val_loss: 0.6813 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 41/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6195 - binary_accuracy: 0.6667 - false_negatives: 188.0000 - val_loss: 0.6583 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 42/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6195 - binary_accuracy: 0.6594 - false_negatives: 184.0000 - val_loss: 0.6586 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 43/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6212 - binary_accuracy: 0.6681 - false_negatives: 182.0000 - val_loss: 0.6656 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 44/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6152 - binary_accuracy: 0.6681 - false_negatives: 165.0000 - val_loss: 0.6660 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 45/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6193 - binary_accuracy: 0.6696 - false_negatives: 181.0000 - val_loss: 0.6655 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 46/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6074 - binary_accuracy: 0.6739 - false_negatives: 173.0000 - val_loss: 0.6814 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 47/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6103 - binary_accuracy: 0.6826 - false_negatives: 173.0000 - val_loss: 0.6987 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 48/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6299 - binary_accuracy: 0.6710 - false_negatives: 179.0000 - val_loss: 0.6463 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 49/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6128 - binary_accuracy: 0.6870 - false_negatives: 172.0000 - val_loss: 0.6662 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 50/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6217 - binary_accuracy: 0.6855 - false_negatives: 167.0000 - val_loss: 0.6462 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 51/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6223 - binary_accuracy: 0.6826 - false_negatives: 175.0000 - val_loss: 0.6540 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 52/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6121 - binary_accuracy: 0.6725 - false_negatives: 173.0000 - val_loss: 0.6781 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 53/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6173 - binary_accuracy: 0.6638 - false_negatives: 175.0000 - val_loss: 0.6540 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 54/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6148 - binary_accuracy: 0.6797 - false_negatives: 170.0000 - val_loss: 0.6750 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 55/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6214 - binary_accuracy: 0.6681 - false_negatives: 197.0000 - val_loss: 0.6621 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 56/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6202 - binary_accuracy: 0.6594 - false_negatives: 183.0000 - val_loss: 0.6622 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 57/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6152 - binary_accuracy: 0.6870 - false_negatives: 168.0000 - val_loss: 0.7090 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 58/600\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6237 - binary_accuracy: 0.6797 - false_negatives: 164.0000 - val_loss: 0.6614 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 59/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6203 - binary_accuracy: 0.6638 - false_negatives: 188.0000 - val_loss: 0.6783 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 60/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6136 - binary_accuracy: 0.6667 - false_negatives: 176.0000 - val_loss: 0.6748 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 61/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6162 - binary_accuracy: 0.6783 - false_negatives: 168.0000 - val_loss: 0.6732 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 62/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6065 - binary_accuracy: 0.6841 - false_negatives: 173.0000 - val_loss: 0.6995 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 63/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6234 - binary_accuracy: 0.6739 - false_negatives: 186.0000 - val_loss: 0.6655 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 64/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6138 - binary_accuracy: 0.6884 - false_negatives: 168.0000 - val_loss: 0.6979 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 65/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6195 - binary_accuracy: 0.6696 - false_negatives: 175.0000 - val_loss: 0.6735 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 66/600\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6095 - binary_accuracy: 0.6725 - false_negatives: 176.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 67/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6202 - binary_accuracy: 0.6638 - false_negatives: 175.0000 - val_loss: 0.6563 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 68/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6259 - binary_accuracy: 0.6536 - false_negatives: 185.0000 - val_loss: 0.6533 - val_binary_accuracy: 0.5913 - val_false_negatives: 43.0000\n",
            "Epoch 69/600\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.6144 - binary_accuracy: 0.6830 - false_negatives: 170.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_120546-iwi4ofzb/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 0.6167 - binary_accuracy: 0.6797 - false_negatives: 178.0000 - val_loss: 0.6301 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 70/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6158 - binary_accuracy: 0.6841 - false_negatives: 185.0000 - val_loss: 0.6579 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 71/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6126 - binary_accuracy: 0.6783 - false_negatives: 171.0000 - val_loss: 0.6747 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 72/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6234 - binary_accuracy: 0.6638 - false_negatives: 181.0000 - val_loss: 0.6772 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 73/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6201 - binary_accuracy: 0.6551 - false_negatives: 191.0000 - val_loss: 0.6887 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 74/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6226 - binary_accuracy: 0.6725 - false_negatives: 168.0000 - val_loss: 0.6597 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 75/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6170 - binary_accuracy: 0.6710 - false_negatives: 196.0000 - val_loss: 0.6813 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 76/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6230 - binary_accuracy: 0.6507 - false_negatives: 188.0000 - val_loss: 0.6856 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 77/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6222 - binary_accuracy: 0.6623 - false_negatives: 168.0000 - val_loss: 0.6884 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 78/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6196 - binary_accuracy: 0.6623 - false_negatives: 186.0000 - val_loss: 0.6793 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 79/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6040 - binary_accuracy: 0.6913 - false_negatives: 169.0000 - val_loss: 0.6882 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 80/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6170 - binary_accuracy: 0.6797 - false_negatives: 168.0000 - val_loss: 0.6691 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 81/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6111 - binary_accuracy: 0.6739 - false_negatives: 180.0000 - val_loss: 0.6637 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 82/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6084 - binary_accuracy: 0.6884 - false_negatives: 168.0000 - val_loss: 0.6807 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 83/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6219 - binary_accuracy: 0.6681 - false_negatives: 189.0000 - val_loss: 0.6701 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 84/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6126 - binary_accuracy: 0.6957 - false_negatives: 165.0000 - val_loss: 0.6774 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 85/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6086 - binary_accuracy: 0.6841 - false_negatives: 159.0000 - val_loss: 0.6836 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 86/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6218 - binary_accuracy: 0.6536 - false_negatives: 190.0000 - val_loss: 0.6602 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 87/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6157 - binary_accuracy: 0.6710 - false_negatives: 192.0000 - val_loss: 0.6780 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 88/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6190 - binary_accuracy: 0.6652 - false_negatives: 172.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 89/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6137 - binary_accuracy: 0.6855 - false_negatives: 174.0000 - val_loss: 0.6839 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 90/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6197 - binary_accuracy: 0.6768 - false_negatives: 178.0000 - val_loss: 0.6661 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 91/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6089 - binary_accuracy: 0.6884 - false_negatives: 167.0000 - val_loss: 0.6729 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 92/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6113 - binary_accuracy: 0.6841 - false_negatives: 163.0000 - val_loss: 0.6681 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 93/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6155 - binary_accuracy: 0.6783 - false_negatives: 183.0000 - val_loss: 0.6604 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 94/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6143 - binary_accuracy: 0.6754 - false_negatives: 182.0000 - val_loss: 0.6594 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 95/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6255 - binary_accuracy: 0.6623 - false_negatives: 172.0000 - val_loss: 0.6679 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 96/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6334 - binary_accuracy: 0.6304 - false_negatives: 213.0000 - val_loss: 0.6548 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 97/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6122 - binary_accuracy: 0.6826 - false_negatives: 183.0000 - val_loss: 0.6820 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 98/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6247 - binary_accuracy: 0.6681 - false_negatives: 189.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 99/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6153 - binary_accuracy: 0.6580 - false_negatives: 180.0000 - val_loss: 0.6860 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 100/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6142 - binary_accuracy: 0.6783 - false_negatives: 172.0000 - val_loss: 0.6975 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 101/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6311 - binary_accuracy: 0.6478 - false_negatives: 188.0000 - val_loss: 0.6673 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 102/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6179 - binary_accuracy: 0.6580 - false_negatives: 188.0000 - val_loss: 0.6891 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 103/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6130 - binary_accuracy: 0.6754 - false_negatives: 172.0000 - val_loss: 0.6844 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 104/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6178 - binary_accuracy: 0.6638 - false_negatives: 172.0000 - val_loss: 0.6716 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 105/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6254 - binary_accuracy: 0.6551 - false_negatives: 189.0000 - val_loss: 0.6722 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 106/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6153 - binary_accuracy: 0.6652 - false_negatives: 196.0000 - val_loss: 0.6774 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 107/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6230 - binary_accuracy: 0.6551 - false_negatives: 193.0000 - val_loss: 0.6874 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 108/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6186 - binary_accuracy: 0.6667 - false_negatives: 169.0000 - val_loss: 0.6916 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 109/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6219 - binary_accuracy: 0.6522 - false_negatives: 187.0000 - val_loss: 0.6732 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 110/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6115 - binary_accuracy: 0.6667 - false_negatives: 187.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 111/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6206 - binary_accuracy: 0.6507 - false_negatives: 160.0000 - val_loss: 0.6891 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 112/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6208 - binary_accuracy: 0.6739 - false_negatives: 194.0000 - val_loss: 0.6757 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 113/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6113 - binary_accuracy: 0.6768 - false_negatives: 182.0000 - val_loss: 0.6887 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 114/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6255 - binary_accuracy: 0.6609 - false_negatives: 178.0000 - val_loss: 0.6770 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 115/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6225 - binary_accuracy: 0.6594 - false_negatives: 166.0000 - val_loss: 0.6653 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 116/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6252 - binary_accuracy: 0.6507 - false_negatives: 197.0000 - val_loss: 0.6579 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 117/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6268 - binary_accuracy: 0.6522 - false_negatives: 213.0000 - val_loss: 0.6564 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 118/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6205 - binary_accuracy: 0.6623 - false_negatives: 180.0000 - val_loss: 0.6977 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 119/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6135 - binary_accuracy: 0.6681 - false_negatives: 185.0000 - val_loss: 0.6719 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 120/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6281 - binary_accuracy: 0.6594 - false_negatives: 160.0000 - val_loss: 0.6946 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 121/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6232 - binary_accuracy: 0.6609 - false_negatives: 207.0000 - val_loss: 0.6774 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 122/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6206 - binary_accuracy: 0.6594 - false_negatives: 197.0000 - val_loss: 0.6882 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 123/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6164 - binary_accuracy: 0.6826 - false_negatives: 166.0000 - val_loss: 0.6746 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 124/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6202 - binary_accuracy: 0.6667 - false_negatives: 175.0000 - val_loss: 0.6628 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 125/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6147 - binary_accuracy: 0.6638 - false_negatives: 170.0000 - val_loss: 0.6705 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 126/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6164 - binary_accuracy: 0.6551 - false_negatives: 181.0000 - val_loss: 0.6738 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 127/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6129 - binary_accuracy: 0.6725 - false_negatives: 166.0000 - val_loss: 0.6700 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 128/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6161 - binary_accuracy: 0.6768 - false_negatives: 163.0000 - val_loss: 0.6727 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 129/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6171 - binary_accuracy: 0.6580 - false_negatives: 182.0000 - val_loss: 0.6832 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 130/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6301 - binary_accuracy: 0.6420 - false_negatives: 195.0000 - val_loss: 0.6598 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 131/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6206 - binary_accuracy: 0.6667 - false_negatives: 183.0000 - val_loss: 0.6767 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 132/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6208 - binary_accuracy: 0.6594 - false_negatives: 194.0000 - val_loss: 0.6689 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 133/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6153 - binary_accuracy: 0.6725 - false_negatives: 174.0000 - val_loss: 0.6710 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 134/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6118 - binary_accuracy: 0.6812 - false_negatives: 170.0000 - val_loss: 0.6946 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 135/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6205 - binary_accuracy: 0.6725 - false_negatives: 162.0000 - val_loss: 0.6584 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 136/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6180 - binary_accuracy: 0.6826 - false_negatives: 182.0000 - val_loss: 0.6716 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 137/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6205 - binary_accuracy: 0.6783 - false_negatives: 181.0000 - val_loss: 0.6550 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 138/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6119 - binary_accuracy: 0.6855 - false_negatives: 180.0000 - val_loss: 0.6629 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 139/600\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6189 - binary_accuracy: 0.6768 - false_negatives: 177.0000 - val_loss: 0.6467 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 140/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6105 - binary_accuracy: 0.6942 - false_negatives: 181.0000 - val_loss: 0.6896 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 141/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6119 - binary_accuracy: 0.6768 - false_negatives: 179.0000 - val_loss: 0.6574 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 142/600\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.6150 - binary_accuracy: 0.6765 - false_negatives: 139.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_120546-iwi4ofzb/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 158ms/step - loss: 0.6097 - binary_accuracy: 0.6797 - false_negatives: 170.0000 - val_loss: 0.6285 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 143/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6194 - binary_accuracy: 0.6594 - false_negatives: 190.0000 - val_loss: 0.6573 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 144/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6140 - binary_accuracy: 0.6623 - false_negatives: 178.0000 - val_loss: 0.6570 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 145/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6226 - binary_accuracy: 0.6478 - false_negatives: 192.0000 - val_loss: 0.6879 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 146/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6118 - binary_accuracy: 0.6739 - false_negatives: 171.0000 - val_loss: 0.6656 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 147/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6116 - binary_accuracy: 0.6942 - false_negatives: 153.0000 - val_loss: 0.6654 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 148/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6157 - binary_accuracy: 0.6754 - false_negatives: 181.0000 - val_loss: 0.6602 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 149/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6169 - binary_accuracy: 0.6797 - false_negatives: 180.0000 - val_loss: 0.6580 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 150/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6141 - binary_accuracy: 0.6681 - false_negatives: 177.0000 - val_loss: 0.6600 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 151/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6150 - binary_accuracy: 0.6696 - false_negatives: 180.0000 - val_loss: 0.6763 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 152/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6173 - binary_accuracy: 0.6594 - false_negatives: 173.0000 - val_loss: 0.6739 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 153/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6121 - binary_accuracy: 0.6754 - false_negatives: 176.0000 - val_loss: 0.6940 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 154/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6169 - binary_accuracy: 0.6623 - false_negatives: 188.0000 - val_loss: 0.6844 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 155/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6221 - binary_accuracy: 0.6609 - false_negatives: 185.0000 - val_loss: 0.6781 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 156/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6164 - binary_accuracy: 0.6870 - false_negatives: 176.0000 - val_loss: 0.6877 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 157/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6109 - binary_accuracy: 0.6739 - false_negatives: 174.0000 - val_loss: 0.6769 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 158/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6122 - binary_accuracy: 0.6913 - false_negatives: 161.0000 - val_loss: 0.6786 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 159/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6245 - binary_accuracy: 0.6754 - false_negatives: 178.0000 - val_loss: 0.6619 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 160/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6145 - binary_accuracy: 0.6725 - false_negatives: 181.0000 - val_loss: 0.6627 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 161/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6149 - binary_accuracy: 0.6797 - false_negatives: 172.0000 - val_loss: 0.6782 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 162/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6128 - binary_accuracy: 0.6783 - false_negatives: 178.0000 - val_loss: 0.6675 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 163/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6227 - binary_accuracy: 0.6681 - false_negatives: 184.0000 - val_loss: 0.6486 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 164/600\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6154 - binary_accuracy: 0.6768 - false_negatives: 183.0000 - val_loss: 0.6575 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 165/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6181 - binary_accuracy: 0.6623 - false_negatives: 177.0000 - val_loss: 0.6674 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 166/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6168 - binary_accuracy: 0.6638 - false_negatives: 186.0000 - val_loss: 0.6495 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 167/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6141 - binary_accuracy: 0.6841 - false_negatives: 174.0000 - val_loss: 0.6876 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 168/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6246 - binary_accuracy: 0.6652 - false_negatives: 185.0000 - val_loss: 0.6663 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 169/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6175 - binary_accuracy: 0.6696 - false_negatives: 179.0000 - val_loss: 0.6846 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 170/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6160 - binary_accuracy: 0.6855 - false_negatives: 182.0000 - val_loss: 0.6899 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 171/600\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6201 - binary_accuracy: 0.6638 - false_negatives: 173.0000 - val_loss: 0.6821 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 172/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6177 - binary_accuracy: 0.6725 - false_negatives: 194.0000 - val_loss: 0.6827 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 173/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6245 - binary_accuracy: 0.6667 - false_negatives: 173.0000 - val_loss: 0.6760 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 174/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6183 - binary_accuracy: 0.6797 - false_negatives: 180.0000 - val_loss: 0.6397 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 175/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6149 - binary_accuracy: 0.6725 - false_negatives: 183.0000 - val_loss: 0.6667 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 176/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6145 - binary_accuracy: 0.6551 - false_negatives: 185.0000 - val_loss: 0.6789 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 177/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6294 - binary_accuracy: 0.6348 - false_negatives: 201.0000 - val_loss: 0.6597 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 178/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6180 - binary_accuracy: 0.6551 - false_negatives: 196.0000 - val_loss: 0.6637 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 179/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6150 - binary_accuracy: 0.6710 - false_negatives: 170.0000 - val_loss: 0.6734 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 180/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6188 - binary_accuracy: 0.6652 - false_negatives: 188.0000 - val_loss: 0.6792 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 181/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6115 - binary_accuracy: 0.6768 - false_negatives: 171.0000 - val_loss: 0.6809 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 182/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6306 - binary_accuracy: 0.6435 - false_negatives: 176.0000 - val_loss: 0.6645 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 183/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6219 - binary_accuracy: 0.6551 - false_negatives: 213.0000 - val_loss: 0.6537 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 184/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6301 - binary_accuracy: 0.6609 - false_negatives: 184.0000 - val_loss: 0.6638 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 185/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6174 - binary_accuracy: 0.6565 - false_negatives: 208.0000 - val_loss: 0.6633 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 186/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6079 - binary_accuracy: 0.6710 - false_negatives: 159.0000 - val_loss: 0.6771 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 187/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6231 - binary_accuracy: 0.6522 - false_negatives: 183.0000 - val_loss: 0.6589 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 188/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6219 - binary_accuracy: 0.6580 - false_negatives: 200.0000 - val_loss: 0.6657 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 189/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6236 - binary_accuracy: 0.6710 - false_negatives: 188.0000 - val_loss: 0.6704 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 190/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6185 - binary_accuracy: 0.6652 - false_negatives: 168.0000 - val_loss: 0.6758 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 191/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6187 - binary_accuracy: 0.6507 - false_negatives: 206.0000 - val_loss: 0.6773 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 192/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6285 - binary_accuracy: 0.6638 - false_negatives: 191.0000 - val_loss: 0.6639 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 193/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6250 - binary_accuracy: 0.6609 - false_negatives: 212.0000 - val_loss: 0.6755 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 194/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6236 - binary_accuracy: 0.6652 - false_negatives: 180.0000 - val_loss: 0.6676 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 195/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6199 - binary_accuracy: 0.6638 - false_negatives: 191.0000 - val_loss: 0.6770 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 196/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6188 - binary_accuracy: 0.6638 - false_negatives: 189.0000 - val_loss: 0.6844 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 197/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6146 - binary_accuracy: 0.6667 - false_negatives: 182.0000 - val_loss: 0.6864 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 198/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6159 - binary_accuracy: 0.6768 - false_negatives: 177.0000 - val_loss: 0.6797 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 199/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6252 - binary_accuracy: 0.6507 - false_negatives: 188.0000 - val_loss: 0.6754 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 200/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6278 - binary_accuracy: 0.6522 - false_negatives: 218.0000 - val_loss: 0.6669 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 201/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6193 - binary_accuracy: 0.6739 - false_negatives: 193.0000 - val_loss: 0.6643 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 202/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6214 - binary_accuracy: 0.6638 - false_negatives: 180.0000 - val_loss: 0.6697 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 203/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6251 - binary_accuracy: 0.6623 - false_negatives: 180.0000 - val_loss: 0.6586 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 204/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6360 - binary_accuracy: 0.6464 - false_negatives: 211.0000 - val_loss: 0.6520 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 205/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6278 - binary_accuracy: 0.6536 - false_negatives: 220.0000 - val_loss: 0.6631 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 206/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6271 - binary_accuracy: 0.6681 - false_negatives: 177.0000 - val_loss: 0.6689 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 207/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6287 - binary_accuracy: 0.6493 - false_negatives: 212.0000 - val_loss: 0.6556 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 208/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6247 - binary_accuracy: 0.6667 - false_negatives: 188.0000 - val_loss: 0.6672 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 209/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6225 - binary_accuracy: 0.6609 - false_negatives: 179.0000 - val_loss: 0.6701 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 210/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6305 - binary_accuracy: 0.6435 - false_negatives: 213.0000 - val_loss: 0.6576 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 211/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6285 - binary_accuracy: 0.6391 - false_negatives: 203.0000 - val_loss: 0.6618 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 212/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6154 - binary_accuracy: 0.6667 - false_negatives: 184.0000 - val_loss: 0.6711 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 213/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6202 - binary_accuracy: 0.6681 - false_negatives: 176.0000 - val_loss: 0.6555 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 214/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6308 - binary_accuracy: 0.6638 - false_negatives: 191.0000 - val_loss: 0.6598 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 215/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6218 - binary_accuracy: 0.6638 - false_negatives: 192.0000 - val_loss: 0.6695 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 216/600\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6214 - binary_accuracy: 0.6420 - false_negatives: 199.0000 - val_loss: 0.6608 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 217/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6203 - binary_accuracy: 0.6522 - false_negatives: 190.0000 - val_loss: 0.6647 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 218/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6151 - binary_accuracy: 0.6710 - false_negatives: 156.0000 - val_loss: 0.6743 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 219/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6248 - binary_accuracy: 0.6406 - false_negatives: 182.0000 - val_loss: 0.6347 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 220/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6332 - binary_accuracy: 0.6406 - false_negatives: 240.0000 - val_loss: 0.6365 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 221/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6262 - binary_accuracy: 0.6522 - false_negatives: 211.0000 - val_loss: 0.6691 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 222/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6295 - binary_accuracy: 0.6391 - false_negatives: 217.0000 - val_loss: 0.6608 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 223/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6225 - binary_accuracy: 0.6580 - false_negatives: 193.0000 - val_loss: 0.6693 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 224/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6188 - binary_accuracy: 0.6609 - false_negatives: 166.0000 - val_loss: 0.6717 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 225/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6203 - binary_accuracy: 0.6812 - false_negatives: 183.0000 - val_loss: 0.6634 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 226/600\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6148 - binary_accuracy: 0.6681 - false_negatives: 176.0000 - val_loss: 0.6778 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 227/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6244 - binary_accuracy: 0.6435 - false_negatives: 206.0000 - val_loss: 0.6560 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 228/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6310 - binary_accuracy: 0.6536 - false_negatives: 194.0000 - val_loss: 0.6576 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 229/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6212 - binary_accuracy: 0.6594 - false_negatives: 193.0000 - val_loss: 0.6695 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 230/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6192 - binary_accuracy: 0.6681 - false_negatives: 182.0000 - val_loss: 0.6772 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 231/600\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6158 - binary_accuracy: 0.6768 - false_negatives: 173.0000 - val_loss: 0.6605 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 232/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6253 - binary_accuracy: 0.6609 - false_negatives: 185.0000 - val_loss: 0.6680 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 233/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6232 - binary_accuracy: 0.6652 - false_negatives: 185.0000 - val_loss: 0.6676 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 234/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6183 - binary_accuracy: 0.6710 - false_negatives: 172.0000 - val_loss: 0.6692 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 235/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6270 - binary_accuracy: 0.6391 - false_negatives: 195.0000 - val_loss: 0.6664 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 236/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6182 - binary_accuracy: 0.6754 - false_negatives: 175.0000 - val_loss: 0.6654 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 237/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6273 - binary_accuracy: 0.6507 - false_negatives: 187.0000 - val_loss: 0.6557 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 238/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6148 - binary_accuracy: 0.6783 - false_negatives: 176.0000 - val_loss: 0.6822 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 239/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6192 - binary_accuracy: 0.6609 - false_negatives: 190.0000 - val_loss: 0.6676 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 240/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6146 - binary_accuracy: 0.6725 - false_negatives: 171.0000 - val_loss: 0.6651 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 241/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6123 - binary_accuracy: 0.6812 - false_negatives: 160.0000 - val_loss: 0.6762 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 242/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6251 - binary_accuracy: 0.6580 - false_negatives: 188.0000 - val_loss: 0.6606 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 243/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6190 - binary_accuracy: 0.6594 - false_negatives: 184.0000 - val_loss: 0.6674 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 244/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6201 - binary_accuracy: 0.6725 - false_negatives: 183.0000 - val_loss: 0.6708 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 245/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6209 - binary_accuracy: 0.6507 - false_negatives: 193.0000 - val_loss: 0.6760 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 246/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6197 - binary_accuracy: 0.6652 - false_negatives: 188.0000 - val_loss: 0.6557 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 247/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6221 - binary_accuracy: 0.6551 - false_negatives: 169.0000 - val_loss: 0.6595 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 248/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6184 - binary_accuracy: 0.6478 - false_negatives: 209.0000 - val_loss: 0.6626 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 249/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6167 - binary_accuracy: 0.6739 - false_negatives: 187.0000 - val_loss: 0.6749 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 250/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6142 - binary_accuracy: 0.6696 - false_negatives: 156.0000 - val_loss: 0.6742 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 251/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6166 - binary_accuracy: 0.6580 - false_negatives: 174.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 252/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6261 - binary_accuracy: 0.6507 - false_negatives: 208.0000 - val_loss: 0.6566 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 253/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6203 - binary_accuracy: 0.6580 - false_negatives: 192.0000 - val_loss: 0.6672 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 254/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6216 - binary_accuracy: 0.6652 - false_negatives: 175.0000 - val_loss: 0.6582 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 255/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6265 - binary_accuracy: 0.6609 - false_negatives: 179.0000 - val_loss: 0.6576 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 256/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6146 - binary_accuracy: 0.6812 - false_negatives: 181.0000 - val_loss: 0.6687 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 257/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6099 - binary_accuracy: 0.6899 - false_negatives: 178.0000 - val_loss: 0.6986 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 258/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6312 - binary_accuracy: 0.6449 - false_negatives: 194.0000 - val_loss: 0.6687 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 259/600\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6298 - binary_accuracy: 0.6522 - false_negatives: 221.0000 - val_loss: 0.6565 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 260/600\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6276 - binary_accuracy: 0.6406 - false_negatives: 193.0000 - val_loss: 0.6525 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 261/600\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6232 - binary_accuracy: 0.6478 - false_negatives: 198.0000 - val_loss: 0.6847 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 262/600\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6233 - binary_accuracy: 0.6565 - false_negatives: 202.0000 - val_loss: 0.6767 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 263/600\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.6173 - binary_accuracy: 0.6739 - false_negatives: 186.0000 - val_loss: 0.6757 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 264/600\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.6137 - binary_accuracy: 0.6725 - false_negatives: 164.0000 - val_loss: 0.6953 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 265/600\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6153 - binary_accuracy: 0.6768 - false_negatives: 175.0000 - val_loss: 0.6736 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 266/600\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6219 - binary_accuracy: 0.6623 - false_negatives: 165.0000 - val_loss: 0.6760 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 267/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6155 - binary_accuracy: 0.6536 - false_negatives: 192.0000 - val_loss: 0.6727 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 268/600\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6218 - binary_accuracy: 0.6435 - false_negatives: 223.0000 - val_loss: 0.6702 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 269/600\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6205 - binary_accuracy: 0.6797 - false_negatives: 172.0000 - val_loss: 0.6646 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 270/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6305 - binary_accuracy: 0.6406 - false_negatives: 195.0000 - val_loss: 0.6505 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 271/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6271 - binary_accuracy: 0.6551 - false_negatives: 182.0000 - val_loss: 0.6607 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 272/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6254 - binary_accuracy: 0.6623 - false_negatives: 205.0000 - val_loss: 0.6552 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 273/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6167 - binary_accuracy: 0.6565 - false_negatives: 190.0000 - val_loss: 0.6729 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 274/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6195 - binary_accuracy: 0.6826 - false_negatives: 165.0000 - val_loss: 0.6615 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 275/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6180 - binary_accuracy: 0.6710 - false_negatives: 179.0000 - val_loss: 0.6634 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 276/600\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6326 - binary_accuracy: 0.6406 - false_negatives: 163.0000 - val_loss: 0.6559 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 277/600\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6269 - binary_accuracy: 0.6449 - false_negatives: 218.0000 - val_loss: 0.6546 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 278/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6209 - binary_accuracy: 0.6652 - false_negatives: 202.0000 - val_loss: 0.6735 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 279/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6176 - binary_accuracy: 0.6638 - false_negatives: 177.0000 - val_loss: 0.6654 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 280/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6296 - binary_accuracy: 0.6522 - false_negatives: 215.0000 - val_loss: 0.6553 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 281/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6232 - binary_accuracy: 0.6536 - false_negatives: 207.0000 - val_loss: 0.6619 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 282/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6209 - binary_accuracy: 0.6783 - false_negatives: 169.0000 - val_loss: 0.6668 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 283/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6278 - binary_accuracy: 0.6623 - false_negatives: 178.0000 - val_loss: 0.6620 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 284/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6285 - binary_accuracy: 0.6580 - false_negatives: 206.0000 - val_loss: 0.6525 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 285/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6204 - binary_accuracy: 0.6594 - false_negatives: 201.0000 - val_loss: 0.6608 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 286/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6262 - binary_accuracy: 0.6391 - false_negatives: 191.0000 - val_loss: 0.6659 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 287/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6256 - binary_accuracy: 0.6609 - false_negatives: 180.0000 - val_loss: 0.6732 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 288/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6137 - binary_accuracy: 0.6797 - false_negatives: 184.0000 - val_loss: 0.6911 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 289/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6224 - binary_accuracy: 0.6681 - false_negatives: 176.0000 - val_loss: 0.6637 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 290/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6138 - binary_accuracy: 0.6594 - false_negatives: 169.0000 - val_loss: 0.6874 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 291/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6278 - binary_accuracy: 0.6449 - false_negatives: 188.0000 - val_loss: 0.6563 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 292/600\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6297 - binary_accuracy: 0.6565 - false_negatives: 201.0000 - val_loss: 0.6541 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 293/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6207 - binary_accuracy: 0.6841 - false_negatives: 180.0000 - val_loss: 0.6742 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 294/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6321 - binary_accuracy: 0.6493 - false_negatives: 173.0000 - val_loss: 0.6564 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 295/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6323 - binary_accuracy: 0.6507 - false_negatives: 220.0000 - val_loss: 0.6605 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 296/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6221 - binary_accuracy: 0.6667 - false_negatives: 183.0000 - val_loss: 0.6595 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 297/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6156 - binary_accuracy: 0.6826 - false_negatives: 169.0000 - val_loss: 0.6737 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 298/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6275 - binary_accuracy: 0.6478 - false_negatives: 177.0000 - val_loss: 0.6642 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 299/600\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.6205 - binary_accuracy: 0.6667 - false_negatives: 207.0000 - val_loss: 0.6554 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 300/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6311 - binary_accuracy: 0.6304 - false_negatives: 200.0000 - val_loss: 0.6564 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 301/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6175 - binary_accuracy: 0.6580 - false_negatives: 188.0000 - val_loss: 0.6827 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 302/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6320 - binary_accuracy: 0.6536 - false_negatives: 203.0000 - val_loss: 0.6621 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 303/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6151 - binary_accuracy: 0.6841 - false_negatives: 183.0000 - val_loss: 0.6872 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 304/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6146 - binary_accuracy: 0.6754 - false_negatives: 162.0000 - val_loss: 0.6701 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 305/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6142 - binary_accuracy: 0.6696 - false_negatives: 184.0000 - val_loss: 0.6756 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 306/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6215 - binary_accuracy: 0.6594 - false_negatives: 179.0000 - val_loss: 0.6607 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 307/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6218 - binary_accuracy: 0.6565 - false_negatives: 185.0000 - val_loss: 0.6697 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 308/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6258 - binary_accuracy: 0.6464 - false_negatives: 194.0000 - val_loss: 0.6603 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 309/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6189 - binary_accuracy: 0.6551 - false_negatives: 184.0000 - val_loss: 0.6811 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 310/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6192 - binary_accuracy: 0.6565 - false_negatives: 168.0000 - val_loss: 0.6806 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 311/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6192 - binary_accuracy: 0.6681 - false_negatives: 192.0000 - val_loss: 0.6735 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 312/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6194 - binary_accuracy: 0.6623 - false_negatives: 187.0000 - val_loss: 0.6748 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 313/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6191 - binary_accuracy: 0.6696 - false_negatives: 179.0000 - val_loss: 0.6656 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 314/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6208 - binary_accuracy: 0.6536 - false_negatives: 186.0000 - val_loss: 0.6677 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 315/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6168 - binary_accuracy: 0.6609 - false_negatives: 169.0000 - val_loss: 0.6750 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 316/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6274 - binary_accuracy: 0.6667 - false_negatives: 185.0000 - val_loss: 0.6570 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 317/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6220 - binary_accuracy: 0.6681 - false_negatives: 180.0000 - val_loss: 0.6760 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 318/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6120 - binary_accuracy: 0.6855 - false_negatives: 173.0000 - val_loss: 0.6687 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 319/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6172 - binary_accuracy: 0.6725 - false_negatives: 180.0000 - val_loss: 0.6739 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 320/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6270 - binary_accuracy: 0.6594 - false_negatives: 188.0000 - val_loss: 0.6654 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 321/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6177 - binary_accuracy: 0.6609 - false_negatives: 184.0000 - val_loss: 0.6703 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 322/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6181 - binary_accuracy: 0.6710 - false_negatives: 186.0000 - val_loss: 0.6692 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 323/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6181 - binary_accuracy: 0.6768 - false_negatives: 176.0000 - val_loss: 0.6658 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 324/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6080 - binary_accuracy: 0.6986 - false_negatives: 166.0000 - val_loss: 0.6791 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 325/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6084 - binary_accuracy: 0.6913 - false_negatives: 161.0000 - val_loss: 0.6625 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 326/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6195 - binary_accuracy: 0.6739 - false_negatives: 181.0000 - val_loss: 0.6653 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 327/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6221 - binary_accuracy: 0.6696 - false_negatives: 190.0000 - val_loss: 0.6629 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 328/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6190 - binary_accuracy: 0.6594 - false_negatives: 186.0000 - val_loss: 0.6605 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 329/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6159 - binary_accuracy: 0.6841 - false_negatives: 162.0000 - val_loss: 0.6646 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 330/600\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6192 - binary_accuracy: 0.6638 - false_negatives: 179.0000 - val_loss: 0.6718 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 331/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6336 - binary_accuracy: 0.6681 - false_negatives: 177.0000 - val_loss: 0.6589 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 332/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6255 - binary_accuracy: 0.6551 - false_negatives: 213.0000 - val_loss: 0.6579 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 333/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6145 - binary_accuracy: 0.6725 - false_negatives: 186.0000 - val_loss: 0.6823 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 334/600\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6180 - binary_accuracy: 0.6739 - false_negatives: 183.0000 - val_loss: 0.6663 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 335/600\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6238 - binary_accuracy: 0.6797 - false_negatives: 184.0000 - val_loss: 0.6642 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 336/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6170 - binary_accuracy: 0.6667 - false_negatives: 195.0000 - val_loss: 0.6831 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 337/600\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6173 - binary_accuracy: 0.6739 - false_negatives: 182.0000 - val_loss: 0.6703 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 338/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6097 - binary_accuracy: 0.6710 - false_negatives: 173.0000 - val_loss: 0.6717 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 339/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6219 - binary_accuracy: 0.6551 - false_negatives: 193.0000 - val_loss: 0.6602 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 340/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6173 - binary_accuracy: 0.6725 - false_negatives: 166.0000 - val_loss: 0.6864 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 341/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6130 - binary_accuracy: 0.6667 - false_negatives: 183.0000 - val_loss: 0.6960 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 342/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6218 - binary_accuracy: 0.6638 - false_negatives: 169.0000 - val_loss: 0.6766 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 343/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6216 - binary_accuracy: 0.6594 - false_negatives: 186.0000 - val_loss: 0.6692 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 344/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6185 - binary_accuracy: 0.6623 - false_negatives: 172.0000 - val_loss: 0.6772 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 345/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6255 - binary_accuracy: 0.6435 - false_negatives: 197.0000 - val_loss: 0.6559 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 346/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6242 - binary_accuracy: 0.6420 - false_negatives: 183.0000 - val_loss: 0.6572 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 347/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6260 - binary_accuracy: 0.6565 - false_negatives: 198.0000 - val_loss: 0.6621 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 348/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6326 - binary_accuracy: 0.6348 - false_negatives: 237.0000 - val_loss: 0.6502 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 349/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6170 - binary_accuracy: 0.6594 - false_negatives: 194.0000 - val_loss: 0.6670 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 350/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6248 - binary_accuracy: 0.6623 - false_negatives: 183.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 351/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6026 - binary_accuracy: 0.6986 - false_negatives: 157.0000 - val_loss: 0.6832 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 352/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6277 - binary_accuracy: 0.6478 - false_negatives: 174.0000 - val_loss: 0.6558 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 353/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6227 - binary_accuracy: 0.6623 - false_negatives: 184.0000 - val_loss: 0.6671 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 354/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6179 - binary_accuracy: 0.6797 - false_negatives: 171.0000 - val_loss: 0.6575 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 355/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6254 - binary_accuracy: 0.6623 - false_negatives: 195.0000 - val_loss: 0.6610 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 356/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6263 - binary_accuracy: 0.6406 - false_negatives: 204.0000 - val_loss: 0.6603 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 357/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6128 - binary_accuracy: 0.6768 - false_negatives: 181.0000 - val_loss: 0.6719 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 358/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6191 - binary_accuracy: 0.6768 - false_negatives: 176.0000 - val_loss: 0.6674 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 359/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6307 - binary_accuracy: 0.6420 - false_negatives: 201.0000 - val_loss: 0.6584 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 360/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6243 - binary_accuracy: 0.6754 - false_negatives: 182.0000 - val_loss: 0.6612 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 361/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6068 - binary_accuracy: 0.6826 - false_negatives: 176.0000 - val_loss: 0.6801 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 362/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6073 - binary_accuracy: 0.6739 - false_negatives: 165.0000 - val_loss: 0.6938 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 363/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6229 - binary_accuracy: 0.6638 - false_negatives: 179.0000 - val_loss: 0.6557 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 364/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6271 - binary_accuracy: 0.6580 - false_negatives: 203.0000 - val_loss: 0.6579 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 365/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6200 - binary_accuracy: 0.6609 - false_negatives: 187.0000 - val_loss: 0.6741 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 366/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6203 - binary_accuracy: 0.6681 - false_negatives: 179.0000 - val_loss: 0.6541 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 367/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6228 - binary_accuracy: 0.6493 - false_negatives: 192.0000 - val_loss: 0.6563 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 368/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6274 - binary_accuracy: 0.6435 - false_negatives: 190.0000 - val_loss: 0.6556 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 369/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6175 - binary_accuracy: 0.6609 - false_negatives: 197.0000 - val_loss: 0.6779 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 370/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6229 - binary_accuracy: 0.6725 - false_negatives: 191.0000 - val_loss: 0.6498 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 371/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6188 - binary_accuracy: 0.6797 - false_negatives: 172.0000 - val_loss: 0.6680 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 372/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6233 - binary_accuracy: 0.6667 - false_negatives: 195.0000 - val_loss: 0.6583 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 373/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6064 - binary_accuracy: 0.6928 - false_negatives: 171.0000 - val_loss: 0.6857 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 374/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6275 - binary_accuracy: 0.6768 - false_negatives: 176.0000 - val_loss: 0.6621 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 375/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6236 - binary_accuracy: 0.6536 - false_negatives: 207.0000 - val_loss: 0.6550 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 376/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6160 - binary_accuracy: 0.6681 - false_negatives: 176.0000 - val_loss: 0.6674 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 377/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6206 - binary_accuracy: 0.6725 - false_negatives: 171.0000 - val_loss: 0.6610 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 378/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6217 - binary_accuracy: 0.6623 - false_negatives: 200.0000 - val_loss: 0.6615 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 379/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6141 - binary_accuracy: 0.6841 - false_negatives: 172.0000 - val_loss: 0.6732 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 380/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6202 - binary_accuracy: 0.6609 - false_negatives: 178.0000 - val_loss: 0.6597 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 381/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6144 - binary_accuracy: 0.6725 - false_negatives: 174.0000 - val_loss: 0.6651 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 382/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6185 - binary_accuracy: 0.6681 - false_negatives: 173.0000 - val_loss: 0.6612 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 383/600\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 0.6137 - binary_accuracy: 0.6594 - false_negatives: 166.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_120546-iwi4ofzb/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 189ms/step - loss: 0.6206 - binary_accuracy: 0.6565 - false_negatives: 184.0000 - val_loss: 0.6226 - val_binary_accuracy: 0.6609 - val_false_negatives: 55.0000\n",
            "Epoch 384/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6204 - binary_accuracy: 0.6522 - false_negatives: 202.0000 - val_loss: 0.6228 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 385/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6142 - binary_accuracy: 0.6870 - false_negatives: 186.0000 - val_loss: 0.6722 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 386/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6176 - binary_accuracy: 0.6797 - false_negatives: 177.0000 - val_loss: 0.6630 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 387/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6078 - binary_accuracy: 0.6812 - false_negatives: 180.0000 - val_loss: 0.6689 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 388/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6216 - binary_accuracy: 0.6652 - false_negatives: 176.0000 - val_loss: 0.6546 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 389/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6228 - binary_accuracy: 0.6493 - false_negatives: 210.0000 - val_loss: 0.6584 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 390/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6214 - binary_accuracy: 0.6652 - false_negatives: 183.0000 - val_loss: 0.6624 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 391/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6145 - binary_accuracy: 0.6710 - false_negatives: 185.0000 - val_loss: 0.6630 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 392/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6194 - binary_accuracy: 0.6681 - false_negatives: 177.0000 - val_loss: 0.6629 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 393/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6258 - binary_accuracy: 0.6464 - false_negatives: 197.0000 - val_loss: 0.6595 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 394/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6162 - binary_accuracy: 0.6696 - false_negatives: 171.0000 - val_loss: 0.6614 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 395/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6153 - binary_accuracy: 0.6725 - false_negatives: 172.0000 - val_loss: 0.6676 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 396/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6277 - binary_accuracy: 0.6551 - false_negatives: 196.0000 - val_loss: 0.6624 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 397/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6310 - binary_accuracy: 0.6551 - false_negatives: 189.0000 - val_loss: 0.6586 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 398/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6172 - binary_accuracy: 0.6812 - false_negatives: 174.0000 - val_loss: 0.6667 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 399/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6160 - binary_accuracy: 0.6797 - false_negatives: 183.0000 - val_loss: 0.6794 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 400/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6246 - binary_accuracy: 0.6565 - false_negatives: 178.0000 - val_loss: 0.6625 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 401/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6205 - binary_accuracy: 0.6449 - false_negatives: 202.0000 - val_loss: 0.6837 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 402/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6173 - binary_accuracy: 0.6696 - false_negatives: 182.0000 - val_loss: 0.6809 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 403/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6138 - binary_accuracy: 0.6623 - false_negatives: 165.0000 - val_loss: 0.6624 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 404/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6208 - binary_accuracy: 0.6710 - false_negatives: 178.0000 - val_loss: 0.6748 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 405/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6200 - binary_accuracy: 0.6652 - false_negatives: 181.0000 - val_loss: 0.6713 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 406/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6251 - binary_accuracy: 0.6565 - false_negatives: 204.0000 - val_loss: 0.6761 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 407/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6268 - binary_accuracy: 0.6507 - false_negatives: 199.0000 - val_loss: 0.6644 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 408/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6265 - binary_accuracy: 0.6478 - false_negatives: 200.0000 - val_loss: 0.6629 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 409/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6176 - binary_accuracy: 0.6652 - false_negatives: 185.0000 - val_loss: 0.6731 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 410/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6184 - binary_accuracy: 0.6710 - false_negatives: 169.0000 - val_loss: 0.6645 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 411/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6193 - binary_accuracy: 0.6826 - false_negatives: 177.0000 - val_loss: 0.6554 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 412/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6180 - binary_accuracy: 0.6696 - false_negatives: 177.0000 - val_loss: 0.6639 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 413/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6144 - binary_accuracy: 0.6725 - false_negatives: 168.0000 - val_loss: 0.6690 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 414/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6167 - binary_accuracy: 0.6623 - false_negatives: 172.0000 - val_loss: 0.6674 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 415/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6177 - binary_accuracy: 0.6812 - false_negatives: 164.0000 - val_loss: 0.6666 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 416/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6263 - binary_accuracy: 0.6449 - false_negatives: 210.0000 - val_loss: 0.6674 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 417/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6239 - binary_accuracy: 0.6638 - false_negatives: 181.0000 - val_loss: 0.6682 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 418/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6245 - binary_accuracy: 0.6580 - false_negatives: 210.0000 - val_loss: 0.6585 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 419/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6199 - binary_accuracy: 0.6565 - false_negatives: 171.0000 - val_loss: 0.6694 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 420/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6304 - binary_accuracy: 0.6464 - false_negatives: 208.0000 - val_loss: 0.6519 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 421/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6214 - binary_accuracy: 0.6652 - false_negatives: 205.0000 - val_loss: 0.6572 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 422/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6223 - binary_accuracy: 0.6493 - false_negatives: 161.0000 - val_loss: 0.6679 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 423/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6236 - binary_accuracy: 0.6493 - false_negatives: 219.0000 - val_loss: 0.6765 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 424/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6247 - binary_accuracy: 0.6623 - false_negatives: 215.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 425/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6222 - binary_accuracy: 0.6522 - false_negatives: 176.0000 - val_loss: 0.6907 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 426/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6217 - binary_accuracy: 0.6667 - false_negatives: 189.0000 - val_loss: 0.6655 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 427/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6206 - binary_accuracy: 0.6681 - false_negatives: 179.0000 - val_loss: 0.6761 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 428/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6325 - binary_accuracy: 0.6507 - false_negatives: 200.0000 - val_loss: 0.6604 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 429/600\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6184 - binary_accuracy: 0.6609 - false_negatives: 199.0000 - val_loss: 0.6649 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 430/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6116 - binary_accuracy: 0.6652 - false_negatives: 166.0000 - val_loss: 0.6953 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 431/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6114 - binary_accuracy: 0.6710 - false_negatives: 177.0000 - val_loss: 0.7016 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 432/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6126 - binary_accuracy: 0.6725 - false_negatives: 175.0000 - val_loss: 0.6870 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 433/600\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.6224 - binary_accuracy: 0.6493 - false_negatives: 170.0000 - val_loss: 0.6679 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 434/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6141 - binary_accuracy: 0.6710 - false_negatives: 180.0000 - val_loss: 0.6709 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 435/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6225 - binary_accuracy: 0.6594 - false_negatives: 195.0000 - val_loss: 0.6723 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 436/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6169 - binary_accuracy: 0.6754 - false_negatives: 179.0000 - val_loss: 0.6787 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 437/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6318 - binary_accuracy: 0.6638 - false_negatives: 193.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 438/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6186 - binary_accuracy: 0.6580 - false_negatives: 186.0000 - val_loss: 0.6775 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 439/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6169 - binary_accuracy: 0.6710 - false_negatives: 190.0000 - val_loss: 0.6915 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 440/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6173 - binary_accuracy: 0.6725 - false_negatives: 164.0000 - val_loss: 0.6856 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 441/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6216 - binary_accuracy: 0.6696 - false_negatives: 180.0000 - val_loss: 0.6701 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 442/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6239 - binary_accuracy: 0.6493 - false_negatives: 211.0000 - val_loss: 0.6676 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 443/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6222 - binary_accuracy: 0.6493 - false_negatives: 205.0000 - val_loss: 0.6702 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 444/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6134 - binary_accuracy: 0.6841 - false_negatives: 162.0000 - val_loss: 0.6764 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 445/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6110 - binary_accuracy: 0.6754 - false_negatives: 169.0000 - val_loss: 0.6702 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 446/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6137 - binary_accuracy: 0.6725 - false_negatives: 173.0000 - val_loss: 0.6959 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 447/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6173 - binary_accuracy: 0.6739 - false_negatives: 169.0000 - val_loss: 0.6644 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 448/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6325 - binary_accuracy: 0.6609 - false_negatives: 198.0000 - val_loss: 0.6499 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 449/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6310 - binary_accuracy: 0.6565 - false_negatives: 193.0000 - val_loss: 0.6625 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 450/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6260 - binary_accuracy: 0.6609 - false_negatives: 200.0000 - val_loss: 0.6498 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 451/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6332 - binary_accuracy: 0.6377 - false_negatives: 216.0000 - val_loss: 0.6523 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 452/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6228 - binary_accuracy: 0.6507 - false_negatives: 206.0000 - val_loss: 0.6562 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 453/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6190 - binary_accuracy: 0.6768 - false_negatives: 185.0000 - val_loss: 0.6602 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 454/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6251 - binary_accuracy: 0.6667 - false_negatives: 189.0000 - val_loss: 0.6557 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 455/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6189 - binary_accuracy: 0.6609 - false_negatives: 192.0000 - val_loss: 0.6587 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 456/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6167 - binary_accuracy: 0.6710 - false_negatives: 170.0000 - val_loss: 0.6705 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 457/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6235 - binary_accuracy: 0.6551 - false_negatives: 185.0000 - val_loss: 0.6568 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 458/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6187 - binary_accuracy: 0.6594 - false_negatives: 200.0000 - val_loss: 0.6639 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 459/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6221 - binary_accuracy: 0.6609 - false_negatives: 164.0000 - val_loss: 0.6647 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 460/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6245 - binary_accuracy: 0.6406 - false_negatives: 218.0000 - val_loss: 0.6518 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 461/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6240 - binary_accuracy: 0.6725 - false_negatives: 178.0000 - val_loss: 0.6573 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 462/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6207 - binary_accuracy: 0.6551 - false_negatives: 202.0000 - val_loss: 0.6630 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 463/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6262 - binary_accuracy: 0.6464 - false_negatives: 185.0000 - val_loss: 0.6557 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 464/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6159 - binary_accuracy: 0.6696 - false_negatives: 174.0000 - val_loss: 0.6639 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 465/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6215 - binary_accuracy: 0.6638 - false_negatives: 181.0000 - val_loss: 0.6594 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 466/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6215 - binary_accuracy: 0.6768 - false_negatives: 178.0000 - val_loss: 0.6643 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 467/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6232 - binary_accuracy: 0.6681 - false_negatives: 189.0000 - val_loss: 0.6571 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 468/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6187 - binary_accuracy: 0.6652 - false_negatives: 178.0000 - val_loss: 0.6643 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 469/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6136 - binary_accuracy: 0.6667 - false_negatives: 175.0000 - val_loss: 0.6612 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 470/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6220 - binary_accuracy: 0.6609 - false_negatives: 168.0000 - val_loss: 0.6542 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 471/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6266 - binary_accuracy: 0.6580 - false_negatives: 204.0000 - val_loss: 0.6597 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 472/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6178 - binary_accuracy: 0.6797 - false_negatives: 174.0000 - val_loss: 0.6611 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 473/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6207 - binary_accuracy: 0.6580 - false_negatives: 170.0000 - val_loss: 0.6606 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 474/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6220 - binary_accuracy: 0.6464 - false_negatives: 197.0000 - val_loss: 0.6708 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 475/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6122 - binary_accuracy: 0.6754 - false_negatives: 158.0000 - val_loss: 0.6744 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 476/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6150 - binary_accuracy: 0.6696 - false_negatives: 172.0000 - val_loss: 0.6636 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 477/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6217 - binary_accuracy: 0.6493 - false_negatives: 184.0000 - val_loss: 0.6666 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 478/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6220 - binary_accuracy: 0.6638 - false_negatives: 191.0000 - val_loss: 0.6573 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 479/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6088 - binary_accuracy: 0.6899 - false_negatives: 158.0000 - val_loss: 0.6647 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 480/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6292 - binary_accuracy: 0.6565 - false_negatives: 180.0000 - val_loss: 0.6612 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 481/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6242 - binary_accuracy: 0.6536 - false_negatives: 183.0000 - val_loss: 0.6544 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 482/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6147 - binary_accuracy: 0.6797 - false_negatives: 176.0000 - val_loss: 0.6616 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 483/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6181 - binary_accuracy: 0.6609 - false_negatives: 185.0000 - val_loss: 0.6642 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 484/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6204 - binary_accuracy: 0.6609 - false_negatives: 163.0000 - val_loss: 0.6609 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 485/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6181 - binary_accuracy: 0.6507 - false_negatives: 189.0000 - val_loss: 0.6651 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 486/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6133 - binary_accuracy: 0.6899 - false_negatives: 180.0000 - val_loss: 0.6637 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 487/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6168 - binary_accuracy: 0.6797 - false_negatives: 167.0000 - val_loss: 0.6609 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 488/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6169 - binary_accuracy: 0.6696 - false_negatives: 180.0000 - val_loss: 0.6614 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 489/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6262 - binary_accuracy: 0.6435 - false_negatives: 189.0000 - val_loss: 0.6568 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 490/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6035 - binary_accuracy: 0.6870 - false_negatives: 169.0000 - val_loss: 0.6767 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 491/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6299 - binary_accuracy: 0.6623 - false_negatives: 169.0000 - val_loss: 0.6596 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 492/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6195 - binary_accuracy: 0.6623 - false_negatives: 203.0000 - val_loss: 0.6649 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 493/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6216 - binary_accuracy: 0.6739 - false_negatives: 166.0000 - val_loss: 0.6606 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 494/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6164 - binary_accuracy: 0.6696 - false_negatives: 191.0000 - val_loss: 0.6617 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 495/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6172 - binary_accuracy: 0.6638 - false_negatives: 178.0000 - val_loss: 0.6645 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 496/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6189 - binary_accuracy: 0.6507 - false_negatives: 178.0000 - val_loss: 0.6492 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 497/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6218 - binary_accuracy: 0.6565 - false_negatives: 202.0000 - val_loss: 0.6601 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 498/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6181 - binary_accuracy: 0.6638 - false_negatives: 184.0000 - val_loss: 0.6715 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 499/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6147 - binary_accuracy: 0.6725 - false_negatives: 163.0000 - val_loss: 0.6691 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 500/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6163 - binary_accuracy: 0.6667 - false_negatives: 190.0000 - val_loss: 0.6659 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 501/600\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6118 - binary_accuracy: 0.6797 - false_negatives: 179.0000 - val_loss: 0.6672 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 502/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6210 - binary_accuracy: 0.6565 - false_negatives: 182.0000 - val_loss: 0.6629 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 503/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6260 - binary_accuracy: 0.6536 - false_negatives: 172.0000 - val_loss: 0.6597 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 504/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6222 - binary_accuracy: 0.6667 - false_negatives: 209.0000 - val_loss: 0.6548 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 505/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6194 - binary_accuracy: 0.6739 - false_negatives: 178.0000 - val_loss: 0.6673 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 506/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6185 - binary_accuracy: 0.6768 - false_negatives: 174.0000 - val_loss: 0.6619 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 507/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6272 - binary_accuracy: 0.6638 - false_negatives: 195.0000 - val_loss: 0.6529 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 508/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6175 - binary_accuracy: 0.6667 - false_negatives: 183.0000 - val_loss: 0.6623 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 509/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6208 - binary_accuracy: 0.6609 - false_negatives: 191.0000 - val_loss: 0.6617 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 510/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6206 - binary_accuracy: 0.6754 - false_negatives: 183.0000 - val_loss: 0.6621 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 511/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6229 - binary_accuracy: 0.6522 - false_negatives: 201.0000 - val_loss: 0.6657 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 512/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6149 - binary_accuracy: 0.6725 - false_negatives: 178.0000 - val_loss: 0.6576 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 513/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6257 - binary_accuracy: 0.6493 - false_negatives: 190.0000 - val_loss: 0.6609 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 514/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6163 - binary_accuracy: 0.6725 - false_negatives: 198.0000 - val_loss: 0.6619 - val_binary_accuracy: 0.6565 - val_false_negatives: 79.0000\n",
            "Epoch 515/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6220 - binary_accuracy: 0.6725 - false_negatives: 165.0000 - val_loss: 0.6574 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 516/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6203 - binary_accuracy: 0.6739 - false_negatives: 191.0000 - val_loss: 0.6526 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 517/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6209 - binary_accuracy: 0.6696 - false_negatives: 185.0000 - val_loss: 0.6482 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 518/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6224 - binary_accuracy: 0.6652 - false_negatives: 184.0000 - val_loss: 0.6523 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 519/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6184 - binary_accuracy: 0.6565 - false_negatives: 193.0000 - val_loss: 0.6506 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 520/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6103 - binary_accuracy: 0.6855 - false_negatives: 178.0000 - val_loss: 0.6595 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 521/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6117 - binary_accuracy: 0.6768 - false_negatives: 179.0000 - val_loss: 0.6635 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 522/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6263 - binary_accuracy: 0.6536 - false_negatives: 184.0000 - val_loss: 0.6569 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 523/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6318 - binary_accuracy: 0.6478 - false_negatives: 204.0000 - val_loss: 0.6485 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 524/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6315 - binary_accuracy: 0.6551 - false_negatives: 206.0000 - val_loss: 0.6464 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 525/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6222 - binary_accuracy: 0.6536 - false_negatives: 195.0000 - val_loss: 0.6567 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 526/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6184 - binary_accuracy: 0.6667 - false_negatives: 175.0000 - val_loss: 0.6615 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 527/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6293 - binary_accuracy: 0.6493 - false_negatives: 200.0000 - val_loss: 0.6508 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 528/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6162 - binary_accuracy: 0.6768 - false_negatives: 185.0000 - val_loss: 0.6651 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 529/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6202 - binary_accuracy: 0.6623 - false_negatives: 180.0000 - val_loss: 0.6555 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 530/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6142 - binary_accuracy: 0.6725 - false_negatives: 178.0000 - val_loss: 0.6593 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 531/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6242 - binary_accuracy: 0.6696 - false_negatives: 180.0000 - val_loss: 0.6506 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 532/600\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6407 - binary_accuracy: 0.6304 - false_negatives: 208.0000 - val_loss: 0.6429 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 533/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6219 - binary_accuracy: 0.6638 - false_negatives: 211.0000 - val_loss: 0.6305 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 534/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6235 - binary_accuracy: 0.6551 - false_negatives: 190.0000 - val_loss: 0.7016 - val_binary_accuracy: 0.5826 - val_false_negatives: 39.0000\n",
            "Epoch 535/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6291 - binary_accuracy: 0.6420 - false_negatives: 198.0000 - val_loss: 0.6368 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 536/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6280 - binary_accuracy: 0.6348 - false_negatives: 226.0000 - val_loss: 0.6313 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 537/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6216 - binary_accuracy: 0.6435 - false_negatives: 197.0000 - val_loss: 0.6415 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 538/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6171 - binary_accuracy: 0.6638 - false_negatives: 180.0000 - val_loss: 0.6282 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 539/600\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6247 - binary_accuracy: 0.6377 - false_negatives: 190.0000 - val_loss: 0.6345 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 540/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6256 - binary_accuracy: 0.6725 - false_negatives: 191.0000 - val_loss: 0.6463 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 541/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6286 - binary_accuracy: 0.6594 - false_negatives: 198.0000 - val_loss: 0.6415 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 542/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6218 - binary_accuracy: 0.6652 - false_negatives: 203.0000 - val_loss: 0.6600 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 543/600\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.6162 - binary_accuracy: 0.6623 - false_negatives: 172.0000 - val_loss: 0.6593 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 544/600\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.6286 - binary_accuracy: 0.6275 - false_negatives: 201.0000 - val_loss: 0.6517 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 545/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6219 - binary_accuracy: 0.6681 - false_negatives: 204.0000 - val_loss: 0.6547 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 546/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6262 - binary_accuracy: 0.6536 - false_negatives: 177.0000 - val_loss: 0.6496 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 547/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6253 - binary_accuracy: 0.6667 - false_negatives: 190.0000 - val_loss: 0.6506 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 548/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6123 - binary_accuracy: 0.6783 - false_negatives: 170.0000 - val_loss: 0.6643 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 549/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6283 - binary_accuracy: 0.6420 - false_negatives: 169.0000 - val_loss: 0.6473 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 550/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6175 - binary_accuracy: 0.6826 - false_negatives: 193.0000 - val_loss: 0.6594 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 551/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6272 - binary_accuracy: 0.6594 - false_negatives: 183.0000 - val_loss: 0.6470 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 552/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6243 - binary_accuracy: 0.6710 - false_negatives: 180.0000 - val_loss: 0.6544 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 553/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6207 - binary_accuracy: 0.6507 - false_negatives: 202.0000 - val_loss: 0.6572 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 554/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6278 - binary_accuracy: 0.6652 - false_negatives: 187.0000 - val_loss: 0.6548 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 555/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6248 - binary_accuracy: 0.6493 - false_negatives: 215.0000 - val_loss: 0.6493 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 556/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6215 - binary_accuracy: 0.6493 - false_negatives: 190.0000 - val_loss: 0.6545 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 557/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6146 - binary_accuracy: 0.6696 - false_negatives: 172.0000 - val_loss: 0.6543 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 558/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6166 - binary_accuracy: 0.6710 - false_negatives: 180.0000 - val_loss: 0.6598 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 559/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6245 - binary_accuracy: 0.6493 - false_negatives: 188.0000 - val_loss: 0.6540 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 560/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6241 - binary_accuracy: 0.6507 - false_negatives: 189.0000 - val_loss: 0.6534 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 561/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6264 - binary_accuracy: 0.6507 - false_negatives: 199.0000 - val_loss: 0.6491 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 562/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6206 - binary_accuracy: 0.6522 - false_negatives: 207.0000 - val_loss: 0.6529 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 563/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6218 - binary_accuracy: 0.6522 - false_negatives: 187.0000 - val_loss: 0.6514 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 564/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6178 - binary_accuracy: 0.6580 - false_negatives: 191.0000 - val_loss: 0.6686 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 565/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6266 - binary_accuracy: 0.6565 - false_negatives: 207.0000 - val_loss: 0.6522 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 566/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6185 - binary_accuracy: 0.6565 - false_negatives: 198.0000 - val_loss: 0.6573 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 567/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6181 - binary_accuracy: 0.6710 - false_negatives: 197.0000 - val_loss: 0.6604 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 568/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6200 - binary_accuracy: 0.6667 - false_negatives: 180.0000 - val_loss: 0.6527 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 569/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6199 - binary_accuracy: 0.6681 - false_negatives: 177.0000 - val_loss: 0.6602 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 570/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6133 - binary_accuracy: 0.6783 - false_negatives: 183.0000 - val_loss: 0.6655 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 571/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6288 - binary_accuracy: 0.6478 - false_negatives: 182.0000 - val_loss: 0.6486 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 572/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6223 - binary_accuracy: 0.6580 - false_negatives: 201.0000 - val_loss: 0.6545 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 573/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6066 - binary_accuracy: 0.6826 - false_negatives: 176.0000 - val_loss: 0.6708 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 574/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6271 - binary_accuracy: 0.6623 - false_negatives: 184.0000 - val_loss: 0.6584 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 575/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6222 - binary_accuracy: 0.6594 - false_negatives: 176.0000 - val_loss: 0.6543 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 576/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6187 - binary_accuracy: 0.6522 - false_negatives: 193.0000 - val_loss: 0.6584 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 577/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6235 - binary_accuracy: 0.6594 - false_negatives: 183.0000 - val_loss: 0.6546 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 578/600\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6256 - binary_accuracy: 0.6507 - false_negatives: 203.0000 - val_loss: 0.6527 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 579/600\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6078 - binary_accuracy: 0.6754 - false_negatives: 173.0000 - val_loss: 0.6712 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 580/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6128 - binary_accuracy: 0.6739 - false_negatives: 184.0000 - val_loss: 0.6620 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 581/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6196 - binary_accuracy: 0.6609 - false_negatives: 179.0000 - val_loss: 0.6518 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 582/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6177 - binary_accuracy: 0.6638 - false_negatives: 197.0000 - val_loss: 0.6622 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 583/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6228 - binary_accuracy: 0.6536 - false_negatives: 176.0000 - val_loss: 0.6597 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 584/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6224 - binary_accuracy: 0.6623 - false_negatives: 199.0000 - val_loss: 0.6542 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 585/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6237 - binary_accuracy: 0.6638 - false_negatives: 184.0000 - val_loss: 0.6499 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 586/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6267 - binary_accuracy: 0.6522 - false_negatives: 204.0000 - val_loss: 0.6499 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 587/600\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6256 - binary_accuracy: 0.6652 - false_negatives: 159.0000 - val_loss: 0.6549 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 588/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6287 - binary_accuracy: 0.6493 - false_negatives: 208.0000 - val_loss: 0.6457 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 589/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6278 - binary_accuracy: 0.6493 - false_negatives: 178.0000 - val_loss: 0.6502 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 590/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6262 - binary_accuracy: 0.6493 - false_negatives: 221.0000 - val_loss: 0.6561 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 591/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6237 - binary_accuracy: 0.6565 - false_negatives: 201.0000 - val_loss: 0.6616 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 592/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6273 - binary_accuracy: 0.6580 - false_negatives: 176.0000 - val_loss: 0.6560 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 593/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6261 - binary_accuracy: 0.6551 - false_negatives: 209.0000 - val_loss: 0.6535 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 594/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6266 - binary_accuracy: 0.6493 - false_negatives: 185.0000 - val_loss: 0.6563 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 595/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6254 - binary_accuracy: 0.6638 - false_negatives: 191.0000 - val_loss: 0.6551 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 596/600\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6265 - binary_accuracy: 0.6565 - false_negatives: 205.0000 - val_loss: 0.6551 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 597/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6241 - binary_accuracy: 0.6522 - false_negatives: 193.0000 - val_loss: 0.6594 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 598/600\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6191 - binary_accuracy: 0.6623 - false_negatives: 180.0000 - val_loss: 0.6639 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 599/600\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6230 - binary_accuracy: 0.6609 - false_negatives: 189.0000 - val_loss: 0.6614 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n",
            "Epoch 600/600\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6218 - binary_accuracy: 0.6681 - false_negatives: 191.0000 - val_loss: 0.6600 - val_binary_accuracy: 0.6609 - val_false_negatives: 78.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c9e14e7df90>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(model4.history.history)[['loss','val_loss']].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "WSriByOoSFQj",
        "outputId": "c8985345-1f65-4a3c-9323-2abd0a4d0ce3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = Sequential()"
      ],
      "metadata": {
        "id": "q-J4Frz2W1dy"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.add(Dense(units=35,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model5.add(Dense(units=500,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model5.add(Dense(units=500,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model5.add(Dropout(0.2))\n",
        "\n",
        "model5.add(BatchNormalization())\n",
        "\n",
        "model5.add(Dense(units=400,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model5.add(Dense(units=400,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model5.add(Dropout(0.2))\n",
        "\n",
        "model5.add(BatchNormalization())\n",
        "\n",
        "model5.add(Dense(units=300,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model5.add(Dense(units=300,activation='relu',kernel_initializer='he_normal',kernel_regularizer=L2(0.03)))\n",
        "\n",
        "model5.add(Dropout(0.2))\n",
        "\n",
        "model5.add(BatchNormalization())\n",
        "\n",
        "model5.add(Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "2kOGEbr5XfMy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
        "              tf.keras.metrics.FalseNegatives()])"
      ],
      "metadata": {
        "id": "fTSIQiyuX13D"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = 'Startups',name = 'Fifth Trail')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "e707ce8d043c4cccaaf6629aace5cdd8",
            "7c8d872bc68d423fbbbe910d77d16ab3",
            "7b649d7e0ad44e50bf22f150f3d04f1b",
            "01b9ea89c7614d1aae3b5090b12b568d",
            "24681ce362ba4303899da0b334398d9c",
            "f1ab21fa4932460d862fcdb2211d9400",
            "54916c17070b4a509a56db7bc8917f58",
            "aa445047f6b14c509eab4f09b9820194"
          ]
        },
        "id": "Is7i4AQIYCRs",
        "outputId": "dcc44da6-30b9-4142-f273-817d7714b737"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:pchov1yp) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='161.471 MB of 161.471 MB uploaded (0.399 MB deduped)\\r'), FloatProgress(value=1.0,…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e707ce8d043c4cccaaf6629aace5cdd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>binary_accuracy</td><td>▅▇▆▆▇▅▇▇▆▄█▇▅▁▆▅▇▅▆▅▂▄▆▆▆▆▄▅▆▄▅▅▆▃▄▆▇▆▂▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>false_negatives_1</td><td>▄█▆▇▅▇▆▄▇▁▆█▃▂▅▆▄▆▄█▁▆▆▆▅▇▆▃▄▆▃▇▆▅▄▆█▆▃▅</td></tr><tr><td>loss</td><td>▂▃▂▁█▅▅▄▄▄▃▄▃▃▄▃▃▂▂▂▂▂▂▁▁▁▂▁▁▁▁▃▂▂▂▁▂▁▁▂</td></tr><tr><td>val_binary_accuracy</td><td>█████▁██▁▁▁██▁████▁███▇▁█████████▁████▁█</td></tr><tr><td>val_false_negatives_1</td><td>█████▁██▁▁▁██▁████▁████▁█████████▁████▁█</td></tr><tr><td>val_loss</td><td>▂▃▂▁▇▅▅▃▃▄▃▄▃▃▄▃▃▂▂▂▂▂▂▁▁▁█▁▁▁▁▄▂▂▂▁▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>409</td></tr><tr><td>best_val_loss</td><td>6.98129</td></tr><tr><td>binary_accuracy</td><td>0.63188</td></tr><tr><td>epoch</td><td>599</td></tr><tr><td>false_negatives_1</td><td>228.0</td></tr><tr><td>loss</td><td>13.40311</td></tr><tr><td>val_binary_accuracy</td><td>0.65652</td></tr><tr><td>val_false_negatives_1</td><td>79.0</td></tr><tr><td>val_loss</td><td>12.53858</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Fifth Trail</strong> at: <a href='https://wandb.ai/ossm0394/Startups/runs/pchov1yp' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/pchov1yp</a><br/>Synced 5 W&B file(s), 1 media file(s), 75 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231002_123251-pchov1yp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:pchov1yp). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231002_123945-sadt98gk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ossm0394/Startups/runs/sadt98gk' target=\"_blank\">Fifth Trail</a></strong> to <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">https://wandb.ai/ossm0394/Startups</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ossm0394/Startups/runs/sadt98gk' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/sadt98gk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ossm0394/Startups/runs/sadt98gk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c9de8354e50>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.fit(x = x_train,y = y_train,epochs = 1000,validation_data = (x_test,y_test),callbacks = [WandbCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_N2v8d1X-J2",
        "outputId": "eeec2308-a85e-415f-e767-f5cd2a4da711"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 57.1952 - binary_accuracy: 0.5984 - false_negatives_2: 119.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 10s 156ms/step - loss: 55.2268 - binary_accuracy: 0.5957 - false_negatives_2: 135.0000 - val_loss: 40.2437 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 21.7971 - binary_accuracy: 0.6324 - false_negatives_2: 139.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 152ms/step - loss: 21.7336 - binary_accuracy: 0.6348 - false_negatives_2: 140.0000 - val_loss: 19.3282 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 3/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 18.7282 - binary_accuracy: 0.6053 - false_negatives_2: 164.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 168ms/step - loss: 18.5679 - binary_accuracy: 0.5884 - false_negatives_2: 167.0000 - val_loss: 17.3384 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 15.5649 - binary_accuracy: 0.6232 - false_negatives_2: 182.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 5s 218ms/step - loss: 15.5649 - binary_accuracy: 0.6232 - false_negatives_2: 182.0000 - val_loss: 13.1880 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 5/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 12.6190 - binary_accuracy: 0.6406 - false_negatives_2: 176.0000 - val_loss: 14.1692 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 6/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 13.6775 - binary_accuracy: 0.6435 - false_negatives_2: 175.0000 - val_loss: 13.2450 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 7/1000\n",
            "22/22 [==============================] - ETA: 0s - loss: 12.0574 - binary_accuracy: 0.6420 - false_negatives_2: 218.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 146ms/step - loss: 12.0574 - binary_accuracy: 0.6420 - false_negatives_2: 218.0000 - val_loss: 10.8610 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 8/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 10.3081 - binary_accuracy: 0.6372 - false_negatives_2: 154.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 150ms/step - loss: 10.3041 - binary_accuracy: 0.6304 - false_negatives_2: 186.0000 - val_loss: 9.9999 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 9/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.9314 - binary_accuracy: 0.6246 - false_negatives_2: 225.0000 - val_loss: 10.3176 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 10.7528 - binary_accuracy: 0.6203 - false_negatives_2: 203.0000 - val_loss: 10.7484 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 12.3030 - binary_accuracy: 0.6362 - false_negatives_2: 219.0000 - val_loss: 15.3529 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.2703 - binary_accuracy: 0.6507 - false_negatives_2: 232.0000 - val_loss: 15.9146 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 14.9704 - binary_accuracy: 0.6406 - false_negatives_2: 228.0000 - val_loss: 13.6744 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 14/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 14.0565 - binary_accuracy: 0.6478 - false_negatives_2: 221.0000 - val_loss: 14.2868 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.3710 - binary_accuracy: 0.6290 - false_negatives_2: 234.0000 - val_loss: 14.1705 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 16/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 13.5434 - binary_accuracy: 0.6333 - false_negatives_2: 233.0000 - val_loss: 13.0855 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 12.6723 - binary_accuracy: 0.6391 - false_negatives_2: 243.0000 - val_loss: 13.1507 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 13.2223 - binary_accuracy: 0.6391 - false_negatives_2: 231.0000 - val_loss: 12.8545 - val_binary_accuracy: 0.3826 - val_false_negatives_2: 4.0000\n",
            "Epoch 19/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 12.8776 - binary_accuracy: 0.6391 - false_negatives_2: 226.0000 - val_loss: 16.9603 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 14.5086 - binary_accuracy: 0.6188 - false_negatives_2: 224.0000 - val_loss: 14.3469 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 21/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 14.6530 - binary_accuracy: 0.6377 - false_negatives_2: 245.0000 - val_loss: 14.5694 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 22/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 14.7044 - binary_accuracy: 0.6348 - false_negatives_2: 240.0000 - val_loss: 15.5613 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 23/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 16.7414 - binary_accuracy: 0.6377 - false_negatives_2: 209.0000 - val_loss: 19.3033 - val_binary_accuracy: 0.6478 - val_false_negatives_2: 77.0000\n",
            "Epoch 24/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 21.3387 - binary_accuracy: 0.6348 - false_negatives_2: 236.0000 - val_loss: 19.9191 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 25/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.6195 - binary_accuracy: 0.6304 - false_negatives_2: 218.0000 - val_loss: 17.2987 - val_binary_accuracy: 0.6217 - val_false_negatives_2: 76.0000\n",
            "Epoch 26/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.6702 - binary_accuracy: 0.6232 - false_negatives_2: 210.0000 - val_loss: 15.7579 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 27/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.6589 - binary_accuracy: 0.6290 - false_negatives_2: 201.0000 - val_loss: 15.5481 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 28/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.0386 - binary_accuracy: 0.6464 - false_negatives_2: 235.0000 - val_loss: 15.2576 - val_binary_accuracy: 0.6435 - val_false_negatives_2: 78.0000\n",
            "Epoch 29/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.6739 - binary_accuracy: 0.6275 - false_negatives_2: 236.0000 - val_loss: 13.9483 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 30/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.9106 - binary_accuracy: 0.6406 - false_negatives_2: 235.0000 - val_loss: 13.5597 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 31/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.4927 - binary_accuracy: 0.6420 - false_negatives_2: 239.0000 - val_loss: 13.7926 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 14.0379 - binary_accuracy: 0.6348 - false_negatives_2: 231.0000 - val_loss: 14.0094 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.5795 - binary_accuracy: 0.6435 - false_negatives_2: 242.0000 - val_loss: 13.7101 - val_binary_accuracy: 0.3870 - val_false_negatives_2: 3.0000\n",
            "Epoch 34/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.1479 - binary_accuracy: 0.6333 - false_negatives_2: 237.0000 - val_loss: 12.7231 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 35/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.9384 - binary_accuracy: 0.6406 - false_negatives_2: 244.0000 - val_loss: 12.8881 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 36/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 13.3752 - binary_accuracy: 0.6261 - false_negatives_2: 219.0000 - val_loss: 13.4535 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 37/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.8268 - binary_accuracy: 0.6507 - false_negatives_2: 228.0000 - val_loss: 13.5377 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 38/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.2062 - binary_accuracy: 0.6377 - false_negatives_2: 222.0000 - val_loss: 13.7825 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 39/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.7469 - binary_accuracy: 0.6261 - false_negatives_2: 243.0000 - val_loss: 12.1442 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 40/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.0320 - binary_accuracy: 0.6435 - false_negatives_2: 239.0000 - val_loss: 11.7842 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 41/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.5540 - binary_accuracy: 0.6478 - false_negatives_2: 242.0000 - val_loss: 11.3437 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 42/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 11.4117 - binary_accuracy: 0.6464 - false_negatives_2: 238.0000 - val_loss: 11.8846 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.8653 - binary_accuracy: 0.6391 - false_negatives_2: 236.0000 - val_loss: 11.9158 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 44/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 11.3428 - binary_accuracy: 0.6464 - false_negatives_2: 236.0000 - val_loss: 11.6291 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 45/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 11.0391 - binary_accuracy: 0.6116 - false_negatives_2: 212.0000 - val_loss: 11.2647 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 10.7059 - binary_accuracy: 0.6406 - false_negatives_2: 238.0000 - val_loss: 10.5460 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 47/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 10.5104 - binary_accuracy: 0.6435 - false_negatives_2: 244.0000 - val_loss: 11.2607 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.5452 - binary_accuracy: 0.6246 - false_negatives_2: 224.0000 - val_loss: 12.5833 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 13.6870 - binary_accuracy: 0.6377 - false_negatives_2: 238.0000 - val_loss: 14.1458 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 13.2165 - binary_accuracy: 0.6290 - false_negatives_2: 241.0000 - val_loss: 12.4929 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 51/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 12.1709 - binary_accuracy: 0.6493 - false_negatives_2: 183.0000 - val_loss: 12.4231 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 52/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.3438 - binary_accuracy: 0.6420 - false_negatives_2: 232.0000 - val_loss: 20.4395 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 28.3082 - binary_accuracy: 0.6362 - false_negatives_2: 227.0000 - val_loss: 32.9746 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 54/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 31.7204 - binary_accuracy: 0.6348 - false_negatives_2: 209.0000 - val_loss: 31.0733 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 55/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 30.5676 - binary_accuracy: 0.6435 - false_negatives_2: 223.0000 - val_loss: 30.6089 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 56/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 27.2038 - binary_accuracy: 0.6391 - false_negatives_2: 243.0000 - val_loss: 24.6421 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 57/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 24.8708 - binary_accuracy: 0.6478 - false_negatives_2: 237.0000 - val_loss: 25.3330 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 58/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 27.0112 - binary_accuracy: 0.6420 - false_negatives_2: 245.0000 - val_loss: 29.4210 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 28.6886 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 27.4076 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 60/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 26.1827 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 24.9351 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 61/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 24.0828 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 23.1567 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 22.7027 - binary_accuracy: 0.6406 - false_negatives_2: 245.0000 - val_loss: 22.1798 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 63/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 21.7476 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 21.1841 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 20.7245 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 20.2346 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 65/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 20.0636 - binary_accuracy: 0.6348 - false_negatives_2: 224.0000 - val_loss: 20.4208 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 66/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 20.7464 - binary_accuracy: 0.6348 - false_negatives_2: 224.0000 - val_loss: 22.1476 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.9037 - binary_accuracy: 0.6478 - false_negatives_2: 220.0000 - val_loss: 21.9272 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 68/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 21.4915 - binary_accuracy: 0.6435 - false_negatives_2: 220.0000 - val_loss: 24.4555 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 69/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 25.8056 - binary_accuracy: 0.6319 - false_negatives_2: 242.0000 - val_loss: 25.7918 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 23.7021 - binary_accuracy: 0.6333 - false_negatives_2: 225.0000 - val_loss: 22.5921 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.5539 - binary_accuracy: 0.6377 - false_negatives_2: 233.0000 - val_loss: 22.7221 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 72/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 23.3601 - binary_accuracy: 0.6507 - false_negatives_2: 239.0000 - val_loss: 26.8148 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 73/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.5246 - binary_accuracy: 0.6391 - false_negatives_2: 235.0000 - val_loss: 23.4159 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 74/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 24.1175 - binary_accuracy: 0.6348 - false_negatives_2: 239.0000 - val_loss: 23.0591 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 75/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.0124 - binary_accuracy: 0.6348 - false_negatives_2: 235.0000 - val_loss: 21.6407 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.7908 - binary_accuracy: 0.6319 - false_negatives_2: 208.0000 - val_loss: 21.0407 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 77/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 20.9948 - binary_accuracy: 0.6435 - false_negatives_2: 243.0000 - val_loss: 21.1879 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 78/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.6106 - binary_accuracy: 0.6246 - false_negatives_2: 243.0000 - val_loss: 21.0120 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 79/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.9053 - binary_accuracy: 0.6348 - false_negatives_2: 231.0000 - val_loss: 20.7038 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 21.7599 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 22.1408 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.0642 - binary_accuracy: 0.6101 - false_negatives_2: 228.0000 - val_loss: 21.5283 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 82/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 20.0377 - binary_accuracy: 0.6391 - false_negatives_2: 242.0000 - val_loss: 17.7492 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 16.7536 - binary_accuracy: 0.6420 - false_negatives_2: 243.0000 - val_loss: 16.3245 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 84/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.9007 - binary_accuracy: 0.6348 - false_negatives_2: 232.0000 - val_loss: 16.9250 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 85/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 23.8069 - binary_accuracy: 0.6275 - false_negatives_2: 209.0000 - val_loss: 33.0581 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 30.3106 - binary_accuracy: 0.6435 - false_negatives_2: 243.0000 - val_loss: 26.8932 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.4582 - binary_accuracy: 0.6449 - false_negatives_2: 227.0000 - val_loss: 22.9922 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 88/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.0749 - binary_accuracy: 0.6333 - false_negatives_2: 234.0000 - val_loss: 19.7272 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.1362 - binary_accuracy: 0.6406 - false_negatives_2: 213.0000 - val_loss: 18.4320 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 17.6154 - binary_accuracy: 0.6072 - false_negatives_2: 227.0000 - val_loss: 17.2314 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 17.5479 - binary_accuracy: 0.6014 - false_negatives_2: 208.0000 - val_loss: 18.3912 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 92/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 19.0656 - binary_accuracy: 0.6377 - false_negatives_2: 209.0000 - val_loss: 21.7746 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.1408 - binary_accuracy: 0.6377 - false_negatives_2: 202.0000 - val_loss: 17.5256 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 94/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.9633 - binary_accuracy: 0.6304 - false_negatives_2: 236.0000 - val_loss: 16.5978 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 95/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.5457 - binary_accuracy: 0.6319 - false_negatives_2: 226.0000 - val_loss: 18.0525 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 96/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.1858 - binary_accuracy: 0.6319 - false_negatives_2: 228.0000 - val_loss: 18.2738 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 97/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.3400 - binary_accuracy: 0.6435 - false_negatives_2: 219.0000 - val_loss: 19.0381 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 98/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 20.0388 - binary_accuracy: 0.5957 - false_negatives_2: 214.0000 - val_loss: 19.8911 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 99/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 20.0937 - binary_accuracy: 0.6377 - false_negatives_2: 220.0000 - val_loss: 20.0438 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 20.1155 - binary_accuracy: 0.6203 - false_negatives_2: 227.0000 - val_loss: 19.3101 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 19.0501 - binary_accuracy: 0.6333 - false_negatives_2: 220.0000 - val_loss: 18.4531 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 102/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 18.2186 - binary_accuracy: 0.6391 - false_negatives_2: 243.0000 - val_loss: 18.1080 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 103/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 18.4628 - binary_accuracy: 0.6565 - false_negatives_2: 223.0000 - val_loss: 18.2209 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 20.3650 - binary_accuracy: 0.6319 - false_negatives_2: 214.0000 - val_loss: 22.7117 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 105/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 22.6064 - binary_accuracy: 0.6493 - false_negatives_2: 235.0000 - val_loss: 21.0502 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 106/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 19.5039 - binary_accuracy: 0.6435 - false_negatives_2: 245.0000 - val_loss: 18.5912 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.4755 - binary_accuracy: 0.6449 - false_negatives_2: 244.0000 - val_loss: 16.5645 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 16.2639 - binary_accuracy: 0.6449 - false_negatives_2: 231.0000 - val_loss: 16.5512 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.5101 - binary_accuracy: 0.6116 - false_negatives_2: 236.0000 - val_loss: 16.7435 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 110/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 17.4045 - binary_accuracy: 0.6536 - false_negatives_2: 230.0000 - val_loss: 17.2373 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 111/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 16.9221 - binary_accuracy: 0.6058 - false_negatives_2: 200.0000 - val_loss: 19.0598 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 112/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.9417 - binary_accuracy: 0.6290 - false_negatives_2: 226.0000 - val_loss: 40.0882 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 113/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 45.7671 - binary_accuracy: 0.6348 - false_negatives_2: 236.0000 - val_loss: 46.0547 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 114/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 43.2960 - binary_accuracy: 0.6319 - false_negatives_2: 243.0000 - val_loss: 40.2366 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 115/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 38.2030 - binary_accuracy: 0.6304 - false_negatives_2: 236.0000 - val_loss: 36.7456 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 116/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 34.5980 - binary_accuracy: 0.6435 - false_negatives_2: 245.0000 - val_loss: 32.5211 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 117/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 31.5998 - binary_accuracy: 0.6304 - false_negatives_2: 235.0000 - val_loss: 30.1952 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 118/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 30.4261 - binary_accuracy: 0.6246 - false_negatives_2: 230.0000 - val_loss: 29.6754 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 119/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 28.5942 - binary_accuracy: 0.6406 - false_negatives_2: 232.0000 - val_loss: 27.6789 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 120/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 26.9090 - binary_accuracy: 0.6261 - false_negatives_2: 237.0000 - val_loss: 26.6690 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 121/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 26.9222 - binary_accuracy: 0.6362 - false_negatives_2: 215.0000 - val_loss: 27.8399 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 122/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 27.2396 - binary_accuracy: 0.6072 - false_negatives_2: 221.0000 - val_loss: 26.6148 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 123/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 26.5766 - binary_accuracy: 0.6261 - false_negatives_2: 227.0000 - val_loss: 25.6410 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 124/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 24.6364 - binary_accuracy: 0.6391 - false_negatives_2: 218.0000 - val_loss: 23.5347 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 125/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.5602 - binary_accuracy: 0.6275 - false_negatives_2: 198.0000 - val_loss: 23.2453 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 126/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 23.2198 - binary_accuracy: 0.6333 - false_negatives_2: 235.0000 - val_loss: 22.9618 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 127/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.3858 - binary_accuracy: 0.6304 - false_negatives_2: 233.0000 - val_loss: 21.3630 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 128/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 20.5313 - binary_accuracy: 0.6348 - false_negatives_2: 238.0000 - val_loss: 19.9894 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 129/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.1860 - binary_accuracy: 0.6014 - false_negatives_2: 207.0000 - val_loss: 19.7730 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 130/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.9088 - binary_accuracy: 0.6130 - false_negatives_2: 223.0000 - val_loss: 18.1707 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 131/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.0498 - binary_accuracy: 0.6072 - false_negatives_2: 234.0000 - val_loss: 18.5566 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.1135 - binary_accuracy: 0.6594 - false_negatives_2: 211.0000 - val_loss: 19.5483 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 133/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.6698 - binary_accuracy: 0.6217 - false_negatives_2: 216.0000 - val_loss: 17.5525 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 134/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.7481 - binary_accuracy: 0.6319 - false_negatives_2: 239.0000 - val_loss: 16.5898 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 135/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 16.2040 - binary_accuracy: 0.6333 - false_negatives_2: 202.0000 - val_loss: 15.8606 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 136/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 15.9224 - binary_accuracy: 0.6377 - false_negatives_2: 238.0000 - val_loss: 16.5061 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 137/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 16.2540 - binary_accuracy: 0.6333 - false_negatives_2: 228.0000 - val_loss: 15.7781 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 138/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 20.1170 - binary_accuracy: 0.6217 - false_negatives_2: 213.0000 - val_loss: 25.2161 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 139/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 25.9726 - binary_accuracy: 0.6406 - false_negatives_2: 197.0000 - val_loss: 25.5345 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 140/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 24.3222 - binary_accuracy: 0.6319 - false_negatives_2: 231.0000 - val_loss: 23.3287 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 141/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 23.1387 - binary_accuracy: 0.6275 - false_negatives_2: 225.0000 - val_loss: 24.0896 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 24.4654 - binary_accuracy: 0.6406 - false_negatives_2: 233.0000 - val_loss: 25.1391 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 143/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 26.1940 - binary_accuracy: 0.6406 - false_negatives_2: 217.0000 - val_loss: 24.4061 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 144/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 23.1153 - binary_accuracy: 0.5855 - false_negatives_2: 205.0000 - val_loss: 22.1145 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 145/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 22.0679 - binary_accuracy: 0.6362 - false_negatives_2: 201.0000 - val_loss: 23.6946 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 146/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 25.5585 - binary_accuracy: 0.6362 - false_negatives_2: 210.0000 - val_loss: 26.2051 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 147/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 25.7396 - binary_accuracy: 0.6406 - false_negatives_2: 245.0000 - val_loss: 24.8426 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 23.4724 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 22.3992 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 149/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.4784 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 22.4952 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 150/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 22.0316 - binary_accuracy: 0.6420 - false_negatives_2: 242.0000 - val_loss: 21.3907 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 151/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.1464 - binary_accuracy: 0.6449 - false_negatives_2: 241.0000 - val_loss: 21.1852 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 152/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.8328 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 19.9927 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 153/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 20.5702 - binary_accuracy: 0.6478 - false_negatives_2: 223.0000 - val_loss: 21.2451 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 154/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.9961 - binary_accuracy: 0.6391 - false_negatives_2: 245.0000 - val_loss: 20.2055 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 155/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.7188 - binary_accuracy: 0.6304 - false_negatives_2: 229.0000 - val_loss: 19.7218 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 156/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.2221 - binary_accuracy: 0.6261 - false_negatives_2: 240.0000 - val_loss: 19.1457 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 157/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.1068 - binary_accuracy: 0.6464 - false_negatives_2: 218.0000 - val_loss: 19.6443 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 158/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.5886 - binary_accuracy: 0.6406 - false_negatives_2: 244.0000 - val_loss: 19.7158 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 159/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.0748 - binary_accuracy: 0.6377 - false_negatives_2: 231.0000 - val_loss: 18.2799 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 160/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.2538 - binary_accuracy: 0.6478 - false_negatives_2: 243.0000 - val_loss: 18.0480 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 161/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 17.2544 - binary_accuracy: 0.6420 - false_negatives_2: 234.0000 - val_loss: 16.6177 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 162/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 19.1529 - binary_accuracy: 0.6319 - false_negatives_2: 226.0000 - val_loss: 19.8603 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 163/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.8892 - binary_accuracy: 0.6159 - false_negatives_2: 207.0000 - val_loss: 20.1310 - val_binary_accuracy: 0.4174 - val_false_negatives_2: 9.0000\n",
            "Epoch 164/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.5617 - binary_accuracy: 0.6464 - false_negatives_2: 242.0000 - val_loss: 18.8389 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 165/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.4503 - binary_accuracy: 0.6420 - false_negatives_2: 224.0000 - val_loss: 18.5052 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 166/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.3327 - binary_accuracy: 0.6406 - false_negatives_2: 243.0000 - val_loss: 18.2563 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 167/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.2771 - binary_accuracy: 0.6377 - false_negatives_2: 239.0000 - val_loss: 18.9013 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.5739 - binary_accuracy: 0.6130 - false_negatives_2: 229.0000 - val_loss: 17.2398 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 169/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.7766 - binary_accuracy: 0.6333 - false_negatives_2: 243.0000 - val_loss: 19.7342 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 170/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.7515 - binary_accuracy: 0.6159 - false_negatives_2: 192.0000 - val_loss: 19.7904 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 171/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.1552 - binary_accuracy: 0.6000 - false_negatives_2: 218.0000 - val_loss: 18.7697 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 172/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 19.2119 - binary_accuracy: 0.6159 - false_negatives_2: 222.0000 - val_loss: 18.5303 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 173/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 17.9147 - binary_accuracy: 0.6348 - false_negatives_2: 233.0000 - val_loss: 17.9448 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 174/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.3576 - binary_accuracy: 0.6333 - false_negatives_2: 225.0000 - val_loss: 19.1810 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 175/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.2188 - binary_accuracy: 0.6406 - false_negatives_2: 244.0000 - val_loss: 18.6196 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 176/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.5740 - binary_accuracy: 0.6362 - false_negatives_2: 232.0000 - val_loss: 19.3640 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 177/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.8561 - binary_accuracy: 0.6406 - false_negatives_2: 239.0000 - val_loss: 20.2012 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 178/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 19.9361 - binary_accuracy: 0.6420 - false_negatives_2: 238.0000 - val_loss: 19.0265 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 179/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 18.9034 - binary_accuracy: 0.6478 - false_negatives_2: 241.0000 - val_loss: 20.9446 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 180/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 28.1602 - binary_accuracy: 0.6000 - false_negatives_2: 225.0000 - val_loss: 32.9520 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 181/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 30.4667 - binary_accuracy: 0.6333 - false_negatives_2: 224.0000 - val_loss: 28.2691 - val_binary_accuracy: 0.3478 - val_false_negatives_2: 1.0000\n",
            "Epoch 182/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 27.0576 - binary_accuracy: 0.6420 - false_negatives_2: 234.0000 - val_loss: 25.4518 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 183/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 24.6249 - binary_accuracy: 0.6435 - false_negatives_2: 245.0000 - val_loss: 23.4777 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 184/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 26.2228 - binary_accuracy: 0.6319 - false_negatives_2: 239.0000 - val_loss: 28.5497 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 185/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 28.5193 - binary_accuracy: 0.6319 - false_negatives_2: 223.0000 - val_loss: 28.0991 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 28.1605 - binary_accuracy: 0.5928 - false_negatives_2: 211.0000 - val_loss: 27.3655 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 187/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 32.1335 - binary_accuracy: 0.6449 - false_negatives_2: 230.0000 - val_loss: 31.3288 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 188/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 29.4418 - binary_accuracy: 0.6507 - false_negatives_2: 222.0000 - val_loss: 26.7976 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 26.0046 - binary_accuracy: 0.5348 - false_negatives_2: 170.0000 - val_loss: 25.4974 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 190/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 25.7454 - binary_accuracy: 0.6203 - false_negatives_2: 211.0000 - val_loss: 24.8408 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.5808 - binary_accuracy: 0.6188 - false_negatives_2: 236.0000 - val_loss: 26.1566 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 192/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 24.5598 - binary_accuracy: 0.6420 - false_negatives_2: 245.0000 - val_loss: 22.8690 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 193/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.3241 - binary_accuracy: 0.6232 - false_negatives_2: 221.0000 - val_loss: 21.5684 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 194/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.6684 - binary_accuracy: 0.6232 - false_negatives_2: 214.0000 - val_loss: 21.7449 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 195/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 21.2324 - binary_accuracy: 0.6333 - false_negatives_2: 238.0000 - val_loss: 21.5584 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 196/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.1800 - binary_accuracy: 0.6304 - false_negatives_2: 237.0000 - val_loss: 20.9385 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 197/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.0726 - binary_accuracy: 0.6406 - false_negatives_2: 244.0000 - val_loss: 20.3035 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 198/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 20.1362 - binary_accuracy: 0.6261 - false_negatives_2: 232.0000 - val_loss: 19.6508 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 199/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.8838 - binary_accuracy: 0.6261 - false_negatives_2: 221.0000 - val_loss: 19.9370 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 200/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.2466 - binary_accuracy: 0.6261 - false_negatives_2: 209.0000 - val_loss: 24.7868 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.6606 - binary_accuracy: 0.6391 - false_negatives_2: 224.0000 - val_loss: 20.1295 - val_binary_accuracy: 0.4304 - val_false_negatives_2: 11.0000\n",
            "Epoch 202/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 19.6946 - binary_accuracy: 0.6348 - false_negatives_2: 237.0000 - val_loss: 19.0471 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 203/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.2188 - binary_accuracy: 0.6435 - false_negatives_2: 219.0000 - val_loss: 19.1950 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 204/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 21.1381 - binary_accuracy: 0.6449 - false_negatives_2: 223.0000 - val_loss: 23.7832 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 205/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 21.6411 - binary_accuracy: 0.6319 - false_negatives_2: 238.0000 - val_loss: 22.6550 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.6776 - binary_accuracy: 0.6174 - false_negatives_2: 222.0000 - val_loss: 24.5995 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 23.0122 - binary_accuracy: 0.6217 - false_negatives_2: 198.0000 - val_loss: 26.4821 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 208/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 26.1073 - binary_accuracy: 0.6072 - false_negatives_2: 230.0000 - val_loss: 28.1272 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 209/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 29.5947 - binary_accuracy: 0.6275 - false_negatives_2: 229.0000 - val_loss: 32.8400 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 210/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 30.7549 - binary_accuracy: 0.6246 - false_negatives_2: 203.0000 - val_loss: 31.3749 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 27.3229 - binary_accuracy: 0.6290 - false_negatives_2: 219.0000 - val_loss: 24.8070 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 212/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.6310 - binary_accuracy: 0.6290 - false_negatives_2: 197.0000 - val_loss: 23.0082 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 213/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 22.4731 - binary_accuracy: 0.6464 - false_negatives_2: 232.0000 - val_loss: 26.6619 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 23.3959 - binary_accuracy: 0.6435 - false_negatives_2: 209.0000 - val_loss: 21.4437 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 215/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 22.1247 - binary_accuracy: 0.6319 - false_negatives_2: 220.0000 - val_loss: 21.5207 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.6411 - binary_accuracy: 0.6290 - false_negatives_2: 236.0000 - val_loss: 21.1969 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 217/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 21.4350 - binary_accuracy: 0.6362 - false_negatives_2: 243.0000 - val_loss: 21.2434 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 218/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 21.4846 - binary_accuracy: 0.6246 - false_negatives_2: 237.0000 - val_loss: 23.3466 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 219/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 21.4435 - binary_accuracy: 0.6072 - false_negatives_2: 213.0000 - val_loss: 21.9077 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 220/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 19.7413 - binary_accuracy: 0.6449 - false_negatives_2: 233.0000 - val_loss: 25.3387 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 19.8764 - binary_accuracy: 0.6261 - false_negatives_2: 202.0000 - val_loss: 19.8467 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 222/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 20.6627 - binary_accuracy: 0.6290 - false_negatives_2: 207.0000 - val_loss: 18.9157 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 223/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 18.5072 - binary_accuracy: 0.5942 - false_negatives_2: 218.0000 - val_loss: 18.1820 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 224/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 20.5466 - binary_accuracy: 0.6188 - false_negatives_2: 209.0000 - val_loss: 24.7030 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 225/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 26.1232 - binary_accuracy: 0.5855 - false_negatives_2: 206.0000 - val_loss: 27.4161 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 26.1861 - binary_accuracy: 0.5841 - false_negatives_2: 205.0000 - val_loss: 26.0421 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 26.5941 - binary_accuracy: 0.6188 - false_negatives_2: 238.0000 - val_loss: 23.8637 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 228/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.0887 - binary_accuracy: 0.6290 - false_negatives_2: 237.0000 - val_loss: 19.2297 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 229/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.1291 - binary_accuracy: 0.5986 - false_negatives_2: 192.0000 - val_loss: 22.4386 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.2292 - binary_accuracy: 0.6246 - false_negatives_2: 222.0000 - val_loss: 23.4994 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 231/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 22.6471 - binary_accuracy: 0.6391 - false_negatives_2: 220.0000 - val_loss: 21.1757 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 232/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 20.5883 - binary_accuracy: 0.6203 - false_negatives_2: 227.0000 - val_loss: 19.2149 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 233/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.9897 - binary_accuracy: 0.6304 - false_negatives_2: 233.0000 - val_loss: 18.9226 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 234/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.3009 - binary_accuracy: 0.6246 - false_negatives_2: 211.0000 - val_loss: 23.5950 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 235/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 22.9165 - binary_accuracy: 0.6275 - false_negatives_2: 235.0000 - val_loss: 22.1672 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 236/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 21.2772 - binary_accuracy: 0.6203 - false_negatives_2: 223.0000 - val_loss: 20.1232 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 237/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.6129 - binary_accuracy: 0.6406 - false_negatives_2: 240.0000 - val_loss: 24.4587 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 238/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.5364 - binary_accuracy: 0.6319 - false_negatives_2: 245.0000 - val_loss: 22.8656 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 239/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 78.4602 - binary_accuracy: 0.6435 - false_negatives_2: 240.0000 - val_loss: 52.3255 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 240/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 37.9227 - binary_accuracy: 0.6246 - false_negatives_2: 219.0000 - val_loss: 30.4208 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 241/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 27.5852 - binary_accuracy: 0.5826 - false_negatives_2: 202.0000 - val_loss: 24.9111 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.6260 - binary_accuracy: 0.6014 - false_negatives_2: 201.0000 - val_loss: 26.4250 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 243/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 26.4425 - binary_accuracy: 0.5855 - false_negatives_2: 208.0000 - val_loss: 25.5107 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 244/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 24.3101 - binary_accuracy: 0.6261 - false_negatives_2: 211.0000 - val_loss: 23.2555 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 245/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.7962 - binary_accuracy: 0.6058 - false_negatives_2: 213.0000 - val_loss: 23.5460 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 246/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 27.9329 - binary_accuracy: 0.6377 - false_negatives_2: 202.0000 - val_loss: 29.8565 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 247/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 27.5402 - binary_accuracy: 0.5957 - false_negatives_2: 203.0000 - val_loss: 36.0468 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 248/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 39.7914 - binary_accuracy: 0.6043 - false_negatives_2: 224.0000 - val_loss: 37.0936 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 249/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 35.6931 - binary_accuracy: 0.5957 - false_negatives_2: 202.0000 - val_loss: 31.6857 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 250/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 34.8975 - binary_accuracy: 0.5783 - false_negatives_2: 194.0000 - val_loss: 28.1682 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 24.9395 - binary_accuracy: 0.6058 - false_negatives_2: 190.0000 - val_loss: 945.9358 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 26.9685 - binary_accuracy: 0.5826 - false_negatives_2: 199.0000 - val_loss: 36.7608 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 253/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 32.6102 - binary_accuracy: 0.5870 - false_negatives_2: 200.0000 - val_loss: 28.1951 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 25.7977 - binary_accuracy: 0.5957 - false_negatives_2: 215.0000 - val_loss: 24.2433 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 255/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.2295 - binary_accuracy: 0.5957 - false_negatives_2: 223.0000 - val_loss: 26.3537 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 256/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 22.4865 - binary_accuracy: 0.6145 - false_negatives_2: 208.0000 - val_loss: 26.8019 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 23.7351 - binary_accuracy: 0.5913 - false_negatives_2: 187.0000 - val_loss: 22.9639 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 258/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 24.5624 - binary_accuracy: 0.5768 - false_negatives_2: 196.0000 - val_loss: 30.3112 - val_binary_accuracy: 0.6522 - val_false_negatives_2: 77.0000\n",
            "Epoch 259/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 24.9660 - binary_accuracy: 0.6174 - false_negatives_2: 198.0000 - val_loss: 20.6087 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 260/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 19.9816 - binary_accuracy: 0.6072 - false_negatives_2: 200.0000 - val_loss: 20.7476 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 261/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 21.3382 - binary_accuracy: 0.5826 - false_negatives_2: 191.0000 - val_loss: 21.1971 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 25.6276 - binary_accuracy: 0.6058 - false_negatives_2: 216.0000 - val_loss: 27.2720 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 263/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 25.3242 - binary_accuracy: 0.5739 - false_negatives_2: 207.0000 - val_loss: 29.1245 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 24.1894 - binary_accuracy: 0.6174 - false_negatives_2: 214.0000 - val_loss: 23.1737 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 265/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 23.8294 - binary_accuracy: 0.6116 - false_negatives_2: 209.0000 - val_loss: 26.1544 - val_binary_accuracy: 0.4174 - val_false_negatives_2: 39.0000\n",
            "Epoch 266/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 24.3634 - binary_accuracy: 0.6145 - false_negatives_2: 228.0000 - val_loss: 24.9690 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 22.6428 - binary_accuracy: 0.6246 - false_negatives_2: 220.0000 - val_loss: 23.5025 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 268/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.8943 - binary_accuracy: 0.6261 - false_negatives_2: 202.0000 - val_loss: 24.0306 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 269/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.9524 - binary_accuracy: 0.6072 - false_negatives_2: 188.0000 - val_loss: 25.0405 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 270/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 27.0678 - binary_accuracy: 0.6116 - false_negatives_2: 218.0000 - val_loss: 27.0597 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 271/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 26.3081 - binary_accuracy: 0.6217 - false_negatives_2: 217.0000 - val_loss: 24.7720 - val_binary_accuracy: 0.3783 - val_false_negatives_2: 3.0000\n",
            "Epoch 272/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.8929 - binary_accuracy: 0.6536 - false_negatives_2: 233.0000 - val_loss: 22.8187 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 23.0296 - binary_accuracy: 0.6377 - false_negatives_2: 238.0000 - val_loss: 23.1367 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 274/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 29.3563 - binary_accuracy: 0.6449 - false_negatives_2: 223.0000 - val_loss: 27.9667 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 275/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 24.6110 - binary_accuracy: 0.6145 - false_negatives_2: 174.0000 - val_loss: 23.4999 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 24.1859 - binary_accuracy: 0.5783 - false_negatives_2: 196.0000 - val_loss: 25.8490 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 277/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 25.7055 - binary_accuracy: 0.5928 - false_negatives_2: 194.0000 - val_loss: 26.4802 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 278/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 23.3943 - binary_accuracy: 0.6464 - false_negatives_2: 226.0000 - val_loss: 21.2091 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 279/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 20.1683 - binary_accuracy: 0.6391 - false_negatives_2: 238.0000 - val_loss: 19.8621 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 280/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.3692 - binary_accuracy: 0.6130 - false_negatives_2: 233.0000 - val_loss: 18.3417 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 281/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.0964 - binary_accuracy: 0.6145 - false_negatives_2: 225.0000 - val_loss: 33.2420 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 282/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.7031 - binary_accuracy: 0.6217 - false_negatives_2: 234.0000 - val_loss: 18.6876 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.0949 - binary_accuracy: 0.6029 - false_negatives_2: 215.0000 - val_loss: 22.4601 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.4214 - binary_accuracy: 0.6000 - false_negatives_2: 225.0000 - val_loss: 19.5191 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 285/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.2071 - binary_accuracy: 0.6261 - false_negatives_2: 225.0000 - val_loss: 19.4658 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 286/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.6520 - binary_accuracy: 0.5870 - false_negatives_2: 221.0000 - val_loss: 21.5242 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 287/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.6087 - binary_accuracy: 0.6174 - false_negatives_2: 218.0000 - val_loss: 25.8242 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.2930 - binary_accuracy: 0.6290 - false_negatives_2: 234.0000 - val_loss: 19.6976 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 289/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.6610 - binary_accuracy: 0.6232 - false_negatives_2: 237.0000 - val_loss: 18.2829 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 290/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 17.3085 - binary_accuracy: 0.5971 - false_negatives_2: 209.0000 - val_loss: 17.0125 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 17.9063 - binary_accuracy: 0.6464 - false_negatives_2: 226.0000 - val_loss: 17.7564 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 292/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 17.6532 - binary_accuracy: 0.6145 - false_negatives_2: 205.0000 - val_loss: 17.2955 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 293/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 15.8890 - binary_accuracy: 0.6130 - false_negatives_2: 216.0000 - val_loss: 15.4558 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 16.6949 - binary_accuracy: 0.6232 - false_negatives_2: 228.0000 - val_loss: 17.2933 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 295/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 19.2479 - binary_accuracy: 0.6275 - false_negatives_2: 230.0000 - val_loss: 19.6672 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 296/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 19.1709 - binary_accuracy: 0.6159 - false_negatives_2: 218.0000 - val_loss: 20.9197 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 297/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 19.0905 - binary_accuracy: 0.6406 - false_negatives_2: 226.0000 - val_loss: 15.8260 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 298/1000\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 16.3064 - binary_accuracy: 0.6203 - false_negatives_2: 216.0000 - val_loss: 16.0730 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 299/1000\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 16.2532 - binary_accuracy: 0.6333 - false_negatives_2: 225.0000 - val_loss: 16.3364 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 16.0164 - binary_accuracy: 0.6116 - false_negatives_2: 222.0000 - val_loss: 17.8057 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 301/1000\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 15.7616 - binary_accuracy: 0.6000 - false_negatives_2: 207.0000 - val_loss: 16.0530 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 302/1000\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 15.2595 - binary_accuracy: 0.6377 - false_negatives_2: 233.0000 - val_loss: 17.0785 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 21.2176 - binary_accuracy: 0.6246 - false_negatives_2: 207.0000 - val_loss: 26.4610 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 304/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 25.6662 - binary_accuracy: 0.6145 - false_negatives_2: 232.0000 - val_loss: 24.8741 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 24.5773 - binary_accuracy: 0.6145 - false_negatives_2: 213.0000 - val_loss: 23.7620 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 306/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 22.2129 - binary_accuracy: 0.6000 - false_negatives_2: 195.0000 - val_loss: 20.9935 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 307/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 20.9094 - binary_accuracy: 0.6000 - false_negatives_2: 201.0000 - val_loss: 21.3122 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.4236 - binary_accuracy: 0.6362 - false_negatives_2: 237.0000 - val_loss: 20.6483 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.7411 - binary_accuracy: 0.6246 - false_negatives_2: 231.0000 - val_loss: 19.3061 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.9308 - binary_accuracy: 0.6232 - false_negatives_2: 234.0000 - val_loss: 19.9172 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 311/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 20.3677 - binary_accuracy: 0.6304 - false_negatives_2: 207.0000 - val_loss: 19.7373 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.1343 - binary_accuracy: 0.6261 - false_negatives_2: 215.0000 - val_loss: 18.6278 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 313/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.7266 - binary_accuracy: 0.6116 - false_negatives_2: 196.0000 - val_loss: 23.8291 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 20.3507 - binary_accuracy: 0.5971 - false_negatives_2: 200.0000 - val_loss: 19.8339 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 315/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 23.1242 - binary_accuracy: 0.5942 - false_negatives_2: 208.0000 - val_loss: 24.5038 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 316/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 22.4795 - binary_accuracy: 0.5928 - false_negatives_2: 188.0000 - val_loss: 19.9637 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 317/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 24.2855 - binary_accuracy: 0.6130 - false_negatives_2: 219.0000 - val_loss: 25.9625 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 318/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.8942 - binary_accuracy: 0.6116 - false_negatives_2: 225.0000 - val_loss: 19.6249 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 319/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 18.1671 - binary_accuracy: 0.6377 - false_negatives_2: 210.0000 - val_loss: 20.0482 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 320/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.7849 - binary_accuracy: 0.5942 - false_negatives_2: 225.0000 - val_loss: 17.8946 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.3634 - binary_accuracy: 0.6087 - false_negatives_2: 217.0000 - val_loss: 17.2162 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 322/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 16.8435 - binary_accuracy: 0.6333 - false_negatives_2: 236.0000 - val_loss: 22.2658 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 17.5305 - binary_accuracy: 0.6275 - false_negatives_2: 215.0000 - val_loss: 18.8359 - val_binary_accuracy: 0.4565 - val_false_negatives_2: 12.0000\n",
            "Epoch 324/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 20.2381 - binary_accuracy: 0.6319 - false_negatives_2: 215.0000 - val_loss: 17.9129 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 325/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 17.0520 - binary_accuracy: 0.6188 - false_negatives_2: 235.0000 - val_loss: 18.4392 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.4895 - binary_accuracy: 0.6014 - false_negatives_2: 196.0000 - val_loss: 20.9189 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 327/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 25.2224 - binary_accuracy: 0.6391 - false_negatives_2: 238.0000 - val_loss: 22.2603 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 328/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.3694 - binary_accuracy: 0.6246 - false_negatives_2: 240.0000 - val_loss: 19.0912 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.9454 - binary_accuracy: 0.6232 - false_negatives_2: 234.0000 - val_loss: 17.1798 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 330/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 17.3309 - binary_accuracy: 0.6246 - false_negatives_2: 224.0000 - val_loss: 16.5518 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 331/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 21.8919 - binary_accuracy: 0.6130 - false_negatives_2: 228.0000 - val_loss: 19.7396 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 332/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.1208 - binary_accuracy: 0.6261 - false_negatives_2: 234.0000 - val_loss: 22.6819 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 333/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 22.0094 - binary_accuracy: 0.6014 - false_negatives_2: 217.0000 - val_loss: 20.8759 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 334/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.5066 - binary_accuracy: 0.6275 - false_negatives_2: 235.0000 - val_loss: 17.1029 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 335/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 16.9182 - binary_accuracy: 0.6145 - false_negatives_2: 222.0000 - val_loss: 15.7447 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 336/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 16.1783 - binary_accuracy: 0.6464 - false_negatives_2: 230.0000 - val_loss: 17.3925 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 337/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 16.6162 - binary_accuracy: 0.6261 - false_negatives_2: 227.0000 - val_loss: 16.2708 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 338/1000\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 15.0743 - binary_accuracy: 0.6319 - false_negatives_2: 218.0000 - val_loss: 16.3545 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 339/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 15.5398 - binary_accuracy: 0.6377 - false_negatives_2: 228.0000 - val_loss: 15.0895 - val_binary_accuracy: 0.3522 - val_false_negatives_2: 2.0000\n",
            "Epoch 340/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 17.7618 - binary_accuracy: 0.6130 - false_negatives_2: 213.0000 - val_loss: 20.2341 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 17.5223 - binary_accuracy: 0.6290 - false_negatives_2: 235.0000 - val_loss: 16.5084 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 342/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 18.3235 - binary_accuracy: 0.6304 - false_negatives_2: 207.0000 - val_loss: 19.2228 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 343/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 17.4765 - binary_accuracy: 0.6290 - false_negatives_2: 225.0000 - val_loss: 16.9839 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 14.9130 - binary_accuracy: 0.6435 - false_negatives_2: 242.0000 - val_loss: 13.4027 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 345/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.3891 - binary_accuracy: 0.6435 - false_negatives_2: 237.0000 - val_loss: 17.8519 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 346/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.3891 - binary_accuracy: 0.6290 - false_negatives_2: 222.0000 - val_loss: 17.1187 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 347/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.4511 - binary_accuracy: 0.6449 - false_negatives_2: 244.0000 - val_loss: 15.9705 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 348/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 16.0092 - binary_accuracy: 0.6478 - false_negatives_2: 240.0000 - val_loss: 14.3016 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 349/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.3215 - binary_accuracy: 0.6362 - false_negatives_2: 237.0000 - val_loss: 12.8417 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 12.5232 - binary_accuracy: 0.6377 - false_negatives_2: 243.0000 - val_loss: 12.9283 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.8516 - binary_accuracy: 0.6406 - false_negatives_2: 245.0000 - val_loss: 17.6767 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 352/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.1052 - binary_accuracy: 0.6420 - false_negatives_2: 244.0000 - val_loss: 13.6174 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 353/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.9573 - binary_accuracy: 0.6435 - false_negatives_2: 237.0000 - val_loss: 13.6811 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.1056 - binary_accuracy: 0.6217 - false_negatives_2: 207.0000 - val_loss: 15.5947 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 355/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 14.1771 - binary_accuracy: 0.6362 - false_negatives_2: 236.0000 - val_loss: 13.1822 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 356/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.9993 - binary_accuracy: 0.5971 - false_negatives_2: 219.0000 - val_loss: 15.3438 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.1026 - binary_accuracy: 0.6232 - false_negatives_2: 236.0000 - val_loss: 12.5626 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 358/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 11.6421 - binary_accuracy: 0.6449 - false_negatives_2: 231.0000 - val_loss: 10.7845 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 359/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 10.7535 - binary_accuracy: 0.6275 - false_negatives_2: 229.0000 - val_loss: 11.4780 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 360/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.4471 - binary_accuracy: 0.6145 - false_negatives_2: 230.0000 - val_loss: 12.1745 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 361/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 10.9864 - binary_accuracy: 0.6188 - false_negatives_2: 234.0000 - val_loss: 10.8043 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 362/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.0809 - binary_accuracy: 0.6420 - false_negatives_2: 243.0000 - val_loss: 10.3312 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 363/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 10.3221 - binary_accuracy: 0.6156 - false_negatives_2: 208.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 163ms/step - loss: 10.2666 - binary_accuracy: 0.6174 - false_negatives_2: 226.0000 - val_loss: 9.4303 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 364/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 15.2515 - binary_accuracy: 0.6420 - false_negatives_2: 245.0000 - val_loss: 11.4834 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 11.0351 - binary_accuracy: 0.6449 - false_negatives_2: 226.0000 - val_loss: 10.4439 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 366/1000\n",
            "22/22 [==============================] - 1s 39ms/step - loss: 9.8278 - binary_accuracy: 0.6203 - false_negatives_2: 221.0000 - val_loss: 14.9681 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 11.2355 - binary_accuracy: 0.6449 - false_negatives_2: 244.0000 - val_loss: 10.6985 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 368/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 10.1158 - binary_accuracy: 0.6464 - false_negatives_2: 244.0000 - val_loss: 11.3063 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 369/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 11.1432 - binary_accuracy: 0.6377 - false_negatives_2: 236.0000 - val_loss: 9.7625 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 370/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 9.8337 - binary_accuracy: 0.6449 - false_negatives_2: 243.0000 - val_loss: 9.9104 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 371/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 10.7736 - binary_accuracy: 0.6246 - false_negatives_2: 223.0000 - val_loss: 11.9226 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 372/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.3702 - binary_accuracy: 0.6377 - false_negatives_2: 227.0000 - val_loss: 14.0472 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 373/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 13.0973 - binary_accuracy: 0.6362 - false_negatives_2: 241.0000 - val_loss: 11.5732 - val_binary_accuracy: 0.6000 - val_false_negatives_2: 73.0000\n",
            "Epoch 374/1000\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 10.4088 - binary_accuracy: 0.6389 - false_negatives_2: 199.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 133ms/step - loss: 10.2522 - binary_accuracy: 0.6377 - false_negatives_2: 236.0000 - val_loss: 9.3648 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 375/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.8096 - binary_accuracy: 0.6333 - false_negatives_2: 237.0000 - val_loss: 10.2464 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 376/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 9.2748 - binary_accuracy: 0.6375 - false_negatives_2: 230.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 148ms/step - loss: 9.2092 - binary_accuracy: 0.6449 - false_negatives_2: 243.0000 - val_loss: 8.4542 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 377/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 16.4650 - binary_accuracy: 0.6145 - false_negatives_2: 222.0000 - val_loss: 17.1278 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 378/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 13.4820 - binary_accuracy: 0.6275 - false_negatives_2: 236.0000 - val_loss: 10.5808 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 379/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 10.0730 - binary_accuracy: 0.6217 - false_negatives_2: 241.0000 - val_loss: 9.4900 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 380/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.9109 - binary_accuracy: 0.6130 - false_negatives_2: 196.0000 - val_loss: 12.8224 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 381/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 12.7616 - binary_accuracy: 0.6101 - false_negatives_2: 185.0000 - val_loss: 9.9003 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 382/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 10.8628 - binary_accuracy: 0.6000 - false_negatives_2: 213.0000 - val_loss: 9.6925 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 383/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.2466 - binary_accuracy: 0.6188 - false_negatives_2: 224.0000 - val_loss: 8.8520 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 384/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.8190 - binary_accuracy: 0.6130 - false_negatives_2: 207.0000 - val_loss: 9.0043 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 385/1000\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 7.6615 - binary_accuracy: 0.6234 - false_negatives_2: 202.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 184ms/step - loss: 7.6033 - binary_accuracy: 0.6290 - false_negatives_2: 229.0000 - val_loss: 7.3167 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 386/1000\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 7.1209 - binary_accuracy: 0.6297 - false_negatives_2: 205.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 177ms/step - loss: 7.1285 - binary_accuracy: 0.6290 - false_negatives_2: 224.0000 - val_loss: 7.1145 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 7.3647 - binary_accuracy: 0.6101 - false_negatives_2: 224.0000 - val_loss: 7.3632 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 388/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 6.9287 - binary_accuracy: 0.6265 - false_negatives_2: 231.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 148ms/step - loss: 6.9205 - binary_accuracy: 0.6304 - false_negatives_2: 235.0000 - val_loss: 6.6109 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 389/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 6.6944 - binary_accuracy: 0.6348 - false_negatives_2: 227.0000 - val_loss: 15.0063 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 11.2893 - binary_accuracy: 0.6333 - false_negatives_2: 237.0000 - val_loss: 8.6822 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 391/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 8.2015 - binary_accuracy: 0.6275 - false_negatives_2: 216.0000 - val_loss: 9.1853 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 392/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 10.0983 - binary_accuracy: 0.6058 - false_negatives_2: 206.0000 - val_loss: 18.6267 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 393/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 11.7240 - binary_accuracy: 0.6261 - false_negatives_2: 226.0000 - val_loss: 9.1595 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 394/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.7614 - binary_accuracy: 0.6377 - false_negatives_2: 233.0000 - val_loss: 8.3574 - val_binary_accuracy: 0.3522 - val_false_negatives_2: 2.0000\n",
            "Epoch 395/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.0101 - binary_accuracy: 0.6000 - false_negatives_2: 222.0000 - val_loss: 8.8621 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.0033 - binary_accuracy: 0.5797 - false_negatives_2: 190.0000 - val_loss: 9.5247 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 397/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 8.1508 - binary_accuracy: 0.6174 - false_negatives_2: 194.0000 - val_loss: 6.9678 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 398/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 9.1985 - binary_accuracy: 0.6362 - false_negatives_2: 239.0000 - val_loss: 7.9467 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 399/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 7.6971 - binary_accuracy: 0.6449 - false_negatives_2: 237.0000 - val_loss: 12.1618 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 8.4895 - binary_accuracy: 0.6304 - false_negatives_2: 241.0000 - val_loss: 7.6651 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 401/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 6.7398 - binary_accuracy: 0.6449 - false_negatives_2: 239.0000 - val_loss: 6.7652 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 402/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 10.0684 - binary_accuracy: 0.6348 - false_negatives_2: 234.0000 - val_loss: 16.5500 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 403/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 16.1681 - binary_accuracy: 0.6159 - false_negatives_2: 219.0000 - val_loss: 16.8327 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 404/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 15.7407 - binary_accuracy: 0.6188 - false_negatives_2: 231.0000 - val_loss: 12.8012 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 405/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 11.1584 - binary_accuracy: 0.6304 - false_negatives_2: 232.0000 - val_loss: 11.1671 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 406/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 11.1504 - binary_accuracy: 0.6348 - false_negatives_2: 219.0000 - val_loss: 15.5114 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 407/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.2711 - binary_accuracy: 0.6058 - false_negatives_2: 190.0000 - val_loss: 10.9904 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 408/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 12.6087 - binary_accuracy: 0.6043 - false_negatives_2: 223.0000 - val_loss: 11.1978 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.1563 - binary_accuracy: 0.6188 - false_negatives_2: 202.0000 - val_loss: 15.3184 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 410/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 13.1555 - binary_accuracy: 0.6333 - false_negatives_2: 239.0000 - val_loss: 16.9329 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 10.4783 - binary_accuracy: 0.6188 - false_negatives_2: 237.0000 - val_loss: 11.5458 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 13.9788 - binary_accuracy: 0.6058 - false_negatives_2: 234.0000 - val_loss: 12.5789 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 413/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 13.3560 - binary_accuracy: 0.5942 - false_negatives_2: 231.0000 - val_loss: 14.8794 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 414/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.4461 - binary_accuracy: 0.6159 - false_negatives_2: 233.0000 - val_loss: 13.8228 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 415/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.6222 - binary_accuracy: 0.6449 - false_negatives_2: 242.0000 - val_loss: 12.8631 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 416/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.6482 - binary_accuracy: 0.6290 - false_negatives_2: 232.0000 - val_loss: 10.5683 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 417/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 11.1993 - binary_accuracy: 0.6333 - false_negatives_2: 229.0000 - val_loss: 12.1404 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 418/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 10.4787 - binary_accuracy: 0.6406 - false_negatives_2: 241.0000 - val_loss: 10.3427 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.9910 - binary_accuracy: 0.6449 - false_negatives_2: 238.0000 - val_loss: 8.4189 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 420/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 9.2588 - binary_accuracy: 0.6290 - false_negatives_2: 233.0000 - val_loss: 10.9005 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 421/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8.6963 - binary_accuracy: 0.6391 - false_negatives_2: 231.0000 - val_loss: 7.5106 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 422/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8.3798 - binary_accuracy: 0.6290 - false_negatives_2: 237.0000 - val_loss: 9.1146 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 423/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.4839 - binary_accuracy: 0.6435 - false_negatives_2: 245.0000 - val_loss: 12.2438 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 424/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.8447 - binary_accuracy: 0.6406 - false_negatives_2: 244.0000 - val_loss: 12.7917 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 425/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.5412 - binary_accuracy: 0.6130 - false_negatives_2: 217.0000 - val_loss: 14.4249 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 426/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.9020 - binary_accuracy: 0.6333 - false_negatives_2: 236.0000 - val_loss: 13.5686 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 427/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.0073 - binary_accuracy: 0.6435 - false_negatives_2: 239.0000 - val_loss: 10.9654 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 428/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 11.2491 - binary_accuracy: 0.6449 - false_negatives_2: 233.0000 - val_loss: 11.8409 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 10.2323 - binary_accuracy: 0.6362 - false_negatives_2: 240.0000 - val_loss: 9.2527 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 430/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.3173 - binary_accuracy: 0.6348 - false_negatives_2: 229.0000 - val_loss: 11.2388 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.0478 - binary_accuracy: 0.6406 - false_negatives_2: 223.0000 - val_loss: 15.5736 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 432/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 12.4615 - binary_accuracy: 0.6217 - false_negatives_2: 240.0000 - val_loss: 10.2075 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 433/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 10.0181 - binary_accuracy: 0.6275 - false_negatives_2: 230.0000 - val_loss: 9.9184 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 434/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.8956 - binary_accuracy: 0.6174 - false_negatives_2: 228.0000 - val_loss: 9.5713 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 435/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.4128 - binary_accuracy: 0.6203 - false_negatives_2: 197.0000 - val_loss: 8.9160 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 436/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.8373 - binary_accuracy: 0.6232 - false_negatives_2: 238.0000 - val_loss: 8.1529 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 437/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 9.0107 - binary_accuracy: 0.6406 - false_negatives_2: 237.0000 - val_loss: 11.0607 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 438/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.5260 - binary_accuracy: 0.6391 - false_negatives_2: 238.0000 - val_loss: 14.3739 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 439/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 14.5383 - binary_accuracy: 0.5971 - false_negatives_2: 226.0000 - val_loss: 12.8308 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 440/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 12.3239 - binary_accuracy: 0.6319 - false_negatives_2: 231.0000 - val_loss: 12.4113 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 15.2627 - binary_accuracy: 0.6116 - false_negatives_2: 222.0000 - val_loss: 19.2202 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 442/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 20.5201 - binary_accuracy: 0.6406 - false_negatives_2: 230.0000 - val_loss: 19.6454 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 19.0044 - binary_accuracy: 0.6261 - false_negatives_2: 228.0000 - val_loss: 18.9534 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 16.5670 - binary_accuracy: 0.5942 - false_negatives_2: 227.0000 - val_loss: 14.8918 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 15.9777 - binary_accuracy: 0.6319 - false_negatives_2: 231.0000 - val_loss: 16.3528 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 17.0318 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 16.6559 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 447/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 14.5331 - binary_accuracy: 0.6420 - false_negatives_2: 244.0000 - val_loss: 12.7029 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 11.9493 - binary_accuracy: 0.6406 - false_negatives_2: 244.0000 - val_loss: 10.7832 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 449/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 10.6528 - binary_accuracy: 0.6348 - false_negatives_2: 242.0000 - val_loss: 11.0902 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 450/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 10.8474 - binary_accuracy: 0.6362 - false_negatives_2: 231.0000 - val_loss: 11.4153 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 11.3290 - binary_accuracy: 0.6362 - false_negatives_2: 242.0000 - val_loss: 14.6000 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 13.8832 - binary_accuracy: 0.6406 - false_negatives_2: 241.0000 - val_loss: 14.1219 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 453/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 12.8832 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 11.5082 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 454/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.0117 - binary_accuracy: 0.6420 - false_negatives_2: 245.0000 - val_loss: 11.2346 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 455/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.4535 - binary_accuracy: 0.6391 - false_negatives_2: 240.0000 - val_loss: 11.9656 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 78.0000\n",
            "Epoch 456/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.6284 - binary_accuracy: 0.6319 - false_negatives_2: 240.0000 - val_loss: 12.6143 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 457/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 14.3321 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 14.1877 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 458/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.7415 - binary_accuracy: 0.6348 - false_negatives_2: 228.0000 - val_loss: 14.8541 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 459/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.4707 - binary_accuracy: 0.5942 - false_negatives_2: 187.0000 - val_loss: 50.2357 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.8833 - binary_accuracy: 0.6304 - false_negatives_2: 229.0000 - val_loss: 17.7403 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 461/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 17.2337 - binary_accuracy: 0.6159 - false_negatives_2: 232.0000 - val_loss: 17.4109 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.8049 - binary_accuracy: 0.6029 - false_negatives_2: 231.0000 - val_loss: 16.6742 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 463/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.5014 - binary_accuracy: 0.6029 - false_negatives_2: 215.0000 - val_loss: 15.5738 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.3595 - binary_accuracy: 0.6188 - false_negatives_2: 234.0000 - val_loss: 14.3169 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 465/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.1228 - binary_accuracy: 0.6101 - false_negatives_2: 217.0000 - val_loss: 13.5337 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 466/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 12.4529 - binary_accuracy: 0.6377 - false_negatives_2: 219.0000 - val_loss: 12.4912 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 467/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 12.3659 - binary_accuracy: 0.5681 - false_negatives_2: 210.0000 - val_loss: 12.5547 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 468/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 11.2974 - binary_accuracy: 0.6232 - false_negatives_2: 217.0000 - val_loss: 10.5530 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 469/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 10.3810 - binary_accuracy: 0.6304 - false_negatives_2: 232.0000 - val_loss: 12.6932 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 16.8722 - binary_accuracy: 0.6159 - false_negatives_2: 209.0000 - val_loss: 17.3288 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 471/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 15.5079 - binary_accuracy: 0.6217 - false_negatives_2: 237.0000 - val_loss: 19.7630 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 472/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 19.4998 - binary_accuracy: 0.6304 - false_negatives_2: 229.0000 - val_loss: 19.3989 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 473/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.9367 - binary_accuracy: 0.6391 - false_negatives_2: 223.0000 - val_loss: 19.9707 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 20.5111 - binary_accuracy: 0.6420 - false_negatives_2: 212.0000 - val_loss: 21.9233 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 475/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 20.5582 - binary_accuracy: 0.5812 - false_negatives_2: 191.0000 - val_loss: 18.3460 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 476/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.9796 - binary_accuracy: 0.6058 - false_negatives_2: 214.0000 - val_loss: 17.6506 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 477/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.7113 - binary_accuracy: 0.6072 - false_negatives_2: 219.0000 - val_loss: 15.6505 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 478/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 14.6190 - binary_accuracy: 0.5971 - false_negatives_2: 209.0000 - val_loss: 13.9806 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 479/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 15.3094 - binary_accuracy: 0.5942 - false_negatives_2: 213.0000 - val_loss: 16.4443 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 480/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 18.4270 - binary_accuracy: 0.6391 - false_negatives_2: 220.0000 - val_loss: 20.5678 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 481/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 19.6695 - binary_accuracy: 0.6130 - false_negatives_2: 205.0000 - val_loss: 18.0099 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 482/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 16.5316 - binary_accuracy: 0.6087 - false_negatives_2: 211.0000 - val_loss: 15.7264 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 483/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 14.9576 - binary_accuracy: 0.6319 - false_negatives_2: 237.0000 - val_loss: 14.0852 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 484/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 13.7727 - binary_accuracy: 0.6391 - false_negatives_2: 225.0000 - val_loss: 13.9384 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 485/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 13.7184 - binary_accuracy: 0.6304 - false_negatives_2: 232.0000 - val_loss: 14.4087 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 486/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 14.0094 - binary_accuracy: 0.6290 - false_negatives_2: 229.0000 - val_loss: 18.8785 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 13.5529 - binary_accuracy: 0.6391 - false_negatives_2: 243.0000 - val_loss: 12.3673 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 488/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 11.7382 - binary_accuracy: 0.6130 - false_negatives_2: 191.0000 - val_loss: 11.1877 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 489/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.0273 - binary_accuracy: 0.6333 - false_negatives_2: 226.0000 - val_loss: 10.4236 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 490/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.5140 - binary_accuracy: 0.6174 - false_negatives_2: 220.0000 - val_loss: 10.9894 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 491/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 11.7604 - binary_accuracy: 0.6348 - false_negatives_2: 231.0000 - val_loss: 10.7598 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 492/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.3804 - binary_accuracy: 0.6290 - false_negatives_2: 243.0000 - val_loss: 9.8744 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 493/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 9.2209 - binary_accuracy: 0.6449 - false_negatives_2: 238.0000 - val_loss: 8.9794 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 494/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.4288 - binary_accuracy: 0.6304 - false_negatives_2: 224.0000 - val_loss: 9.6549 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 495/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.8208 - binary_accuracy: 0.6275 - false_negatives_2: 235.0000 - val_loss: 9.8265 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 496/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.9240 - binary_accuracy: 0.6261 - false_negatives_2: 230.0000 - val_loss: 10.4488 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 497/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.2912 - binary_accuracy: 0.6188 - false_negatives_2: 219.0000 - val_loss: 8.9462 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 498/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 8.9366 - binary_accuracy: 0.6304 - false_negatives_2: 241.0000 - val_loss: 9.3413 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 499/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.7247 - binary_accuracy: 0.6362 - false_negatives_2: 217.0000 - val_loss: 8.8939 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 500/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.8715 - binary_accuracy: 0.6290 - false_negatives_2: 231.0000 - val_loss: 10.0875 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 501/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.0336 - binary_accuracy: 0.6217 - false_negatives_2: 234.0000 - val_loss: 21.7717 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.8988 - binary_accuracy: 0.6145 - false_negatives_2: 216.0000 - val_loss: 15.1904 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 503/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.8965 - binary_accuracy: 0.6188 - false_negatives_2: 232.0000 - val_loss: 12.6844 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 504/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 13.8613 - binary_accuracy: 0.6377 - false_negatives_2: 223.0000 - val_loss: 13.7191 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 505/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 42.2126 - binary_accuracy: 0.6203 - false_negatives_2: 236.0000 - val_loss: 23.7683 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 17.7780 - binary_accuracy: 0.6391 - false_negatives_2: 237.0000 - val_loss: 13.5646 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 507/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 12.1179 - binary_accuracy: 0.6217 - false_negatives_2: 232.0000 - val_loss: 14.0901 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.6373 - binary_accuracy: 0.6275 - false_negatives_2: 222.0000 - val_loss: 14.0292 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 509/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.0733 - binary_accuracy: 0.6290 - false_negatives_2: 237.0000 - val_loss: 14.1630 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 510/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.9110 - binary_accuracy: 0.6174 - false_negatives_2: 202.0000 - val_loss: 19.2434 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 511/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 20.3812 - binary_accuracy: 0.6362 - false_negatives_2: 225.0000 - val_loss: 16.9447 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 512/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 17.6134 - binary_accuracy: 0.6130 - false_negatives_2: 223.0000 - val_loss: 19.4903 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 513/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.4021 - binary_accuracy: 0.6246 - false_negatives_2: 208.0000 - val_loss: 26.3996 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 514/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 24.6217 - binary_accuracy: 0.6174 - false_negatives_2: 213.0000 - val_loss: 22.7725 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 515/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.1224 - binary_accuracy: 0.6000 - false_negatives_2: 211.0000 - val_loss: 16.6746 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 516/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.7593 - binary_accuracy: 0.5855 - false_negatives_2: 202.0000 - val_loss: 16.2855 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 517/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 16.7018 - binary_accuracy: 0.6275 - false_negatives_2: 218.0000 - val_loss: 18.1777 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 518/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.5319 - binary_accuracy: 0.5942 - false_negatives_2: 206.0000 - val_loss: 19.8334 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 519/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.0602 - binary_accuracy: 0.6000 - false_negatives_2: 228.0000 - val_loss: 16.7650 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 14.5177 - binary_accuracy: 0.6174 - false_negatives_2: 223.0000 - val_loss: 15.0464 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 15.1187 - binary_accuracy: 0.6217 - false_negatives_2: 205.0000 - val_loss: 15.5336 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 21.8235 - binary_accuracy: 0.6116 - false_negatives_2: 223.0000 - val_loss: 47.9187 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 22.7410 - binary_accuracy: 0.6159 - false_negatives_2: 210.0000 - val_loss: 25.7875 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 23.5057 - binary_accuracy: 0.5971 - false_negatives_2: 210.0000 - val_loss: 23.5307 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 525/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 22.3781 - binary_accuracy: 0.6333 - false_negatives_2: 234.0000 - val_loss: 27.4991 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 21.7047 - binary_accuracy: 0.6014 - false_negatives_2: 218.0000 - val_loss: 23.7436 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 19.2311 - binary_accuracy: 0.6304 - false_negatives_2: 241.0000 - val_loss: 17.6972 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 17.7765 - binary_accuracy: 0.5681 - false_negatives_2: 174.0000 - val_loss: 18.3344 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 529/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.5721 - binary_accuracy: 0.6145 - false_negatives_2: 197.0000 - val_loss: 20.5409 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 530/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.5225 - binary_accuracy: 0.6174 - false_negatives_2: 212.0000 - val_loss: 22.1676 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 531/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.0217 - binary_accuracy: 0.5899 - false_negatives_2: 190.0000 - val_loss: 19.8821 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 532/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 20.8407 - binary_accuracy: 0.6014 - false_negatives_2: 212.0000 - val_loss: 20.6034 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 533/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.4813 - binary_accuracy: 0.6116 - false_negatives_2: 220.0000 - val_loss: 34.2683 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.3597 - binary_accuracy: 0.6072 - false_negatives_2: 217.0000 - val_loss: 17.2303 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 535/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 15.5514 - binary_accuracy: 0.6101 - false_negatives_2: 216.0000 - val_loss: 15.3096 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 536/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.5532 - binary_accuracy: 0.6319 - false_negatives_2: 237.0000 - val_loss: 16.7082 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 537/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.5841 - binary_accuracy: 0.6232 - false_negatives_2: 225.0000 - val_loss: 14.3884 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 538/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.5243 - binary_accuracy: 0.6043 - false_negatives_2: 235.0000 - val_loss: 12.9376 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 539/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.1307 - binary_accuracy: 0.6072 - false_negatives_2: 195.0000 - val_loss: 13.0426 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 540/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.8285 - binary_accuracy: 0.6014 - false_negatives_2: 220.0000 - val_loss: 12.3637 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 541/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.5573 - binary_accuracy: 0.6116 - false_negatives_2: 233.0000 - val_loss: 14.7407 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 542/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.2976 - binary_accuracy: 0.6043 - false_negatives_2: 205.0000 - val_loss: 11.8863 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 543/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 12.1098 - binary_accuracy: 0.6174 - false_negatives_2: 225.0000 - val_loss: 13.4047 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.2148 - binary_accuracy: 0.6377 - false_negatives_2: 220.0000 - val_loss: 13.4020 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 545/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.6391 - binary_accuracy: 0.6203 - false_negatives_2: 194.0000 - val_loss: 15.0697 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 546/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.7278 - binary_accuracy: 0.5986 - false_negatives_2: 227.0000 - val_loss: 18.0028 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 547/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.9686 - binary_accuracy: 0.6333 - false_negatives_2: 229.0000 - val_loss: 18.2251 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 548/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.9510 - binary_accuracy: 0.6130 - false_negatives_2: 222.0000 - val_loss: 16.3853 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 16.9042 - binary_accuracy: 0.6435 - false_negatives_2: 243.0000 - val_loss: 17.2902 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 550/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.6643 - binary_accuracy: 0.5957 - false_negatives_2: 209.0000 - val_loss: 15.9342 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 551/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 15.5971 - binary_accuracy: 0.6348 - false_negatives_2: 239.0000 - val_loss: 15.3525 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 552/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 15.1567 - binary_accuracy: 0.6275 - false_negatives_2: 208.0000 - val_loss: 14.0175 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 553/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 14.7925 - binary_accuracy: 0.5928 - false_negatives_2: 192.0000 - val_loss: 18.2600 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 554/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.7740 - binary_accuracy: 0.6333 - false_negatives_2: 236.0000 - val_loss: 16.1474 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.1818 - binary_accuracy: 0.6464 - false_negatives_2: 242.0000 - val_loss: 27.5190 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 22.7372 - binary_accuracy: 0.6174 - false_negatives_2: 232.0000 - val_loss: 29.2947 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 557/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.6816 - binary_accuracy: 0.6348 - false_negatives_2: 239.0000 - val_loss: 19.6449 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 558/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.5334 - binary_accuracy: 0.6362 - false_negatives_2: 233.0000 - val_loss: 16.9743 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 16.9508 - binary_accuracy: 0.5884 - false_negatives_2: 219.0000 - val_loss: 17.3836 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 18.0300 - binary_accuracy: 0.6435 - false_negatives_2: 224.0000 - val_loss: 17.1206 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 561/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 16.7796 - binary_accuracy: 0.6116 - false_negatives_2: 218.0000 - val_loss: 16.9259 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 562/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 18.9821 - binary_accuracy: 0.6217 - false_negatives_2: 223.0000 - val_loss: 18.4090 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 563/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 21.2478 - binary_accuracy: 0.6232 - false_negatives_2: 229.0000 - val_loss: 24.2071 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 564/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 22.5267 - binary_accuracy: 0.6232 - false_negatives_2: 220.0000 - val_loss: 21.4243 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 565/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 24.2950 - binary_accuracy: 0.6348 - false_negatives_2: 209.0000 - val_loss: 23.5748 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 566/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 22.1964 - binary_accuracy: 0.6362 - false_negatives_2: 219.0000 - val_loss: 20.8195 - val_binary_accuracy: 0.3478 - val_false_negatives_2: 2.0000\n",
            "Epoch 567/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 22.2292 - binary_accuracy: 0.6232 - false_negatives_2: 227.0000 - val_loss: 22.0923 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 568/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 20.5980 - binary_accuracy: 0.5928 - false_negatives_2: 208.0000 - val_loss: 19.9517 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 569/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.9844 - binary_accuracy: 0.6043 - false_negatives_2: 194.0000 - val_loss: 18.9719 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 570/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.7889 - binary_accuracy: 0.5928 - false_negatives_2: 175.0000 - val_loss: 16.7503 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 571/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 16.8097 - binary_accuracy: 0.6014 - false_negatives_2: 214.0000 - val_loss: 17.3774 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 572/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.5554 - binary_accuracy: 0.6333 - false_negatives_2: 218.0000 - val_loss: 17.9810 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 573/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.5753 - binary_accuracy: 0.6290 - false_negatives_2: 223.0000 - val_loss: 16.2989 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 574/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 15.1107 - binary_accuracy: 0.6290 - false_negatives_2: 226.0000 - val_loss: 14.6955 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 575/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.4169 - binary_accuracy: 0.6145 - false_negatives_2: 219.0000 - val_loss: 14.6024 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 576/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 17.5451 - binary_accuracy: 0.6232 - false_negatives_2: 192.0000 - val_loss: 24.1280 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 577/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.2658 - binary_accuracy: 0.6130 - false_negatives_2: 204.0000 - val_loss: 22.2529 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 578/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.0376 - binary_accuracy: 0.6217 - false_negatives_2: 233.0000 - val_loss: 19.2604 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 579/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.3815 - binary_accuracy: 0.5870 - false_negatives_2: 215.0000 - val_loss: 17.8895 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 580/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.6903 - binary_accuracy: 0.6101 - false_negatives_2: 216.0000 - val_loss: 17.0068 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 581/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 17.6004 - binary_accuracy: 0.6159 - false_negatives_2: 215.0000 - val_loss: 17.1832 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 582/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 15.6753 - binary_accuracy: 0.6275 - false_negatives_2: 235.0000 - val_loss: 15.0075 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 583/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.8757 - binary_accuracy: 0.6261 - false_negatives_2: 226.0000 - val_loss: 15.3305 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 584/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 15.2721 - binary_accuracy: 0.5826 - false_negatives_2: 214.0000 - val_loss: 13.9305 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 585/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 13.7306 - binary_accuracy: 0.6014 - false_negatives_2: 217.0000 - val_loss: 13.0430 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 586/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.3695 - binary_accuracy: 0.6275 - false_negatives_2: 223.0000 - val_loss: 14.1764 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 587/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.7301 - binary_accuracy: 0.6159 - false_negatives_2: 217.0000 - val_loss: 18.9374 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.3322 - binary_accuracy: 0.6478 - false_negatives_2: 242.0000 - val_loss: 17.5441 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 589/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.9133 - binary_accuracy: 0.6333 - false_negatives_2: 226.0000 - val_loss: 15.0052 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 590/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 15.4273 - binary_accuracy: 0.6043 - false_negatives_2: 234.0000 - val_loss: 14.1578 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 591/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.4596 - binary_accuracy: 0.6348 - false_negatives_2: 209.0000 - val_loss: 19.5321 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 19.9776 - binary_accuracy: 0.5971 - false_negatives_2: 207.0000 - val_loss: 20.1498 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 593/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 19.4786 - binary_accuracy: 0.6420 - false_negatives_2: 225.0000 - val_loss: 19.1329 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 594/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.0004 - binary_accuracy: 0.6420 - false_negatives_2: 238.0000 - val_loss: 23.9996 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 595/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 20.7708 - binary_accuracy: 0.6014 - false_negatives_2: 211.0000 - val_loss: 18.0305 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 596/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 17.7914 - binary_accuracy: 0.6551 - false_negatives_2: 224.0000 - val_loss: 17.8283 - val_binary_accuracy: 0.4043 - val_false_negatives_2: 5.0000\n",
            "Epoch 597/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.2724 - binary_accuracy: 0.6333 - false_negatives_2: 231.0000 - val_loss: 16.5984 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.0350 - binary_accuracy: 0.6449 - false_negatives_2: 231.0000 - val_loss: 17.4851 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 599/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 17.0838 - binary_accuracy: 0.6217 - false_negatives_2: 209.0000 - val_loss: 17.2005 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 15.1326 - binary_accuracy: 0.6188 - false_negatives_2: 231.0000 - val_loss: 14.5797 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 601/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 13.2168 - binary_accuracy: 0.6362 - false_negatives_2: 229.0000 - val_loss: 14.4896 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 602/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 12.9978 - binary_accuracy: 0.6333 - false_negatives_2: 237.0000 - val_loss: 12.0784 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 603/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 11.8989 - binary_accuracy: 0.6348 - false_negatives_2: 234.0000 - val_loss: 11.2274 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 604/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 13.9877 - binary_accuracy: 0.6319 - false_negatives_2: 234.0000 - val_loss: 13.6347 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 13.0032 - binary_accuracy: 0.6246 - false_negatives_2: 205.0000 - val_loss: 12.8509 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 606/1000\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 12.4594 - binary_accuracy: 0.6435 - false_negatives_2: 235.0000 - val_loss: 15.7928 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 12.2573 - binary_accuracy: 0.6420 - false_negatives_2: 213.0000 - val_loss: 14.2978 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 13.5398 - binary_accuracy: 0.6333 - false_negatives_2: 236.0000 - val_loss: 12.2321 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 609/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 11.5585 - binary_accuracy: 0.5870 - false_negatives_2: 216.0000 - val_loss: 11.0185 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 610/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 10.5139 - binary_accuracy: 0.5971 - false_negatives_2: 196.0000 - val_loss: 9.7247 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 611/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.6852 - binary_accuracy: 0.6116 - false_negatives_2: 229.0000 - val_loss: 9.9520 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 612/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 9.9242 - binary_accuracy: 0.6116 - false_negatives_2: 197.0000 - val_loss: 9.9315 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 613/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.9374 - binary_accuracy: 0.6159 - false_negatives_2: 238.0000 - val_loss: 9.7981 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.7715 - binary_accuracy: 0.6493 - false_negatives_2: 206.0000 - val_loss: 11.7135 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.2706 - binary_accuracy: 0.6319 - false_negatives_2: 233.0000 - val_loss: 10.1029 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 616/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.2224 - binary_accuracy: 0.6478 - false_negatives_2: 231.0000 - val_loss: 8.7950 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.0449 - binary_accuracy: 0.6058 - false_negatives_2: 228.0000 - val_loss: 17.8049 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 618/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 15.2973 - binary_accuracy: 0.6406 - false_negatives_2: 240.0000 - val_loss: 10.5790 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 619/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.9162 - binary_accuracy: 0.6449 - false_negatives_2: 230.0000 - val_loss: 26.2427 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.9370 - binary_accuracy: 0.6449 - false_negatives_2: 245.0000 - val_loss: 11.3554 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 621/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 11.2176 - binary_accuracy: 0.6435 - false_negatives_2: 238.0000 - val_loss: 12.7330 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 622/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.9323 - binary_accuracy: 0.6420 - false_negatives_2: 244.0000 - val_loss: 12.1408 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 623/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.0838 - binary_accuracy: 0.6478 - false_negatives_2: 239.0000 - val_loss: 10.6913 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 624/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 11.0482 - binary_accuracy: 0.6319 - false_negatives_2: 237.0000 - val_loss: 16.2805 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.9367 - binary_accuracy: 0.6290 - false_negatives_2: 239.0000 - val_loss: 15.0962 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.7517 - binary_accuracy: 0.6043 - false_negatives_2: 189.0000 - val_loss: 18.5601 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 14.2320 - binary_accuracy: 0.5783 - false_negatives_2: 213.0000 - val_loss: 13.0032 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 628/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 11.2133 - binary_accuracy: 0.5841 - false_negatives_2: 180.0000 - val_loss: 11.3867 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 11.3926 - binary_accuracy: 0.6130 - false_negatives_2: 218.0000 - val_loss: 13.6462 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 11.7985 - binary_accuracy: 0.6362 - false_negatives_2: 228.0000 - val_loss: 12.2195 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 631/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.9286 - binary_accuracy: 0.6348 - false_negatives_2: 226.0000 - val_loss: 10.9898 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 632/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.2861 - binary_accuracy: 0.6304 - false_negatives_2: 237.0000 - val_loss: 10.2922 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 633/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 12.5564 - binary_accuracy: 0.6290 - false_negatives_2: 233.0000 - val_loss: 13.5653 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 11.8026 - binary_accuracy: 0.6188 - false_negatives_2: 238.0000 - val_loss: 10.3145 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 635/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.0917 - binary_accuracy: 0.6420 - false_negatives_2: 245.0000 - val_loss: 8.7555 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 636/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 8.9043 - binary_accuracy: 0.6232 - false_negatives_2: 233.0000 - val_loss: 8.5701 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 637/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 8.5738 - binary_accuracy: 0.6377 - false_negatives_2: 232.0000 - val_loss: 9.0069 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 638/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 8.7812 - binary_accuracy: 0.6319 - false_negatives_2: 223.0000 - val_loss: 8.1682 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 639/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 8.5877 - binary_accuracy: 0.6261 - false_negatives_2: 228.0000 - val_loss: 9.4356 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 640/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 11.4440 - binary_accuracy: 0.6275 - false_negatives_2: 216.0000 - val_loss: 11.1530 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 641/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 9.3973 - binary_accuracy: 0.6319 - false_negatives_2: 236.0000 - val_loss: 9.2453 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 642/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 11.7980 - binary_accuracy: 0.6406 - false_negatives_2: 243.0000 - val_loss: 10.3251 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 9.0704 - binary_accuracy: 0.6420 - false_negatives_2: 243.0000 - val_loss: 24.4097 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 17.6135 - binary_accuracy: 0.6145 - false_negatives_2: 233.0000 - val_loss: 9.3880 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 8.6682 - binary_accuracy: 0.6246 - false_negatives_2: 220.0000 - val_loss: 8.4274 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 646/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 9.6420 - binary_accuracy: 0.6333 - false_negatives_2: 227.0000 - val_loss: 8.9337 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 647/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 8.1415 - binary_accuracy: 0.6362 - false_negatives_2: 230.0000 - val_loss: 7.7802 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.9642 - binary_accuracy: 0.5652 - false_negatives_2: 208.0000 - val_loss: 10.2685 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 649/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 9.5161 - binary_accuracy: 0.6029 - false_negatives_2: 220.0000 - val_loss: 8.4032 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 650/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 8.0724 - binary_accuracy: 0.6174 - false_negatives_2: 214.0000 - val_loss: 7.3425 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 651/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 8.9033 - binary_accuracy: 0.6203 - false_negatives_2: 237.0000 - val_loss: 10.8062 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 652/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.2165 - binary_accuracy: 0.6188 - false_negatives_2: 226.0000 - val_loss: 10.5549 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 653/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.8443 - binary_accuracy: 0.6232 - false_negatives_2: 208.0000 - val_loss: 8.6040 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 654/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.9515 - binary_accuracy: 0.6217 - false_negatives_2: 220.0000 - val_loss: 7.3505 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 655/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.6576 - binary_accuracy: 0.6174 - false_negatives_2: 208.0000 - val_loss: 7.9754 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 656/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 8.9474 - binary_accuracy: 0.6406 - false_negatives_2: 225.0000 - val_loss: 10.9839 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 657/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 9.4200 - binary_accuracy: 0.6377 - false_negatives_2: 239.0000 - val_loss: 7.6281 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 658/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.6908 - binary_accuracy: 0.5957 - false_negatives_2: 207.0000 - val_loss: 7.9053 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 6.5841 - binary_accuracy: 0.6027 - false_negatives_2: 197.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_123945-sadt98gk/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 138ms/step - loss: 6.5603 - binary_accuracy: 0.5986 - false_negatives_2: 200.0000 - val_loss: 5.6000 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 660/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 7.0594 - binary_accuracy: 0.6348 - false_negatives_2: 218.0000 - val_loss: 9.6901 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 10.4946 - binary_accuracy: 0.6000 - false_negatives_2: 195.0000 - val_loss: 9.5611 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 662/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 9.6591 - binary_accuracy: 0.6043 - false_negatives_2: 226.0000 - val_loss: 9.9777 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 663/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 11.4249 - binary_accuracy: 0.6319 - false_negatives_2: 241.0000 - val_loss: 11.5654 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 664/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.2100 - binary_accuracy: 0.6217 - false_negatives_2: 235.0000 - val_loss: 11.9168 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.5502 - binary_accuracy: 0.6232 - false_negatives_2: 203.0000 - val_loss: 8.9986 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 666/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 8.0548 - binary_accuracy: 0.6029 - false_negatives_2: 209.0000 - val_loss: 7.3699 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 667/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.5740 - binary_accuracy: 0.6058 - false_negatives_2: 231.0000 - val_loss: 14.0869 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 668/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.3566 - binary_accuracy: 0.6348 - false_negatives_2: 239.0000 - val_loss: 11.0440 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 669/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 14.2009 - binary_accuracy: 0.6188 - false_negatives_2: 225.0000 - val_loss: 13.6341 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 670/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 13.0076 - binary_accuracy: 0.6304 - false_negatives_2: 231.0000 - val_loss: 12.6197 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 671/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 13.3593 - binary_accuracy: 0.6246 - false_negatives_2: 236.0000 - val_loss: 13.9162 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 672/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 13.4716 - binary_accuracy: 0.6377 - false_negatives_2: 242.0000 - val_loss: 12.3265 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 13.6430 - binary_accuracy: 0.6348 - false_negatives_2: 243.0000 - val_loss: 12.2387 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 674/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 12.6025 - binary_accuracy: 0.6449 - false_negatives_2: 238.0000 - val_loss: 11.8487 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 675/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 11.9187 - binary_accuracy: 0.6333 - false_negatives_2: 217.0000 - val_loss: 12.6037 - val_binary_accuracy: 0.6826 - val_false_negatives_2: 68.0000\n",
            "Epoch 676/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 10.9451 - binary_accuracy: 0.6043 - false_negatives_2: 204.0000 - val_loss: 9.2832 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 677/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 9.1560 - binary_accuracy: 0.5928 - false_negatives_2: 209.0000 - val_loss: 10.8438 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 9.6578 - binary_accuracy: 0.5957 - false_negatives_2: 232.0000 - val_loss: 9.1911 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 679/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.7786 - binary_accuracy: 0.6333 - false_negatives_2: 217.0000 - val_loss: 8.2098 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 680/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 7.8494 - binary_accuracy: 0.6406 - false_negatives_2: 238.0000 - val_loss: 7.1394 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 681/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.1503 - binary_accuracy: 0.6261 - false_negatives_2: 225.0000 - val_loss: 7.9662 - val_binary_accuracy: 0.6478 - val_false_negatives_2: 77.0000\n",
            "Epoch 682/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.9998 - binary_accuracy: 0.6319 - false_negatives_2: 226.0000 - val_loss: 6.5019 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 683/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.6737 - binary_accuracy: 0.6275 - false_negatives_2: 232.0000 - val_loss: 7.3530 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 684/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.6958 - binary_accuracy: 0.6449 - false_negatives_2: 242.0000 - val_loss: 9.1995 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 685/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8.5890 - binary_accuracy: 0.6246 - false_negatives_2: 228.0000 - val_loss: 8.1855 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 686/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 7.6526 - binary_accuracy: 0.6188 - false_negatives_2: 216.0000 - val_loss: 9.4104 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 687/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 9.3686 - binary_accuracy: 0.6435 - false_negatives_2: 244.0000 - val_loss: 8.5987 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 688/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.5467 - binary_accuracy: 0.6348 - false_negatives_2: 230.0000 - val_loss: 8.4438 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8.7259 - binary_accuracy: 0.6377 - false_negatives_2: 225.0000 - val_loss: 9.6209 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 690/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.2597 - binary_accuracy: 0.6362 - false_negatives_2: 243.0000 - val_loss: 11.7024 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 8.1399 - binary_accuracy: 0.6029 - false_negatives_2: 217.0000 - val_loss: 9.0513 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 692/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.4056 - binary_accuracy: 0.6478 - false_negatives_2: 240.0000 - val_loss: 10.5481 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 693/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 11.2911 - binary_accuracy: 0.6101 - false_negatives_2: 220.0000 - val_loss: 9.8913 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 694/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.2990 - binary_accuracy: 0.6232 - false_negatives_2: 239.0000 - val_loss: 8.0058 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 695/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 9.0602 - binary_accuracy: 0.6377 - false_negatives_2: 230.0000 - val_loss: 10.7016 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 696/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 12.5406 - binary_accuracy: 0.6130 - false_negatives_2: 216.0000 - val_loss: 384.3556 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 20.7057 - binary_accuracy: 0.6377 - false_negatives_2: 215.0000 - val_loss: 19.4198 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 698/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.9859 - binary_accuracy: 0.6000 - false_negatives_2: 209.0000 - val_loss: 15.2887 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 699/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.0816 - binary_accuracy: 0.5899 - false_negatives_2: 188.0000 - val_loss: 15.2016 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.3837 - binary_accuracy: 0.6203 - false_negatives_2: 231.0000 - val_loss: 17.1414 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 701/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 19.0291 - binary_accuracy: 0.6435 - false_negatives_2: 238.0000 - val_loss: 18.2406 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 702/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.6817 - binary_accuracy: 0.6174 - false_negatives_2: 210.0000 - val_loss: 15.4028 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 703/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 15.3593 - binary_accuracy: 0.6174 - false_negatives_2: 209.0000 - val_loss: 14.7096 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 14.6652 - binary_accuracy: 0.5899 - false_negatives_2: 186.0000 - val_loss: 13.2724 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 705/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.6883 - binary_accuracy: 0.6159 - false_negatives_2: 214.0000 - val_loss: 16.2581 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 706/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.4616 - binary_accuracy: 0.6000 - false_negatives_2: 225.0000 - val_loss: 17.8541 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 707/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 16.8641 - binary_accuracy: 0.6362 - false_negatives_2: 216.0000 - val_loss: 16.3441 - val_binary_accuracy: 0.5957 - val_false_negatives_2: 43.0000\n",
            "Epoch 708/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.9389 - binary_accuracy: 0.5971 - false_negatives_2: 225.0000 - val_loss: 13.8658 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 709/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 13.4298 - binary_accuracy: 0.6348 - false_negatives_2: 239.0000 - val_loss: 13.6830 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 710/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 14.6232 - binary_accuracy: 0.6145 - false_negatives_2: 214.0000 - val_loss: 14.4724 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 711/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 12.9639 - binary_accuracy: 0.6261 - false_negatives_2: 227.0000 - val_loss: 12.1764 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 712/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 11.9482 - binary_accuracy: 0.6101 - false_negatives_2: 219.0000 - val_loss: 12.5260 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 713/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 11.6639 - binary_accuracy: 0.6406 - false_negatives_2: 231.0000 - val_loss: 11.2916 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 714/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 11.6577 - binary_accuracy: 0.6348 - false_negatives_2: 216.0000 - val_loss: 11.5458 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 715/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 11.0270 - binary_accuracy: 0.6217 - false_negatives_2: 225.0000 - val_loss: 10.8736 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 716/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 11.2765 - binary_accuracy: 0.6319 - false_negatives_2: 218.0000 - val_loss: 11.0585 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 10.9988 - binary_accuracy: 0.6435 - false_negatives_2: 241.0000 - val_loss: 10.3898 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 718/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 10.6337 - binary_accuracy: 0.6362 - false_negatives_2: 240.0000 - val_loss: 10.7800 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 719/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 10.1885 - binary_accuracy: 0.6290 - false_negatives_2: 235.0000 - val_loss: 9.5985 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 720/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.4067 - binary_accuracy: 0.6261 - false_negatives_2: 214.0000 - val_loss: 11.4949 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 721/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 9.4231 - binary_accuracy: 0.5841 - false_negatives_2: 213.0000 - val_loss: 9.3182 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 722/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.8730 - binary_accuracy: 0.6188 - false_negatives_2: 207.0000 - val_loss: 10.3867 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 723/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 9.7535 - binary_accuracy: 0.6232 - false_negatives_2: 218.0000 - val_loss: 8.7381 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 724/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 8.3065 - binary_accuracy: 0.6319 - false_negatives_2: 237.0000 - val_loss: 8.8349 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 725/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 11.6656 - binary_accuracy: 0.6058 - false_negatives_2: 198.0000 - val_loss: 16.7002 - val_binary_accuracy: 0.3522 - val_false_negatives_2: 2.0000\n",
            "Epoch 726/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 17.9794 - binary_accuracy: 0.6420 - false_negatives_2: 231.0000 - val_loss: 21.8452 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 727/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 26.7917 - binary_accuracy: 0.6319 - false_negatives_2: 238.0000 - val_loss: 28.9439 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 27.3295 - binary_accuracy: 0.6362 - false_negatives_2: 227.0000 - val_loss: 24.7948 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 729/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 23.3328 - binary_accuracy: 0.6493 - false_negatives_2: 226.0000 - val_loss: 27.6759 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 23.8347 - binary_accuracy: 0.6391 - false_negatives_2: 234.0000 - val_loss: 25.9786 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 731/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 26.3540 - binary_accuracy: 0.5957 - false_negatives_2: 206.0000 - val_loss: 23.0103 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 732/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.8116 - binary_accuracy: 0.6246 - false_negatives_2: 234.0000 - val_loss: 27.6046 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 733/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 21.8411 - binary_accuracy: 0.6130 - false_negatives_2: 217.0000 - val_loss: 19.0356 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 734/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.6836 - binary_accuracy: 0.6348 - false_negatives_2: 213.0000 - val_loss: 19.0737 - val_binary_accuracy: 0.6478 - val_false_negatives_2: 77.0000\n",
            "Epoch 735/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 20.4688 - binary_accuracy: 0.6319 - false_negatives_2: 202.0000 - val_loss: 21.2914 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 736/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 21.3714 - binary_accuracy: 0.5855 - false_negatives_2: 217.0000 - val_loss: 29.7754 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 737/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 28.0847 - binary_accuracy: 0.6333 - false_negatives_2: 241.0000 - val_loss: 21.9012 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 738/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 20.2375 - binary_accuracy: 0.6203 - false_negatives_2: 233.0000 - val_loss: 19.8414 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 739/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.0440 - binary_accuracy: 0.6435 - false_negatives_2: 224.0000 - val_loss: 18.9807 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.6416 - binary_accuracy: 0.6522 - false_negatives_2: 212.0000 - val_loss: 30.0975 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 21.4009 - binary_accuracy: 0.6304 - false_negatives_2: 222.0000 - val_loss: 16.4878 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 742/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.0425 - binary_accuracy: 0.6087 - false_negatives_2: 221.0000 - val_loss: 15.6332 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 743/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.0634 - binary_accuracy: 0.6377 - false_negatives_2: 234.0000 - val_loss: 15.8410 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 744/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 15.3433 - binary_accuracy: 0.6188 - false_negatives_2: 227.0000 - val_loss: 16.4548 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 745/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.9324 - binary_accuracy: 0.6377 - false_negatives_2: 227.0000 - val_loss: 17.1626 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 746/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 15.7322 - binary_accuracy: 0.6275 - false_negatives_2: 221.0000 - val_loss: 14.1363 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 747/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 13.6688 - binary_accuracy: 0.6348 - false_negatives_2: 221.0000 - val_loss: 15.6187 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 748/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.8367 - binary_accuracy: 0.6319 - false_negatives_2: 238.0000 - val_loss: 17.3596 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 749/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.3435 - binary_accuracy: 0.6290 - false_negatives_2: 234.0000 - val_loss: 18.7926 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 750/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 19.1355 - binary_accuracy: 0.6435 - false_negatives_2: 235.0000 - val_loss: 19.9882 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 751/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 18.8123 - binary_accuracy: 0.6377 - false_negatives_2: 234.0000 - val_loss: 17.6661 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 752/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 17.7626 - binary_accuracy: 0.6232 - false_negatives_2: 233.0000 - val_loss: 17.6451 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 753/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 17.6467 - binary_accuracy: 0.6101 - false_negatives_2: 228.0000 - val_loss: 19.9178 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 754/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 23.9028 - binary_accuracy: 0.6014 - false_negatives_2: 200.0000 - val_loss: 24.5358 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 22.7936 - binary_accuracy: 0.6188 - false_negatives_2: 229.0000 - val_loss: 20.2058 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 756/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 19.6661 - binary_accuracy: 0.6348 - false_negatives_2: 237.0000 - val_loss: 19.3244 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 757/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 20.0647 - binary_accuracy: 0.6217 - false_negatives_2: 228.0000 - val_loss: 20.3746 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 758/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 19.0349 - binary_accuracy: 0.6116 - false_negatives_2: 227.0000 - val_loss: 17.9548 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 759/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 18.4073 - binary_accuracy: 0.6246 - false_negatives_2: 222.0000 - val_loss: 19.4908 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 760/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.5515 - binary_accuracy: 0.6203 - false_negatives_2: 219.0000 - val_loss: 18.8718 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 761/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.6928 - binary_accuracy: 0.6275 - false_negatives_2: 227.0000 - val_loss: 23.0198 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 762/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 19.3613 - binary_accuracy: 0.6333 - false_negatives_2: 242.0000 - val_loss: 17.7050 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 763/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.0441 - binary_accuracy: 0.6029 - false_negatives_2: 205.0000 - val_loss: 18.7028 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 764/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.6090 - binary_accuracy: 0.6232 - false_negatives_2: 229.0000 - val_loss: 15.1166 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 765/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.4785 - binary_accuracy: 0.6435 - false_negatives_2: 244.0000 - val_loss: 19.3058 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.9921 - binary_accuracy: 0.6377 - false_negatives_2: 235.0000 - val_loss: 16.3234 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 767/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.2279 - binary_accuracy: 0.6246 - false_negatives_2: 234.0000 - val_loss: 14.3096 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 768/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.7708 - binary_accuracy: 0.6319 - false_negatives_2: 239.0000 - val_loss: 16.7947 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 17.0450 - binary_accuracy: 0.6348 - false_negatives_2: 217.0000 - val_loss: 16.2111 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 770/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 15.4946 - binary_accuracy: 0.6420 - false_negatives_2: 237.0000 - val_loss: 16.5756 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 771/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.0937 - binary_accuracy: 0.6159 - false_negatives_2: 213.0000 - val_loss: 15.5511 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 772/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 20.0727 - binary_accuracy: 0.5928 - false_negatives_2: 229.0000 - val_loss: 26.0088 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 773/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.0488 - binary_accuracy: 0.6087 - false_negatives_2: 209.0000 - val_loss: 18.2927 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 774/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 18.4042 - binary_accuracy: 0.6261 - false_negatives_2: 198.0000 - val_loss: 20.0513 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 775/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.1914 - binary_accuracy: 0.5971 - false_negatives_2: 190.0000 - val_loss: 20.7059 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 776/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 19.8361 - binary_accuracy: 0.6275 - false_negatives_2: 229.0000 - val_loss: 18.6316 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 777/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.8607 - binary_accuracy: 0.6043 - false_negatives_2: 190.0000 - val_loss: 22.1227 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 19.0377 - binary_accuracy: 0.6116 - false_negatives_2: 220.0000 - val_loss: 17.0974 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 779/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.0822 - binary_accuracy: 0.6159 - false_negatives_2: 228.0000 - val_loss: 20.9323 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 780/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.5199 - binary_accuracy: 0.6391 - false_negatives_2: 210.0000 - val_loss: 18.9469 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 781/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 20.0966 - binary_accuracy: 0.6130 - false_negatives_2: 212.0000 - val_loss: 23.3049 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 782/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 24.5504 - binary_accuracy: 0.6304 - false_negatives_2: 235.0000 - val_loss: 24.1733 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 783/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.5885 - binary_accuracy: 0.6275 - false_negatives_2: 238.0000 - val_loss: 20.4550 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 19.8254 - binary_accuracy: 0.6565 - false_negatives_2: 219.0000 - val_loss: 21.8841 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 785/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.0376 - binary_accuracy: 0.6464 - false_negatives_2: 230.0000 - val_loss: 20.7122 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 19.3733 - binary_accuracy: 0.6319 - false_negatives_2: 236.0000 - val_loss: 18.8751 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 787/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.9332 - binary_accuracy: 0.6130 - false_negatives_2: 228.0000 - val_loss: 21.7835 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 788/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 19.6504 - binary_accuracy: 0.6304 - false_negatives_2: 240.0000 - val_loss: 20.6223 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 789/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 20.1866 - binary_accuracy: 0.6275 - false_negatives_2: 209.0000 - val_loss: 21.6477 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 790/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 22.7811 - binary_accuracy: 0.6348 - false_negatives_2: 210.0000 - val_loss: 25.6967 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 791/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 23.5348 - binary_accuracy: 0.6435 - false_negatives_2: 234.0000 - val_loss: 22.3278 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 792/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 21.8543 - binary_accuracy: 0.6058 - false_negatives_2: 197.0000 - val_loss: 20.3838 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 793/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 18.3684 - binary_accuracy: 0.6333 - false_negatives_2: 226.0000 - val_loss: 19.8309 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 794/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 18.8771 - binary_accuracy: 0.6290 - false_negatives_2: 218.0000 - val_loss: 18.4023 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 795/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 20.5796 - binary_accuracy: 0.5870 - false_negatives_2: 203.0000 - val_loss: 21.9072 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 796/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 21.7984 - binary_accuracy: 0.6014 - false_negatives_2: 225.0000 - val_loss: 21.8590 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 797/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 19.9821 - binary_accuracy: 0.5652 - false_negatives_2: 178.0000 - val_loss: 19.1508 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 798/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 21.7740 - binary_accuracy: 0.6348 - false_negatives_2: 232.0000 - val_loss: 20.1632 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 18.5360 - binary_accuracy: 0.6058 - false_negatives_2: 210.0000 - val_loss: 18.6466 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 800/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.6959 - binary_accuracy: 0.6246 - false_negatives_2: 211.0000 - val_loss: 31.4594 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 801/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 42.2548 - binary_accuracy: 0.6362 - false_negatives_2: 244.0000 - val_loss: 27.9009 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 802/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.2740 - binary_accuracy: 0.6362 - false_negatives_2: 237.0000 - val_loss: 19.9644 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 803/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 19.6662 - binary_accuracy: 0.6232 - false_negatives_2: 233.0000 - val_loss: 19.3077 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.3951 - binary_accuracy: 0.6232 - false_negatives_2: 213.0000 - val_loss: 19.0571 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 805/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.7250 - binary_accuracy: 0.6304 - false_negatives_2: 238.0000 - val_loss: 18.5260 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 806/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.2054 - binary_accuracy: 0.6261 - false_negatives_2: 235.0000 - val_loss: 15.5960 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 807/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 15.4784 - binary_accuracy: 0.6319 - false_negatives_2: 234.0000 - val_loss: 16.0645 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 808/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 14.7135 - binary_accuracy: 0.6449 - false_negatives_2: 220.0000 - val_loss: 13.2571 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 17.7484 - binary_accuracy: 0.5986 - false_negatives_2: 198.0000 - val_loss: 17.3406 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 15.0795 - binary_accuracy: 0.6420 - false_negatives_2: 235.0000 - val_loss: 13.4806 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 811/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.4982 - binary_accuracy: 0.6029 - false_negatives_2: 206.0000 - val_loss: 11.9781 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 812/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.2534 - binary_accuracy: 0.6145 - false_negatives_2: 211.0000 - val_loss: 12.5851 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 813/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.7492 - binary_accuracy: 0.6377 - false_negatives_2: 229.0000 - val_loss: 13.5972 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 13.0209 - binary_accuracy: 0.6087 - false_negatives_2: 184.0000 - val_loss: 12.4650 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 815/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 13.4288 - binary_accuracy: 0.6464 - false_negatives_2: 238.0000 - val_loss: 16.5026 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.5547 - binary_accuracy: 0.6130 - false_negatives_2: 231.0000 - val_loss: 13.3062 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 817/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.4024 - binary_accuracy: 0.6435 - false_negatives_2: 239.0000 - val_loss: 20.9651 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 818/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.3707 - binary_accuracy: 0.6406 - false_negatives_2: 230.0000 - val_loss: 27.0156 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.7454 - binary_accuracy: 0.6116 - false_negatives_2: 218.0000 - val_loss: 19.8141 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 820/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 20.1454 - binary_accuracy: 0.6275 - false_negatives_2: 204.0000 - val_loss: 21.9751 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 821/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.7138 - binary_accuracy: 0.6203 - false_negatives_2: 231.0000 - val_loss: 21.3793 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 822/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.6383 - binary_accuracy: 0.5899 - false_negatives_2: 217.0000 - val_loss: 18.1844 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 823/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.2480 - binary_accuracy: 0.6232 - false_negatives_2: 228.0000 - val_loss: 17.1312 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 824/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.8922 - binary_accuracy: 0.6319 - false_negatives_2: 233.0000 - val_loss: 21.3189 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 825/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.4886 - binary_accuracy: 0.6333 - false_negatives_2: 234.0000 - val_loss: 16.6657 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 826/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.9295 - binary_accuracy: 0.6275 - false_negatives_2: 219.0000 - val_loss: 21.8868 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 20.1168 - binary_accuracy: 0.6029 - false_negatives_2: 211.0000 - val_loss: 18.6670 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 828/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 17.1122 - binary_accuracy: 0.6116 - false_negatives_2: 219.0000 - val_loss: 16.4350 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 829/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 19.6120 - binary_accuracy: 0.6058 - false_negatives_2: 209.0000 - val_loss: 40.5915 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 830/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 28.3423 - binary_accuracy: 0.6217 - false_negatives_2: 230.0000 - val_loss: 19.8628 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 831/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 18.0404 - binary_accuracy: 0.6391 - false_negatives_2: 244.0000 - val_loss: 16.7307 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 832/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 16.1678 - binary_accuracy: 0.6333 - false_negatives_2: 243.0000 - val_loss: 16.3022 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 833/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 24.1050 - binary_accuracy: 0.6507 - false_negatives_2: 231.0000 - val_loss: 18.1121 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 834/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 18.5331 - binary_accuracy: 0.6391 - false_negatives_2: 218.0000 - val_loss: 20.1265 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 835/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 19.2689 - binary_accuracy: 0.6261 - false_negatives_2: 237.0000 - val_loss: 17.9362 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 836/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 17.3820 - binary_accuracy: 0.6304 - false_negatives_2: 221.0000 - val_loss: 16.1783 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 837/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 16.4675 - binary_accuracy: 0.6493 - false_negatives_2: 216.0000 - val_loss: 15.7220 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 838/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 16.1544 - binary_accuracy: 0.6391 - false_negatives_2: 218.0000 - val_loss: 15.6038 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 14.7441 - binary_accuracy: 0.6362 - false_negatives_2: 235.0000 - val_loss: 14.2384 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 840/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 13.9035 - binary_accuracy: 0.6435 - false_negatives_2: 242.0000 - val_loss: 13.6577 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 841/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 14.1588 - binary_accuracy: 0.6478 - false_negatives_2: 222.0000 - val_loss: 13.7118 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 842/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.1729 - binary_accuracy: 0.6275 - false_negatives_2: 221.0000 - val_loss: 14.2599 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 843/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 14.9799 - binary_accuracy: 0.6217 - false_negatives_2: 229.0000 - val_loss: 19.3609 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 844/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.8706 - binary_accuracy: 0.6101 - false_negatives_2: 220.0000 - val_loss: 16.6070 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 845/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 15.8666 - binary_accuracy: 0.6449 - false_negatives_2: 230.0000 - val_loss: 14.6000 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 846/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 15.5752 - binary_accuracy: 0.6377 - false_negatives_2: 232.0000 - val_loss: 14.2716 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 847/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 13.3529 - binary_accuracy: 0.6435 - false_negatives_2: 245.0000 - val_loss: 12.8575 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 848/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 12.6280 - binary_accuracy: 0.6391 - false_negatives_2: 226.0000 - val_loss: 12.5575 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 849/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 12.7232 - binary_accuracy: 0.6304 - false_negatives_2: 236.0000 - val_loss: 13.8113 - val_binary_accuracy: 0.3565 - val_false_negatives_2: 2.0000\n",
            "Epoch 850/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.7237 - binary_accuracy: 0.6406 - false_negatives_2: 231.0000 - val_loss: 13.3230 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 851/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 14.3159 - binary_accuracy: 0.6348 - false_negatives_2: 242.0000 - val_loss: 14.8278 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 852/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 14.0455 - binary_accuracy: 0.6217 - false_negatives_2: 228.0000 - val_loss: 12.9155 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 853/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 13.3593 - binary_accuracy: 0.6130 - false_negatives_2: 228.0000 - val_loss: 13.4480 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 854/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 12.7943 - binary_accuracy: 0.6290 - false_negatives_2: 223.0000 - val_loss: 14.4409 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.7894 - binary_accuracy: 0.6319 - false_negatives_2: 218.0000 - val_loss: 13.0621 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 856/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 13.1561 - binary_accuracy: 0.6449 - false_negatives_2: 243.0000 - val_loss: 16.5487 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 857/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 20.5667 - binary_accuracy: 0.6319 - false_negatives_2: 236.0000 - val_loss: 24.2485 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 858/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.0703 - binary_accuracy: 0.6478 - false_negatives_2: 224.0000 - val_loss: 23.6639 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 23.4989 - binary_accuracy: 0.6275 - false_negatives_2: 233.0000 - val_loss: 25.8563 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.7707 - binary_accuracy: 0.6304 - false_negatives_2: 242.0000 - val_loss: 21.9966 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 861/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.2529 - binary_accuracy: 0.6406 - false_negatives_2: 236.0000 - val_loss: 21.8212 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 862/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 20.7840 - binary_accuracy: 0.6435 - false_negatives_2: 242.0000 - val_loss: 20.5669 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 863/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 23.1325 - binary_accuracy: 0.6406 - false_negatives_2: 240.0000 - val_loss: 25.8395 - val_binary_accuracy: 0.5957 - val_false_negatives_2: 72.0000\n",
            "Epoch 864/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 25.7104 - binary_accuracy: 0.6130 - false_negatives_2: 219.0000 - val_loss: 28.1417 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 865/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 25.7068 - binary_accuracy: 0.6232 - false_negatives_2: 220.0000 - val_loss: 23.7685 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 866/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.6180 - binary_accuracy: 0.6319 - false_negatives_2: 237.0000 - val_loss: 21.8284 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 867/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 23.0231 - binary_accuracy: 0.6493 - false_negatives_2: 234.0000 - val_loss: 23.8652 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 868/1000\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 22.8528 - binary_accuracy: 0.6232 - false_negatives_2: 225.0000 - val_loss: 23.1561 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 869/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 21.9700 - binary_accuracy: 0.6420 - false_negatives_2: 232.0000 - val_loss: 21.8210 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 870/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 23.1112 - binary_accuracy: 0.6319 - false_negatives_2: 224.0000 - val_loss: 26.2878 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 871/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 27.3398 - binary_accuracy: 0.6377 - false_negatives_2: 241.0000 - val_loss: 27.9540 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 872/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 24.3883 - binary_accuracy: 0.6304 - false_negatives_2: 243.0000 - val_loss: 23.0661 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 873/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 22.8066 - binary_accuracy: 0.6406 - false_negatives_2: 240.0000 - val_loss: 22.9451 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 21.2340 - binary_accuracy: 0.6420 - false_negatives_2: 239.0000 - val_loss: 19.7270 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 875/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 19.7416 - binary_accuracy: 0.6406 - false_negatives_2: 237.0000 - val_loss: 20.2071 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 876/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 20.1099 - binary_accuracy: 0.6319 - false_negatives_2: 243.0000 - val_loss: 19.8153 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 877/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 19.3743 - binary_accuracy: 0.6435 - false_negatives_2: 245.0000 - val_loss: 19.0685 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 878/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.0079 - binary_accuracy: 0.6391 - false_negatives_2: 223.0000 - val_loss: 19.1970 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 879/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.9615 - binary_accuracy: 0.6348 - false_negatives_2: 223.0000 - val_loss: 18.3079 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 880/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.5128 - binary_accuracy: 0.6406 - false_negatives_2: 221.0000 - val_loss: 23.1423 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 881/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.3444 - binary_accuracy: 0.6275 - false_negatives_2: 234.0000 - val_loss: 24.1867 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 882/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 26.3881 - binary_accuracy: 0.6449 - false_negatives_2: 243.0000 - val_loss: 24.2498 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 883/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 23.0459 - binary_accuracy: 0.6087 - false_negatives_2: 235.0000 - val_loss: 23.9559 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 884/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 23.5286 - binary_accuracy: 0.6188 - false_negatives_2: 237.0000 - val_loss: 23.8693 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 22.6479 - binary_accuracy: 0.6145 - false_negatives_2: 226.0000 - val_loss: 21.0232 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 886/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 19.6249 - binary_accuracy: 0.6377 - false_negatives_2: 233.0000 - val_loss: 19.0489 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 887/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 19.6851 - binary_accuracy: 0.6159 - false_negatives_2: 222.0000 - val_loss: 22.3087 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 888/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 20.2894 - binary_accuracy: 0.6159 - false_negatives_2: 208.0000 - val_loss: 21.4908 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 889/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 23.0343 - binary_accuracy: 0.6101 - false_negatives_2: 221.0000 - val_loss: 25.9175 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 890/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 26.7226 - binary_accuracy: 0.5725 - false_negatives_2: 205.0000 - val_loss: 26.1722 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 891/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 26.1479 - binary_accuracy: 0.6377 - false_negatives_2: 228.0000 - val_loss: 25.6735 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 892/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 26.5581 - binary_accuracy: 0.6319 - false_negatives_2: 227.0000 - val_loss: 27.2000 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 26.9940 - binary_accuracy: 0.6275 - false_negatives_2: 233.0000 - val_loss: 24.7773 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 894/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.9532 - binary_accuracy: 0.6435 - false_negatives_2: 235.0000 - val_loss: 20.0184 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 895/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.8426 - binary_accuracy: 0.6377 - false_negatives_2: 215.0000 - val_loss: 23.7629 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 896/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.0654 - binary_accuracy: 0.6304 - false_negatives_2: 236.0000 - val_loss: 21.9404 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 897/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 23.5328 - binary_accuracy: 0.6232 - false_negatives_2: 226.0000 - val_loss: 21.6804 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 898/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 20.2209 - binary_accuracy: 0.6377 - false_negatives_2: 211.0000 - val_loss: 19.6821 - val_binary_accuracy: 0.6478 - val_false_negatives_2: 77.0000\n",
            "Epoch 899/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 19.2536 - binary_accuracy: 0.6304 - false_negatives_2: 195.0000 - val_loss: 18.7974 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 900/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.2341 - binary_accuracy: 0.6406 - false_negatives_2: 222.0000 - val_loss: 19.6980 - val_binary_accuracy: 0.5870 - val_false_negatives_2: 69.0000\n",
            "Epoch 901/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 19.6216 - binary_accuracy: 0.6406 - false_negatives_2: 212.0000 - val_loss: 18.3360 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 902/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 17.1716 - binary_accuracy: 0.6391 - false_negatives_2: 244.0000 - val_loss: 16.2572 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 903/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 16.1808 - binary_accuracy: 0.6333 - false_negatives_2: 234.0000 - val_loss: 15.8113 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 904/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 17.8190 - binary_accuracy: 0.6478 - false_negatives_2: 215.0000 - val_loss: 19.1636 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 905/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 18.0167 - binary_accuracy: 0.6246 - false_negatives_2: 220.0000 - val_loss: 16.3595 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 906/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 17.4266 - binary_accuracy: 0.6580 - false_negatives_2: 191.0000 - val_loss: 18.7384 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 17.8964 - binary_accuracy: 0.5522 - false_negatives_2: 180.0000 - val_loss: 17.5061 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 908/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 17.4379 - binary_accuracy: 0.6464 - false_negatives_2: 223.0000 - val_loss: 17.2668 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 909/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 17.6223 - binary_accuracy: 0.6290 - false_negatives_2: 215.0000 - val_loss: 18.0047 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 910/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 17.4374 - binary_accuracy: 0.6507 - false_negatives_2: 217.0000 - val_loss: 18.5570 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 911/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 18.1347 - binary_accuracy: 0.6333 - false_negatives_2: 213.0000 - val_loss: 18.5965 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 912/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 18.8600 - binary_accuracy: 0.6275 - false_negatives_2: 224.0000 - val_loss: 18.0745 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 913/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 17.1654 - binary_accuracy: 0.6565 - false_negatives_2: 225.0000 - val_loss: 16.8279 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 914/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 16.9949 - binary_accuracy: 0.6333 - false_negatives_2: 219.0000 - val_loss: 16.7250 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 915/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 16.1600 - binary_accuracy: 0.6217 - false_negatives_2: 217.0000 - val_loss: 16.2125 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 916/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.1853 - binary_accuracy: 0.6217 - false_negatives_2: 230.0000 - val_loss: 17.7323 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 917/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 18.5718 - binary_accuracy: 0.6159 - false_negatives_2: 206.0000 - val_loss: 20.4232 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 918/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.0257 - binary_accuracy: 0.6304 - false_negatives_2: 233.0000 - val_loss: 18.3526 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 919/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 17.8689 - binary_accuracy: 0.6261 - false_negatives_2: 216.0000 - val_loss: 17.2087 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 920/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 17.5695 - binary_accuracy: 0.6406 - false_negatives_2: 203.0000 - val_loss: 18.8501 - val_binary_accuracy: 0.3870 - val_false_negatives_2: 3.0000\n",
            "Epoch 921/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 16.9949 - binary_accuracy: 0.6232 - false_negatives_2: 215.0000 - val_loss: 16.1162 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 922/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 16.6252 - binary_accuracy: 0.6261 - false_negatives_2: 202.0000 - val_loss: 17.6694 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 923/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 18.3005 - binary_accuracy: 0.6348 - false_negatives_2: 224.0000 - val_loss: 17.2088 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 924/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 17.1240 - binary_accuracy: 0.6435 - false_negatives_2: 229.0000 - val_loss: 18.7348 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 925/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 25.6438 - binary_accuracy: 0.6377 - false_negatives_2: 212.0000 - val_loss: 23.0461 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 926/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 20.6066 - binary_accuracy: 0.6522 - false_negatives_2: 236.0000 - val_loss: 19.5307 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 927/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.4625 - binary_accuracy: 0.6464 - false_negatives_2: 241.0000 - val_loss: 22.1773 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 928/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.3625 - binary_accuracy: 0.6522 - false_negatives_2: 207.0000 - val_loss: 22.4026 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 19.9978 - binary_accuracy: 0.6406 - false_negatives_2: 234.0000 - val_loss: 21.0534 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 930/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.0577 - binary_accuracy: 0.6174 - false_negatives_2: 222.0000 - val_loss: 23.3651 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 931/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.6611 - binary_accuracy: 0.6449 - false_negatives_2: 239.0000 - val_loss: 20.2287 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 932/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 20.0153 - binary_accuracy: 0.6377 - false_negatives_2: 225.0000 - val_loss: 23.2892 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 933/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 21.0821 - binary_accuracy: 0.6420 - false_negatives_2: 182.0000 - val_loss: 19.4297 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 934/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.1422 - binary_accuracy: 0.6058 - false_negatives_2: 210.0000 - val_loss: 22.7313 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 935/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 26.6188 - binary_accuracy: 0.6232 - false_negatives_2: 229.0000 - val_loss: 28.7764 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 936/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 30.9783 - binary_accuracy: 0.6348 - false_negatives_2: 192.0000 - val_loss: 30.0341 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 937/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 27.0227 - binary_accuracy: 0.6391 - false_negatives_2: 228.0000 - val_loss: 24.3607 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 938/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 25.6757 - binary_accuracy: 0.6333 - false_negatives_2: 227.0000 - val_loss: 27.4290 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 939/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 31.3602 - binary_accuracy: 0.6203 - false_negatives_2: 231.0000 - val_loss: 32.3579 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 940/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 30.6192 - binary_accuracy: 0.6348 - false_negatives_2: 237.0000 - val_loss: 30.4480 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 29.3633 - binary_accuracy: 0.6333 - false_negatives_2: 208.0000 - val_loss: 28.9482 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 942/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 27.8250 - binary_accuracy: 0.5768 - false_negatives_2: 191.0000 - val_loss: 26.9388 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 943/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 26.4668 - binary_accuracy: 0.6029 - false_negatives_2: 187.0000 - val_loss: 26.9806 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 944/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 27.5099 - binary_accuracy: 0.6435 - false_negatives_2: 217.0000 - val_loss: 26.7771 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 945/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 25.9279 - binary_accuracy: 0.6377 - false_negatives_2: 218.0000 - val_loss: 29.7813 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 946/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 38.7073 - binary_accuracy: 0.6275 - false_negatives_2: 216.0000 - val_loss: 30.6921 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 947/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 29.6662 - binary_accuracy: 0.6116 - false_negatives_2: 205.0000 - val_loss: 28.2112 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 948/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 26.7652 - binary_accuracy: 0.6246 - false_negatives_2: 208.0000 - val_loss: 25.7316 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 949/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 24.8214 - binary_accuracy: 0.6420 - false_negatives_2: 233.0000 - val_loss: 24.0790 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 950/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 23.6932 - binary_accuracy: 0.6406 - false_negatives_2: 227.0000 - val_loss: 23.4898 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 951/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 23.7784 - binary_accuracy: 0.6522 - false_negatives_2: 208.0000 - val_loss: 25.2062 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 24.8265 - binary_accuracy: 0.6362 - false_negatives_2: 241.0000 - val_loss: 25.5831 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 953/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 26.2288 - binary_accuracy: 0.6261 - false_negatives_2: 239.0000 - val_loss: 33.0137 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 30.4226 - binary_accuracy: 0.6348 - false_negatives_2: 219.0000 - val_loss: 26.1644 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 955/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 25.0351 - binary_accuracy: 0.6362 - false_negatives_2: 191.0000 - val_loss: 23.8416 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 956/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.5174 - binary_accuracy: 0.6406 - false_negatives_2: 231.0000 - val_loss: 26.7531 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 957/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 26.0828 - binary_accuracy: 0.6362 - false_negatives_2: 226.0000 - val_loss: 25.9724 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 958/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 25.3001 - binary_accuracy: 0.6333 - false_negatives_2: 217.0000 - val_loss: 24.7207 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 959/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 24.9546 - binary_accuracy: 0.6333 - false_negatives_2: 195.0000 - val_loss: 24.7822 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 960/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 24.2724 - binary_accuracy: 0.6362 - false_negatives_2: 223.0000 - val_loss: 23.3994 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 961/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 24.9825 - binary_accuracy: 0.6449 - false_negatives_2: 211.0000 - val_loss: 24.9039 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 962/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.6168 - binary_accuracy: 0.6406 - false_negatives_2: 242.0000 - val_loss: 24.9060 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 963/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 27.1538 - binary_accuracy: 0.6420 - false_negatives_2: 226.0000 - val_loss: 28.0023 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 964/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 27.1843 - binary_accuracy: 0.6275 - false_negatives_2: 242.0000 - val_loss: 26.9167 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 965/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 26.8270 - binary_accuracy: 0.6304 - false_negatives_2: 223.0000 - val_loss: 26.9518 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 966/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 27.4830 - binary_accuracy: 0.6217 - false_negatives_2: 215.0000 - val_loss: 26.8797 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 967/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 26.7236 - binary_accuracy: 0.6246 - false_negatives_2: 211.0000 - val_loss: 25.8267 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 968/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 24.7581 - binary_accuracy: 0.6145 - false_negatives_2: 209.0000 - val_loss: 24.9708 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.7642 - binary_accuracy: 0.6246 - false_negatives_2: 210.0000 - val_loss: 22.9293 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 970/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 23.9485 - binary_accuracy: 0.6217 - false_negatives_2: 206.0000 - val_loss: 26.6568 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 971/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 23.1445 - binary_accuracy: 0.6232 - false_negatives_2: 231.0000 - val_loss: 22.1672 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 972/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.5233 - binary_accuracy: 0.5971 - false_negatives_2: 208.0000 - val_loss: 21.8919 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 973/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 21.8126 - binary_accuracy: 0.6377 - false_negatives_2: 229.0000 - val_loss: 28.9443 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 974/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 26.6836 - binary_accuracy: 0.5971 - false_negatives_2: 196.0000 - val_loss: 29.2131 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 975/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 28.6154 - binary_accuracy: 0.6522 - false_negatives_2: 221.0000 - val_loss: 27.9549 - val_binary_accuracy: 0.6609 - val_false_negatives_2: 78.0000\n",
            "Epoch 976/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 26.0423 - binary_accuracy: 0.6275 - false_negatives_2: 233.0000 - val_loss: 25.0249 - val_binary_accuracy: 0.3391 - val_false_negatives_2: 1.0000\n",
            "Epoch 977/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.6443 - binary_accuracy: 0.6449 - false_negatives_2: 236.0000 - val_loss: 23.1927 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 978/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 23.2302 - binary_accuracy: 0.6580 - false_negatives_2: 190.0000 - val_loss: 23.9049 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 979/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 24.0479 - binary_accuracy: 0.6188 - false_negatives_2: 215.0000 - val_loss: 24.1797 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 1.0000\n",
            "Epoch 980/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 25.6694 - binary_accuracy: 0.6319 - false_negatives_2: 232.0000 - val_loss: 26.7987 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 981/1000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 24.0048 - binary_accuracy: 0.6391 - false_negatives_2: 230.0000 - val_loss: 22.3723 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 982/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 22.3252 - binary_accuracy: 0.6246 - false_negatives_2: 232.0000 - val_loss: 20.8771 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 983/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 20.3552 - binary_accuracy: 0.6188 - false_negatives_2: 209.0000 - val_loss: 21.1975 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 21.7850 - binary_accuracy: 0.6333 - false_negatives_2: 212.0000 - val_loss: 22.8299 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 985/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 28.0551 - binary_accuracy: 0.6391 - false_negatives_2: 242.0000 - val_loss: 31.8967 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 986/1000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 27.7565 - binary_accuracy: 0.6377 - false_negatives_2: 230.0000 - val_loss: 25.5042 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 987/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 26.5244 - binary_accuracy: 0.6029 - false_negatives_2: 226.0000 - val_loss: 27.6371 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 988/1000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 25.8496 - binary_accuracy: 0.6406 - false_negatives_2: 245.0000 - val_loss: 24.2004 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 989/1000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 23.6912 - binary_accuracy: 0.6449 - false_negatives_2: 231.0000 - val_loss: 23.3977 - val_binary_accuracy: 0.4522 - val_false_negatives_2: 11.0000\n",
            "Epoch 990/1000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 23.9441 - binary_accuracy: 0.6362 - false_negatives_2: 220.0000 - val_loss: 23.3330 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 991/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 22.6817 - binary_accuracy: 0.6377 - false_negatives_2: 217.0000 - val_loss: 22.3723 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 22.7235 - binary_accuracy: 0.6304 - false_negatives_2: 206.0000 - val_loss: 22.0771 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 22.0736 - binary_accuracy: 0.6377 - false_negatives_2: 232.0000 - val_loss: 22.1534 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 994/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.5162 - binary_accuracy: 0.6420 - false_negatives_2: 216.0000 - val_loss: 22.7234 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 995/1000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 25.7466 - binary_accuracy: 0.6391 - false_negatives_2: 213.0000 - val_loss: 26.5107 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 996/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.9289 - binary_accuracy: 0.6319 - false_negatives_2: 237.0000 - val_loss: 24.0809 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 997/1000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 24.2550 - binary_accuracy: 0.6188 - false_negatives_2: 221.0000 - val_loss: 23.6846 - val_binary_accuracy: 0.3435 - val_false_negatives_2: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 22.4960 - binary_accuracy: 0.6420 - false_negatives_2: 218.0000 - val_loss: 21.6116 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 999/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 21.8078 - binary_accuracy: 0.6217 - false_negatives_2: 230.0000 - val_loss: 21.1955 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n",
            "Epoch 1000/1000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 22.3804 - binary_accuracy: 0.6420 - false_negatives_2: 229.0000 - val_loss: 21.4809 - val_binary_accuracy: 0.6565 - val_false_negatives_2: 79.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c9ea06e1cf0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "x_train_sc = sc.fit_transform(x_train)\n",
        "x_test_sc = sc.fit_transform(x_test)\n"
      ],
      "metadata": {
        "id": "L2aYqjPr9phH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = Sequential()"
      ],
      "metadata": {
        "id": "_jeHnvxxYPUP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6.add(Dense(units=35,activation='relu',kernel_initializer='GlorotNormal'))\n",
        "\n",
        "model6.add(Dense(units=500,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model6.add(Dropout(0.2))\n",
        "\n",
        "model6.add(BatchNormalization())\n",
        "\n",
        "model6.add(Dense(units=500,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model6.add(Dropout(0.2))\n",
        "\n",
        "model6.add(BatchNormalization())\n",
        "\n",
        "model6.add(Dense(units=200,activation='relu',kernel_initializer='GlorotNormal'))\n",
        "\n",
        "model6.add(Dropout(0.2))\n",
        "\n",
        "model6.add(BatchNormalization())\n",
        "\n",
        "model6.add(Dense(units=1,activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "c5srxvtV9i-T"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
        "              tf.keras.metrics.FalseNegatives()])"
      ],
      "metadata": {
        "id": "CcvtiNI0-H_6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = 'Startups',name = 'Sixth Trail')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "_ZwMN05H_hKV",
        "outputId": "c0f45c83-2931-4913-b39c-934e37898e95"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mossm0394\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231002_152537-tcqjqx3o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ossm0394/Startups/runs/tcqjqx3o' target=\"_blank\">Sixth Trail</a></strong> to <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">https://wandb.ai/ossm0394/Startups</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ossm0394/Startups/runs/tcqjqx3o' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/tcqjqx3o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ossm0394/Startups/runs/tcqjqx3o?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x782fe3d7c2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.fit(x = x_train_sc,y = y_train,epochs = 700,validation_data = (x_test_sc,y_test),callbacks = [WandbCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPeaWY_C_U1f",
        "outputId": "c47de228-7ce4-4017-8af8-6713151a8839"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.5845 - binary_accuracy: 0.6949 - false_negatives: 51.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 11s 123ms/step - loss: 0.5702 - binary_accuracy: 0.7058 - false_negatives: 62.0000 - val_loss: 0.3524 - val_binary_accuracy: 0.8522 - val_false_negatives: 6.0000\n",
            "Epoch 2/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.2310 - binary_accuracy: 0.9118 - false_negatives: 13.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 106ms/step - loss: 0.2324 - binary_accuracy: 0.9101 - false_negatives: 17.0000 - val_loss: 0.2152 - val_binary_accuracy: 0.9348 - val_false_negatives: 6.0000\n",
            "Epoch 3/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 0.1467 - binary_accuracy: 0.9306 - false_negatives: 16.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 104ms/step - loss: 0.1407 - binary_accuracy: 0.9348 - false_negatives: 20.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9696 - val_false_negatives: 5.0000\n",
            "Epoch 4/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0731 - binary_accuracy: 0.9724 - false_negatives: 7.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 135ms/step - loss: 0.0773 - binary_accuracy: 0.9739 - false_negatives: 8.0000 - val_loss: 0.0969 - val_binary_accuracy: 0.9739 - val_false_negatives: 3.0000\n",
            "Epoch 5/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0640 - binary_accuracy: 0.9779 - false_negatives: 4.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 137ms/step - loss: 0.0578 - binary_accuracy: 0.9783 - false_negatives: 6.0000 - val_loss: 0.0560 - val_binary_accuracy: 0.9913 - val_false_negatives: 2.0000\n",
            "Epoch 6/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0411 - binary_accuracy: 0.9841 - false_negatives: 4.0000 - val_loss: 0.0562 - val_binary_accuracy: 0.9870 - val_false_negatives: 3.0000\n",
            "Epoch 7/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.0326 - binary_accuracy: 0.9885 - false_negatives: 3.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 99ms/step - loss: 0.0309 - binary_accuracy: 0.9884 - false_negatives: 4.0000 - val_loss: 0.0340 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 8/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0165 - binary_accuracy: 0.9963 - false_negatives: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 104ms/step - loss: 0.0156 - binary_accuracy: 0.9971 - false_negatives: 1.0000 - val_loss: 0.0244 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 9/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0178 - binary_accuracy: 0.9942 - false_negatives: 3.0000 - val_loss: 0.0352 - val_binary_accuracy: 0.9913 - val_false_negatives: 2.0000\n",
            "Epoch 10/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0238 - binary_accuracy: 0.9982 - false_negatives: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 105ms/step - loss: 0.0193 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0232 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 11/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.0112 - binary_accuracy: 0.9984 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 141ms/step - loss: 0.0112 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0160 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 12/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0119 - binary_accuracy: 0.9957 - false_negatives: 1.0000 - val_loss: 0.0168 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 13/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.0073 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0193 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 14/700\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.0175 - binary_accuracy: 0.9942 - false_negatives: 2.0000 - val_loss: 0.0171 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 15/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.0091 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0334 - val_binary_accuracy: 0.9913 - val_false_negatives: 2.0000\n",
            "Epoch 16/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.0118 - binary_accuracy: 0.9957 - false_negatives: 1.0000 - val_loss: 0.0191 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 17/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 0.0053 - binary_accuracy: 0.9983 - false_negatives: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 133ms/step - loss: 0.0048 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0129 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 18/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 0.0077 - binary_accuracy: 0.9965 - false_negatives: 1.0000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 100ms/step - loss: 0.0069 - binary_accuracy: 0.9971 - false_negatives: 1.0000 - val_loss: 0.0108 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 19/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0081 - binary_accuracy: 0.9957 - false_negatives: 1.0000 - val_loss: 0.0139 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 20/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0103 - binary_accuracy: 0.9957 - false_negatives: 0.0000e+00 - val_loss: 0.0196 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 21/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.0099 - binary_accuracy: 0.9957 - false_negatives: 3.0000 - val_loss: 0.0132 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 22/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0047 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0206 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 23/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0047 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0263 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 24/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0029 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0290 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 25/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0251 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 26/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0023 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0257 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 27/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0036 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0280 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 28/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0101 - binary_accuracy: 0.9971 - false_negatives: 1.0000 - val_loss: 0.0303 - val_binary_accuracy: 0.9913 - val_false_negatives: 2.0000\n",
            "Epoch 29/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0217 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 30/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0229 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 31/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0214 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 32/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0251 - binary_accuracy: 0.9942 - false_negatives: 0.0000e+00 - val_loss: 0.0124 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 33/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0110 - binary_accuracy: 0.9971 - false_negatives: 1.0000 - val_loss: 0.0635 - val_binary_accuracy: 0.9783 - val_false_negatives: 3.0000\n",
            "Epoch 34/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0137 - binary_accuracy: 0.9957 - false_negatives: 1.0000 - val_loss: 0.0245 - val_binary_accuracy: 0.9913 - val_false_negatives: 2.0000\n",
            "Epoch 35/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.0088 - binary_accuracy: 0.9984 - false_negatives: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 88ms/step - loss: 0.0187 - binary_accuracy: 0.9957 - false_negatives: 3.0000 - val_loss: 0.0106 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 36/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0455 - val_binary_accuracy: 0.9870 - val_false_negatives: 1.0000\n",
            "Epoch 37/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0049 - binary_accuracy: 0.9971 - false_negatives: 0.0000e+00 - val_loss: 0.0106 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 38/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0086 - binary_accuracy: 0.9963 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 131ms/step - loss: 0.0077 - binary_accuracy: 0.9971 - false_negatives: 0.0000e+00 - val_loss: 0.0041 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 39/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0033 - binary_accuracy: 0.9982 - false_negatives: 1.0000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 138ms/step - loss: 0.0027 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 40/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 41/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0059 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 42/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0036 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0093 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 43/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.7336e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0051 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 44/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 7.4701e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0043 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 45/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0038 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 46/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0099 - binary_accuracy: 0.9971 - false_negatives: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 47/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0070 - binary_accuracy: 0.9982 - false_negatives: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 92ms/step - loss: 0.0057 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 2.9275e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 48/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.6322e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 49/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0032 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0146 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 50/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0369 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 51/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.3411e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0393 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 52/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0405 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 53/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.7322e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0399 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 54/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.0225e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0390 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 55/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0389 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 56/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.7338e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0377 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 57/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.4956e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0374 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 58/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0071 - binary_accuracy: 0.9957 - false_negatives: 1.0000 - val_loss: 0.0436 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 59/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0042 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0521 - val_binary_accuracy: 0.9913 - val_false_negatives: 2.0000\n",
            "Epoch 60/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0042 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0428 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 61/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.2618e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0459 - val_binary_accuracy: 0.9913 - val_false_negatives: 1.0000\n",
            "Epoch 62/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0022 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0407 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 63/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0050 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0418 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 64/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0056 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0371 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 65/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0069 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0369 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 66/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0016 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0465 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 67/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.6445e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0494 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 68/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0453 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 69/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0034 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0336 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 70/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0024 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0373 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 71/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0090 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 0.0335 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 72/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.0598e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0310 - val_binary_accuracy: 0.9913 - val_false_negatives: 1.0000\n",
            "Epoch 73/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0272 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 74/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0047 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0213 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 75/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.7643e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0192 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 76/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.4958e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0175 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 77/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.2623e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0182 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 78/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.5993e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0227 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 79/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0159 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 80/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 7.9819e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0160 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 81/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.5313e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0166 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 82/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.1653e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0182 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 83/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0218 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 84/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0254 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 85/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0519e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0222 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 86/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.9548e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0212 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 87/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.6584e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0203 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 88/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.1977e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0202 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 89/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.8656e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0200 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 90/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.4200e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0197 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 91/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0036 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 0.0161 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 92/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.0205e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0075 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 93/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0044 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 94/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0057 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0073 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 95/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.2185e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0116 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 96/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0179 - binary_accuracy: 0.9971 - false_negatives: 0.0000e+00 - val_loss: 0.0367 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 97/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0062 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 0.0126 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 98/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 6.9981e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0096 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 99/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0588e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0120 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 100/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.6433e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0130 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 101/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 7.3855e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0125 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 102/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.6892e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0126 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 103/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2250e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0123 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 104/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 3.8109e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0116 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 105/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 5.2150e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0111 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 106/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.9030e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0109 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 107/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0026 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0150 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 108/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0141 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 109/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8049e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0137 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 110/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0022 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0073 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 111/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.1865e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0063 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 112/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.7907e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0066 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 113/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0036 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0162 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 114/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 6.5198e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0187 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 115/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8220e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0190 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 116/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.4025e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0168 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 117/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.4196e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0142 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 118/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.1333e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0140 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 119/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.4397e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0141 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 120/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.4489e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0142 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 121/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0026 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0157 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 122/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0082 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 0.0210 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 123/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0028 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0197 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 124/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.0159e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0150 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 125/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0015 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0119 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 126/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.1169e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0101 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 127/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.1671e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0102 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 128/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.7689e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0114 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 129/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.1351e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0115 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 130/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 6.0632e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0121 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 131/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.4988e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0122 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 132/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.6131e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0125 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 133/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0017 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0137 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 134/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 7.5380e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0145 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 135/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.6506e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0146 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 136/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0060 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 0.0158 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 137/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0230 - binary_accuracy: 0.9942 - false_negatives: 0.0000e+00 - val_loss: 0.0128 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 138/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0044 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9957 - val_false_negatives: 0.0000e+00\n",
            "Epoch 139/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0054 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 140/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 3.7116e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0032 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 141/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 9.0846e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 142/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0034 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 0.0097 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 143/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3131e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0112 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 144/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.9574e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0116 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 145/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 9.6190e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0122 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 146/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.6903e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0135 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 147/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.7499e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0140 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 148/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.7392e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0137 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 149/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.1614e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0141 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 150/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.8693e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0141 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 151/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.5185e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0117 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 152/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1472e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0110 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 153/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1683e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0105 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 154/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2560e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0108 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 155/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 9.8583e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0107 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 156/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0093 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 157/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0038 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 158/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0133 - binary_accuracy: 0.9942 - false_negatives: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 159/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0046 - binary_accuracy: 0.9971 - false_negatives: 1.0000 - val_loss: 0.0166 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 160/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0058 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 5.9544e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 161/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.3453e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 162/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.6941e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.1420e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 163/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0059 - binary_accuracy: 0.9982 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 91ms/step - loss: 0.0047 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 3.7228e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 164/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 7.8364e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 108ms/step - loss: 6.2225e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0638e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 165/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.3927e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.3750e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 166/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.0077 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9957 - val_false_negatives: 0.0000e+00\n",
            "Epoch 167/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.0094 - binary_accuracy: 0.9957 - false_negatives: 0.0000e+00 - val_loss: 3.0801e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 168/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 3.2168e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 135ms/step - loss: 2.7242e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.7222e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 169/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0022 - binary_accuracy: 0.9982 - false_negatives: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 101ms/step - loss: 0.0017 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 1.4209e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 170/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.8878e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 101ms/step - loss: 1.7439e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2960e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 171/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 4.8102e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 116ms/step - loss: 4.6830e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2699e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 172/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0075 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 1.3118e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 173/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.9490e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 174/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0047 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 4.8435e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 175/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0016 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.3955e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 176/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4367e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 177/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8278e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.2383e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 178/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.0640e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.6900e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 179/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0308e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.9106e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 180/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.7818e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.7053e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 181/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 5.8175e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.7508e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 182/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.4349e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0157e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 183/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.0193e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3666e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 184/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 3.4773e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 124ms/step - loss: 3.1078e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.7760e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 185/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.2762e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 101ms/step - loss: 2.1079e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.2961e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 186/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 1.5098e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 101ms/step - loss: 1.4108e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.2768e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 187/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0598e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3045e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 188/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.5806e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.4464e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 189/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 2.0152e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 99ms/step - loss: 1.8725e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.0614e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 190/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.4288e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.1775e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 191/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 7.6844e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 116ms/step - loss: 6.8809e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8687e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 192/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 2.3986e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 159ms/step - loss: 2.4519e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.3846e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 193/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 2.3678e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 109ms/step - loss: 4.9582e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.9918e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 194/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 8.1215e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 110ms/step - loss: 8.5877e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.9374e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 195/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 3.2941e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 122ms/step - loss: 2.7903e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.9041e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 196/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.3220e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.4173e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 197/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8351e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5939e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 198/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0265e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.7766e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 199/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.4820e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5978e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 200/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.0513e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.3906e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 201/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.5886e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.3352e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 202/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.4413e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.4240e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 203/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1190e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.9021e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 204/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 7.5291e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.0958e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 205/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.0490e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.4441e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 206/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 6.0349e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.7651e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 207/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.0215e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.2342e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 208/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.5254e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.0001e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 209/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.5185e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.1504e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 210/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 2.0803e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3284e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 211/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.7767e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.1247e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 212/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8.5543e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.1020e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 213/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0024 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 6.6806e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 214/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.3232e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.1653e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 215/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 7.8890e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.9823e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 216/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 5.0420e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3574e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 217/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0908e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.3683e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 218/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.7887e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8798e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 219/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 2.6163e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 93ms/step - loss: 6.4180e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.5386e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 220/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 1.7789e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 100ms/step - loss: 2.8664e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.9912e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 221/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.4553e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0479e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 222/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 9.7611e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 119ms/step - loss: 9.2299e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.8616e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 223/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 5.5674e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 105ms/step - loss: 4.4052e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.8603e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 224/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 5.0295e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 143ms/step - loss: 4.4450e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.3146e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 225/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 4.4933e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 120ms/step - loss: 3.7569e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.0544e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 226/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.0024e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.1014e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 227/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0476e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.6637e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 228/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.9265e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.8082e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 229/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.1165e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.7359e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 230/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 9.4295e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.6655e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 231/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.6645e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.4608e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 232/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.6086e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.1538e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 233/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8497e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.0836e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 234/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.8570e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.1206e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 235/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.3582e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0737e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 236/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0020 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 2.8705e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 237/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1654e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.0496e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 238/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.9097e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.6125e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 239/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.5114e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.2989e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 240/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.3735e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.0958e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 241/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0042 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 4.2857e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 242/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0072 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 5.6694e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 243/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 9.1182e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.4621e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 244/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.3259e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.0505e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 245/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0811e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.7483e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 246/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.9327e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0023e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 247/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.1636e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.3234e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 248/700\n",
            "15/22 [===================>..........] - ETA: 0s - loss: 3.3253e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 92ms/step - loss: 2.8952e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.7909e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 249/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 5.6859e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 141ms/step - loss: 4.9226e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.5899e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 250/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.7917e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.6589e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 251/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 9.9754e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.6436e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 252/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.8295e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.6492e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 253/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.3210e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.6434e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 254/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 4.6595e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.6202e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 255/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.5794e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 256/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.9217e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.1039e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 257/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.4126e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.0732e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 258/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 7.6283e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 92ms/step - loss: 5.6901e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3856e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 259/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 4.6405e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 100ms/step - loss: 3.7295e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2503e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 260/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 2.7021e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 103ms/step - loss: 2.3334e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2272e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 261/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.3131e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 115ms/step - loss: 1.1893e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1360e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 262/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 4.5712e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 169ms/step - loss: 3.6944e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0659e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 263/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0080 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 2.1888e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 264/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.0081 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 1.9413e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 265/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.0198e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.3635e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 266/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6281e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.8176e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 267/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4579e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.9326e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 268/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 5.0149e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.9638e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 269/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7852e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0744e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 270/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8125e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.1027e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 271/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.1587e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0949e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 272/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0040e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.7706e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 273/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0021 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 2.0322e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 274/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.5871e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.1147e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 275/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.8560e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8960e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 276/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0115 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 6.2903e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 277/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8124e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4298e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 278/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 279/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.1987e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0070 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 280/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.5813e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0040 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 281/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2046e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0030 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 282/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.3781e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 283/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0723e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 284/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.0623e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 285/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.8076e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 286/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.1861e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 287/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.9770e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 288/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.8596e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 289/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 5.6542e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 290/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.4446e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.0859e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 291/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 3.0401e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.5118e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 292/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 2.3428e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.7162e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 293/700\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 1.0297e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.4553e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 294/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 5.8575e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.4355e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 295/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 2.4141e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.2590e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 296/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 1.9592e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.3648e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 297/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 5.5205e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.5240e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 298/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 4.2395e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.6189e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 299/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.4133e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.1045e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 300/700\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 2.7971e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.2667e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 301/700\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 8.7990e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.2777e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 302/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 2.2333e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.4999e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 303/700\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 1.2118e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.7408e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 304/700\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 8.3182e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.6430e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 305/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4812e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.1084e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 306/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.0196e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.3664e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 307/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.2687e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3011e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 308/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 8.5029e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.6589e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 309/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.6216e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.4946e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 310/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 5.2654e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 311/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.2269e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 312/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 3.9708e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0038 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 313/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 3.2104e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0037 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 314/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.2284e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 315/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.5820e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 316/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.7145e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 317/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.1471e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 318/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.1305e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 319/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0488e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0049 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 320/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.0305e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0049 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 321/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2757e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0046 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 322/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.0940e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0044 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 323/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.2473e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0043 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 324/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.3128e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0035 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 325/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.7559e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 326/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.6951e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.7421e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 327/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.7621e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.9760e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 328/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0086 - binary_accuracy: 0.9971 - false_negatives: 0.0000e+00 - val_loss: 1.8821e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 329/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0097 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 3.9696e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 330/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0014 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 91ms/step - loss: 0.0023 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 5.8934e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 331/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 3.1072e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 128ms/step - loss: 2.8608e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0959e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 332/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0109 - binary_accuracy: 0.9957 - false_negatives: 0.0000e+00 - val_loss: 1.1667e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 333/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0347 - binary_accuracy: 0.9928 - false_negatives: 5.0000 - val_loss: 2.0092e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 334/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0019 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.0789e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 335/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0031 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 1.7656e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 336/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.2107e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0250e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 337/700\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.9006e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.1764e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 338/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 5.9304e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.2307e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 339/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.7885e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.1450e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 340/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.7373e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.4514e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 341/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0082 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 9.1119e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 342/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0032 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 1.0337e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 343/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0085 - binary_accuracy: 0.9971 - false_negatives: 0.0000e+00 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 344/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 345/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3083e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0053 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 346/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.2776e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0040 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 347/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.2194e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 348/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.3394e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 349/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.8377e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 350/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.1139e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 351/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.8139e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 352/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.0325e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 353/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0618e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.8930e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 354/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3430e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5605e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 355/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.5930e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.7131e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 356/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.7097e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.9030e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 357/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.0248e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.7734e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 358/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.8463e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5357e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 359/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0080 - binary_accuracy: 0.9957 - false_negatives: 3.0000 - val_loss: 1.5960e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 360/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.9508e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.7222e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 361/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0039 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 3.3814e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 362/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.4443e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.1054e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 363/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.7724e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.6807e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 364/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 1.8326e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 365/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 6.6386e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0065e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 366/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.8019e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.4369e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 367/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.4719e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.4618e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 368/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.8899e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.2482e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 369/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1236e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.5607e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 370/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.8796e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.1298e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 371/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 8.9415e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.6707e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 372/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.9695e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.3364e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 373/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.7965e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.1115e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 374/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6560e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.9804e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 375/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1459e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.8756e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 376/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.6332e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.5617e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 377/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 4.6317e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 378/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.7000e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.0446e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 379/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.3924e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.6430e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 380/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.8386e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.9145e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 381/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.4590e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.3981e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 382/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0549e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0659e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 383/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.7509e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.7623e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 384/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3368e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.5875e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 385/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.4447e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.4218e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 386/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.4997e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.2322e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 387/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.2798e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.1657e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 388/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.0407e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.9631e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 389/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.6290e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.9622e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 390/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.7238e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8736e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 391/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.6265e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8250e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 392/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.2972e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.7592e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 393/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.9544e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.6628e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 394/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.5013e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.6071e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 395/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 4.7720e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3702e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 396/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.1381e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1641e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 397/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0996e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0928e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 398/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.8421e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0510e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 399/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 3.6484e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.6034e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 400/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.2586e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.2937e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 401/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.7300e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.7904e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 402/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.9505e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.0131e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 403/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.9130e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.9636e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 404/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.0094e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.5323e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 405/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4947e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.8857e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 406/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.6490e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.7068e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 407/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.6337e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.7560e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 408/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.0835e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.4580e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 409/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0635e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.4339e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 410/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.4751e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.4797e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 411/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.9935e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.0034e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 412/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.5687e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.9286e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 413/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.8802e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.9089e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 414/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.4538e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.7544e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 415/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1656e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.7884e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 416/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4746e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.6506e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 417/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3440e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.7725e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 418/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0034 - binary_accuracy: 0.9971 - false_negatives: 1.0000 - val_loss: 6.2850e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 419/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0057 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 1.0953e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 420/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.2792e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.2313e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 421/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 9.5568e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 422/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0020 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 1.9589e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 423/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0031 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 8.0853e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 424/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.9913e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.2470e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 425/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.4786e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0705e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 426/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.6271e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1519e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 427/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.1360e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1734e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 428/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0038 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 5.2134e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 429/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 3.3364e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.2745e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 430/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 6.2498e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.7988e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 431/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.0429e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5197e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 432/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.6638e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.6291e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 433/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2543e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.8011e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 434/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6878e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.4732e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 435/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.5663e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3862e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 436/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.6406e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.4808e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 437/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.0698e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.9029e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 438/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.6501e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.6039e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 439/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0927e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.7661e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 440/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.6803e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.6691e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 441/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.1024e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.6703e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 442/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.2536e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8678e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 443/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0026 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 3.3308e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 444/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.8102e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.0427e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 445/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.7334e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.1906e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 446/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.5778e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.3480e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 447/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 6.6205e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.4923e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 448/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0026 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 1.0395e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 449/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.9170e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.4085e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 450/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.1995e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3215e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 451/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 7.8293e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.6791e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 452/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.0011 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 105ms/step - loss: 9.3978e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0851e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 453/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.2103e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.3103e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 454/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.6679e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.3657e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 455/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 0.0024 - binary_accuracy: 0.9983 - false_negatives: 0.0000e+00    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 100ms/step - loss: 0.0020 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 2.9998e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 456/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.6059e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.1123e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 457/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 2.8416e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 106ms/step - loss: 7.3512e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.6776e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 458/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 7.5867e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 97ms/step - loss: 6.5549e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.3986e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 459/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.4267e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 129ms/step - loss: 4.7938e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.3405e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 460/700\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 1.3565e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 151ms/step - loss: 1.3320e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.2582e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 461/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 5.7951e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 101ms/step - loss: 5.0842e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.0808e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 462/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 2.5016e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 100ms/step - loss: 1.9793e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.7262e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 463/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 1.4562e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_152537-tcqjqx3o/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 119ms/step - loss: 1.2805e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.6937e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 464/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.9924e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.7460e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 465/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.3049e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.7806e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 466/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 8.1075e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.7936e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 467/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.3016e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8407e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 468/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.2967e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8432e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 469/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0315e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8358e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 470/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.0724e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8716e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 471/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 8.3155e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8358e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 472/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.2307e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8084e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 473/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3228e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.8287e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 474/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.5285e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.7982e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 475/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0149 - binary_accuracy: 0.9971 - false_negatives: 1.0000 - val_loss: 2.0166e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 476/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.0052 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 7.1559e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 477/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 1.7384e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.5067e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 478/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 6.3212e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.0528e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 479/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.3332e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 480/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 7.9606e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.6434e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 481/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 7.3340e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.0631e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 482/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 3.1623e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.1680e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 483/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.3769e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.4260e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 484/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 3.1939e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.6074e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 485/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0017 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 3.9786e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 486/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.2546e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.2720e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 487/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0836e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.3330e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 488/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.1708e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.9906e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 489/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.2490e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.2714e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 490/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 3.2523e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.4303e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 491/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 4.4954e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3346e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 492/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.2341e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8016e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 493/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.7382e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5861e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 494/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 3.3083e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.9533e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 495/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.1350e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.1335e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 496/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 3.5307e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.5359e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 497/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1119e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.1332e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 498/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.4328e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.1694e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 499/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.2118e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0983e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 500/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.1717e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0773e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 501/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.4884e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.2598e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 502/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.3965e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.0293e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 503/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0114 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 5.9928e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 504/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0026 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 4.6287e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 505/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0487e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.2821e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 506/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3641e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.3398e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 507/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.8941e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.4837e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 508/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 8.5372e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.7969e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 509/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5371e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 510/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3253e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 511/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.2777e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0035 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 512/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1704e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0037 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 513/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.9876e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0032 - val_binary_accuracy: 0.9957 - val_false_negatives: 1.0000\n",
            "Epoch 514/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.3044e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 3.1691e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 515/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.5020e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 2.1935e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 516/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0062 - binary_accuracy: 0.9971 - false_negatives: 2.0000 - val_loss: 2.7328e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 517/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.9735e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.3307e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 518/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.6213e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0041e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 519/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2737e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0504e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 520/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.7376e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.5813e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 521/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8959e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.7219e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 522/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1166e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.9409e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 523/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1118e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.3157e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 524/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0034 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 2.1690e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 525/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.8730e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 526/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.6210e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3466e-04 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 527/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 6.4108e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.8100e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 528/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.3851e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.2119e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 529/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 7.8446e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.7726e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 530/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.8480e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.1659e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 531/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.9758e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.9854e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 532/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.0804e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.1004e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 533/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 6.6028e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.6909e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 534/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 9.8149e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.1159e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 535/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.9521e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.6056e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 536/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 3.4561e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.4277e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 537/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4101e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.3202e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 538/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.0337e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.0043e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 539/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.2179e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.4984e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 540/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.3854e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.5416e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 541/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0241 - binary_accuracy: 0.9957 - false_negatives: 0.0000e+00 - val_loss: 3.9726e-05 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 542/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0162 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 7.7712e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 543/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6238e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.2788e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 544/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.1570e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.6806e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 545/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3711e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.5517e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 546/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.8730e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3401e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 547/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.1770e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.4726e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 548/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.2821e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.3082e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 549/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.2246e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.5810e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 550/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.3805e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.7575e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 551/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.9383e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 552/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.1447e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3808e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 553/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.9069e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2973e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 554/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.5098e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2800e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 555/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3431e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2804e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 556/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.8848e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3048e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 557/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.2495e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3005e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 558/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6288e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2972e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 559/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.6460e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2651e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 560/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.3150e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2329e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 561/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.2670e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1888e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 562/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0078e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3062e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 563/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.0165e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3241e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 564/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.9869e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3559e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 565/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6087e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3683e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 566/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.1463e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2375e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 567/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.6618e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1154e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 568/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0052 - binary_accuracy: 0.9986 - false_negatives: 0.0000e+00 - val_loss: 1.2290e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 569/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4843e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.9475e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 570/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 4.5555e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.6912e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 571/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4585e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 572/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3675e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.1764e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 573/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0159e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0010e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 574/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.3706e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0881e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 575/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.9574e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2076e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 576/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.4079e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3396e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 577/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.5256e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4374e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 578/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 5.6171e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4056e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 579/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.0236e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4201e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 580/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.4570e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.5350e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 581/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.2212e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4539e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 582/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.3407e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4503e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 583/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.6684e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4309e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 584/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 8.1163e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3528e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 585/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.4389e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1343e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 586/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.7991e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0631e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 587/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.1835e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0494e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 588/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.0621e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.9831e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 589/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.6333e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.8766e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 590/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.4347e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.4966e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 591/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.0503e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.7828e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 592/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.8294e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.6542e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 593/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.7916e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.1421e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 594/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2326e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.1196e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 595/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.8939e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.0193e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 596/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8967e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3918e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 597/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7519e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.5094e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 598/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0233e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.5053e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 599/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0779e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4167e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 600/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.3228e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.4017e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 601/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.0728e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.3546e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 602/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.9217e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2650e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 603/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.5667e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.9876e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 604/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 9.1205e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.0993e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 605/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.4529e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.7101e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 606/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1525e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.6093e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 607/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.3195e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.8580e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 608/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8636e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.4137e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 609/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0099 - binary_accuracy: 0.9986 - false_negatives: 1.0000 - val_loss: 7.2640e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 610/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.0094e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.5785e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 611/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1107e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.8432e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 612/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2067e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.8987e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 613/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.5335e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.8918e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 614/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 7.5763e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.9475e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 615/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1521e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.9227e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 616/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.6069e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.3253e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 617/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.8399e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.4275e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 618/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.0779e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.4643e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 619/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.8347e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.7585e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 620/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.2289e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0418e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 621/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 8.1801e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0865e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 622/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.1115e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0132e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 623/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1784e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.9196e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 624/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1976e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 8.9196e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 625/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1042e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.3343e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 626/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.4063e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.4244e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 627/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6696e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.3251e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 628/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.1970e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.0245e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 629/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1330e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1595e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 630/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.8600e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1922e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 631/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.2204e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1964e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 632/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0328e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1693e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 633/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.5512e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1865e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 634/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.6657e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1522e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 635/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.2750e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1299e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 636/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3353e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1864e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 637/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0477e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1681e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 638/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.9092e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1911e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 639/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.6807e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1342e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 640/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.6329e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1087e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 641/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.0303e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1643e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 642/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.8211e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1675e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 643/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 4.3828e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1816e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 644/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.3460e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1457e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 645/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.8262e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1576e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 646/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.8990e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.1523e-06 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 647/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 5.7619e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 9.8810e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 648/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.9980e-04 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.9140e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 649/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.7494e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.6300e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 650/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 5.9437e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.3943e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 651/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 6.0574e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.0110e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 652/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.3968e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.9838e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 653/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.5560e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.0601e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 654/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.9560e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.1280e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 655/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1422e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.1839e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 656/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4543e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.8939e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 657/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1303e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.6321e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 658/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0025e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.4503e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 659/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.1667e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.0517e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 660/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.6371e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.9102e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 661/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.2656e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.0342e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 662/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.7017e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.1481e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 663/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.5735e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.2450e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 664/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.0055e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.2175e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 665/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.5352e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.3007e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 666/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.1243e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.3665e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 667/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0945e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.3291e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 668/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.4097e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.6017e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 669/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8230e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.5645e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 670/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.3844e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.3847e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 671/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 7.2617e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 6.6723e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 672/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 5.8938e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.0281e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 673/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.7769e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.5742e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 674/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.1145e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.2777e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 675/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8.3297e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 7.2059e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 676/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.0399e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.4601e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 677/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.5934e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3828e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 678/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.3961e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3571e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 679/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 6.9767e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.3249e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 680/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.2001e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 5.1078e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 681/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0875e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8475e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 682/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1278e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.6010e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 683/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.0294e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8303e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 684/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.1751e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.9413e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 685/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 5.9607e-07 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5546e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 686/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.2552e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.6036e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 687/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.8830e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.7563e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 688/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.2426e-07 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5967e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 689/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.4080e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.3417e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 690/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2015e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.5977e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 691/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.7145e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8237e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 692/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.2938e-05 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8144e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 693/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1944e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8492e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 694/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 5.2502e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8892e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 695/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 4.9276e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.9761e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 696/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.3309e-07 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.9447e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 697/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.7066e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8812e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 698/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.9433e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.9250e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 699/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.4833e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.8596e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n",
            "Epoch 700/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 5.2852e-06 - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 4.9333e-07 - val_binary_accuracy: 1.0000 - val_false_negatives: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x782fe3d7ff40>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(model6.history.history)[['loss','val_loss']].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "sqjJTejIDniz",
        "outputId": "8f4d2414-26dd-4060-95dd-dcf5fd853e9e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = Sequential()"
      ],
      "metadata": {
        "id": "MkzMyq3_CP92"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model7.add(Dense(units=35,activation='relu',kernel_initializer='GlorotNormal'))\n",
        "\n",
        "model7.add(Dense(units=100,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model7.add(Dropout(0.2))\n",
        "\n",
        "model7.add(BatchNormalization())\n",
        "\n",
        "model7.add(Dense(units=150,activation='relu',kernel_initializer='he_normal'))\n",
        "\n",
        "model7.add(Dropout(0.2))\n",
        "\n",
        "model7.add(BatchNormalization())\n",
        "\n",
        "model7.add(Dense(units=200,activation='relu',kernel_initializer='GlorotNormal'))\n",
        "\n",
        "model7.add(Dropout(0.2))\n",
        "\n",
        "model7.add(BatchNormalization())\n",
        "\n",
        "model7.add(Dense(units=1,activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "ePl8YEr0_faZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model7.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
        "              tf.keras.metrics.FalseNegatives()])"
      ],
      "metadata": {
        "id": "VLK0FTnwBneS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = 'Startups',name = 'Seventh Trail')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "NGIP_ckZCzla",
        "outputId": "5199f230-a93e-4f7b-e07a-de298d7d6f71"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:tcqjqx3o) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>binary_accuracy</td><td>▁████▁███▁███████████████▅██████▅███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>false_negatives</td><td>▅▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▇▂▂▁▁█▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▃▁▁▁▁▁▁▁</td></tr><tr><td>val_binary_accuracy</td><td>▅▅█▅▁▅▅▅▅█████████▅██████████▅██████████</td></tr><tr><td>val_false_negatives</td><td>██▁██████▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▆▆▂█▇█▂▃▃▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>462</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>binary_accuracy</td><td>1.0</td></tr><tr><td>epoch</td><td>699</td></tr><tr><td>false_negatives</td><td>0.0</td></tr><tr><td>loss</td><td>1e-05</td></tr><tr><td>val_binary_accuracy</td><td>1.0</td></tr><tr><td>val_false_negatives</td><td>0.0</td></tr><tr><td>val_loss</td><td>0.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Sixth Trail</strong> at: <a href='https://wandb.ai/ossm0394/Startups/runs/tcqjqx3o' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/tcqjqx3o</a><br/>Synced 5 W&B file(s), 1 media file(s), 270 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231002_152537-tcqjqx3o/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:tcqjqx3o). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231002_154023-wke2j8mw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ossm0394/Startups/runs/wke2j8mw' target=\"_blank\">Seventh Trail</a></strong> to <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ossm0394/Startups' target=\"_blank\">https://wandb.ai/ossm0394/Startups</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ossm0394/Startups/runs/wke2j8mw' target=\"_blank\">https://wandb.ai/ossm0394/Startups/runs/wke2j8mw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ossm0394/Startups/runs/wke2j8mw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x782fb6ea0c70>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.fit(x = x_train_sc,y = y_train,epochs = 700,validation_data = (x_test_sc,y_test),callbacks = [WandbCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PUCEcXRDDIE",
        "outputId": "15cf0a9f-7131-4dfb-ba4e-51c96b9569ae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 0.7207 - binary_accuracy: 0.6211 - false_negatives_1: 68.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 8s 108ms/step - loss: 0.6499 - binary_accuracy: 0.6710 - false_negatives_1: 79.0000 - val_loss: 0.4586 - val_binary_accuracy: 0.8522 - val_false_negatives_1: 30.0000\n",
            "Epoch 2/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 0.4037 - binary_accuracy: 0.8125 - false_negatives_1: 33.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 109ms/step - loss: 0.3838 - binary_accuracy: 0.8290 - false_negatives_1: 46.0000 - val_loss: 0.3225 - val_binary_accuracy: 0.9000 - val_false_negatives_1: 21.0000\n",
            "Epoch 3/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.2482 - binary_accuracy: 0.8915 - false_negatives_1: 27.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 120ms/step - loss: 0.2425 - binary_accuracy: 0.8942 - false_negatives_1: 31.0000 - val_loss: 0.2228 - val_binary_accuracy: 0.9087 - val_false_negatives_1: 20.0000\n",
            "Epoch 4/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 0.1747 - binary_accuracy: 0.9392 - false_negatives_1: 14.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 104ms/step - loss: 0.1799 - binary_accuracy: 0.9362 - false_negatives_1: 19.0000 - val_loss: 0.1625 - val_binary_accuracy: 0.9391 - val_false_negatives_1: 13.0000\n",
            "Epoch 5/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.9622 - false_negatives_1: 8.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 162ms/step - loss: 0.1073 - binary_accuracy: 0.9623 - false_negatives_1: 11.0000 - val_loss: 0.1255 - val_binary_accuracy: 0.9391 - val_false_negatives_1: 13.0000\n",
            "Epoch 6/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0930 - binary_accuracy: 0.9652 - false_negatives_1: 12.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 105ms/step - loss: 0.0930 - binary_accuracy: 0.9652 - false_negatives_1: 12.0000 - val_loss: 0.0864 - val_binary_accuracy: 0.9609 - val_false_negatives_1: 9.0000\n",
            "Epoch 7/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.0724 - binary_accuracy: 0.9786 - false_negatives_1: 4.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 119ms/step - loss: 0.0693 - binary_accuracy: 0.9783 - false_negatives_1: 5.0000 - val_loss: 0.0688 - val_binary_accuracy: 0.9652 - val_false_negatives_1: 8.0000\n",
            "Epoch 8/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0476 - binary_accuracy: 0.9826 - false_negatives_1: 4.0000 - val_loss: 0.0724 - val_binary_accuracy: 0.9696 - val_false_negatives_1: 7.0000\n",
            "Epoch 9/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0257 - binary_accuracy: 0.9971 - false_negatives_1: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 105ms/step - loss: 0.0257 - binary_accuracy: 0.9971 - false_negatives_1: 1.0000 - val_loss: 0.0525 - val_binary_accuracy: 0.9783 - val_false_negatives_1: 5.0000\n",
            "Epoch 10/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 0.0291 - binary_accuracy: 0.9961 - false_negatives_1: 2.0000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 104ms/step - loss: 0.0328 - binary_accuracy: 0.9928 - false_negatives_1: 3.0000 - val_loss: 0.0427 - val_binary_accuracy: 0.9826 - val_false_negatives_1: 4.0000\n",
            "Epoch 11/700\n",
            "15/22 [===================>..........] - ETA: 0s - loss: 0.0430 - binary_accuracy: 0.9875 - false_negatives_1: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 144ms/step - loss: 0.0326 - binary_accuracy: 0.9913 - false_negatives_1: 1.0000 - val_loss: 0.0327 - val_binary_accuracy: 0.9826 - val_false_negatives_1: 4.0000\n",
            "Epoch 12/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0203 - binary_accuracy: 0.9942 - false_negatives_1: 2.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 126ms/step - loss: 0.0203 - binary_accuracy: 0.9942 - false_negatives_1: 2.0000 - val_loss: 0.0248 - val_binary_accuracy: 0.9913 - val_false_negatives_1: 2.0000\n",
            "Epoch 13/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 0.0235 - binary_accuracy: 0.9931 - false_negatives_1: 4.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 125ms/step - loss: 0.0219 - binary_accuracy: 0.9942 - false_negatives_1: 4.0000 - val_loss: 0.0204 - val_binary_accuracy: 0.9913 - val_false_negatives_1: 2.0000\n",
            "Epoch 14/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0221 - binary_accuracy: 0.9942 - false_negatives_1: 1.0000 - val_loss: 0.0216 - val_binary_accuracy: 0.9913 - val_false_negatives_1: 2.0000\n",
            "Epoch 15/700\n",
            "15/22 [===================>..........] - ETA: 0s - loss: 0.0152 - binary_accuracy: 0.9979 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 105ms/step - loss: 0.0136 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0199 - val_binary_accuracy: 0.9913 - val_false_negatives_1: 2.0000\n",
            "Epoch 16/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0092 - binary_accuracy: 0.9982 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 103ms/step - loss: 0.0080 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0112 - val_binary_accuracy: 0.9913 - val_false_negatives_1: 2.0000\n",
            "Epoch 17/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0245 - binary_accuracy: 0.9899 - false_negatives_1: 3.0000 - val_loss: 0.0115 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 18/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 0.0054 - binary_accuracy: 0.9983 - false_negatives_1: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 127ms/step - loss: 0.0071 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 19/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 0.0108 - binary_accuracy: 0.9934 - false_negatives_1: 2.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 148ms/step - loss: 0.0127 - binary_accuracy: 0.9928 - false_negatives_1: 3.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 20/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0045 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0094 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 21/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0021 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0098 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 22/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0075 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0100 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 23/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0148 - binary_accuracy: 0.9957 - false_negatives_1: 2.0000 - val_loss: 0.0116 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 24/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0073 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0151 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 25/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0031 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0151 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 26/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0083 - binary_accuracy: 0.9971 - false_negatives_1: 1.0000 - val_loss: 0.0156 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 27/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0169 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 28/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0056 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0182 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 29/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0100 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0156 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 30/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0132 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 0.0110 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 31/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0146 - binary_accuracy: 0.9942 - false_negatives_1: 1.0000 - val_loss: 0.0102 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 32/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0035 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0101 - val_binary_accuracy: 0.9913 - val_false_negatives_1: 2.0000\n",
            "Epoch 33/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0079 - binary_accuracy: 0.9971 - false_negatives_1: 1.0000 - val_loss: 0.0157 - val_binary_accuracy: 0.9913 - val_false_negatives_1: 2.0000\n",
            "Epoch 34/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0183 - val_binary_accuracy: 0.9913 - val_false_negatives_1: 2.0000\n",
            "Epoch 35/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0081 - binary_accuracy: 0.9971 - false_negatives_1: 1.0000 - val_loss: 0.0177 - val_binary_accuracy: 0.9913 - val_false_negatives_1: 2.0000\n",
            "Epoch 36/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0033 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0156 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 37/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0154 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 38/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0040 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0127 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 39/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0060 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0168 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 40/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0179 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 41/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0043 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0182 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 42/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0181 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 43/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0031 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0220 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 44/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0216 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 45/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0096 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 0.0246 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 46/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0029 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0266 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 47/700\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0262 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 48/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0028 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0252 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 49/700\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.0025 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0199 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 50/700\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0203 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 51/700\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.0021 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0207 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 52/700\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.0076 - binary_accuracy: 0.9971 - false_negatives_1: 0.0000e+00 - val_loss: 0.0209 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 53/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.0030 - binary_accuracy: 0.9971 - false_negatives_1: 1.0000 - val_loss: 0.0309 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 54/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0129 - binary_accuracy: 0.9942 - false_negatives_1: 4.0000 - val_loss: 0.0322 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 55/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0333 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 56/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0323 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 57/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0016 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0311 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 58/700\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.0045 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0330 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 59/700\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 5.0774e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0333 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 60/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 1.9598e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0333 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 61/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0329 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 62/700\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.0051 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0327 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 63/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0021 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0302 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 64/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 5.4802e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0303 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 65/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 8.5306e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0309 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 66/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0300 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 67/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 2.5548e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0292 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 68/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0027 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0279 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 69/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 4.1870e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0270 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 70/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.7371e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0271 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 71/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0282 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 72/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 2.6192e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0285 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 73/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 4.3491e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0284 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 74/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.4256e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0281 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 75/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.0128 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0302 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 76/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0017 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0478 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 77/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0109 - binary_accuracy: 0.9957 - false_negatives_1: 2.0000 - val_loss: 0.0354 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 78/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0019 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0174 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 79/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0060 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0112 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 80/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0024 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0092 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 81/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0020 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0135 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 82/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 3.5677e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0150 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 83/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6076e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0154 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 84/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.9822e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0160 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 85/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 7.3427e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0148 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 86/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 5.6399e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0144 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 87/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0018 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0166 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 88/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.0026 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0163 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 89/700\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 1.1792e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0092 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 90/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0101 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 91/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.2913e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0104 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 92/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 2.3979e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0103 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 93/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0017 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0102 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 94/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0111 - binary_accuracy: 0.9957 - false_negatives_1: 3.0000 - val_loss: 0.0150 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 95/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0140 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 96/700\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 6.4877e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0131 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 97/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7627e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0123 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 98/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0604e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0119 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 99/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.2237e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0109 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 100/700\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.0035 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0091 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 101/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 2.4210e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 126ms/step - loss: 2.2666e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0074 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 102/700\n",
            "19/22 [========================>.....] - ETA: 0s - loss: 4.9593e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 123ms/step - loss: 6.7768e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0070 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 103/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 3.0542e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 124ms/step - loss: 3.3060e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 104/700\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0089 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 208ms/step - loss: 0.0089 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 105/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0082 - binary_accuracy: 0.9963 - false_negatives_1: 0.0000e+00    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 116ms/step - loss: 0.0065 - binary_accuracy: 0.9971 - false_negatives_1: 0.0000e+00 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 106/700\n",
            "18/22 [=======================>......] - ETA: 0s - loss: 7.6280e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 101ms/step - loss: 6.4680e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 107/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0028 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 108/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8013e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 109/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0039 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 110/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 111/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 4.2640e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0032 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 112/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.9418e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 113/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6716e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 114/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.7374e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 115/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.5865e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 116/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 117/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.1903e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 118/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0106 - binary_accuracy: 0.9963 - false_negatives_1: 2.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 86ms/step - loss: 0.0084 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 119/700\n",
            "20/22 [==========================>...] - ETA: 0s - loss: 9.8452e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 158ms/step - loss: 9.3574e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 120/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 3.5799e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 117ms/step - loss: 4.0422e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.2976e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 121/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 3.3450e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 103ms/step - loss: 2.8103e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 5.7250e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 122/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0039 - binary_accuracy: 0.9982 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 101ms/step - loss: 0.0031 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 3.5088e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 123/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 0.0017 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 99ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.1355e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 124/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 3.6959e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 3s 148ms/step - loss: 3.2784e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.8002e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 125/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0028 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 8.0627e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 126/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 1.9957e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 127/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0012 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 128/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0016 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 129/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0550e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0046 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 130/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8490e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0049 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 131/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.4013e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0044 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 132/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0054 - binary_accuracy: 0.9971 - false_negatives_1: 0.0000e+00 - val_loss: 0.0043 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 133/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0024 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 134/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.9847e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 135/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0024 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 136/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.7550e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0164 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 137/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0243e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0191 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 138/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.9180e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0172 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 139/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.6972e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0163 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 140/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0943e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0169 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 141/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.5216e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0183 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 142/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1724e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0197 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 143/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.0736e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0198 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 144/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0081 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0235 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 145/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.4807e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0259 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 146/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.5290e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0255 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 147/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6628e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0245 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 148/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0124 - binary_accuracy: 0.9942 - false_negatives_1: 0.0000e+00 - val_loss: 0.0211 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 149/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.4015e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0096 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 150/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0102 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 151/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0068 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 0.0206 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 152/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0045 - binary_accuracy: 0.9971 - false_negatives_1: 0.0000e+00 - val_loss: 0.0232 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 153/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0065 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 0.0247 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 154/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0192 - binary_accuracy: 0.9957 - false_negatives_1: 0.0000e+00 - val_loss: 0.0205 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 155/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0029 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0248 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 156/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8340e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0251 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 157/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7997e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0259 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 158/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.7293e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0260 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 159/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8830e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0276 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 160/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.9747e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0278 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 161/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.0040e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0280 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 162/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.1372e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0282 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 163/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.9065e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0270 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 164/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.8555e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0265 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 165/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.3344e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0268 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 166/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.9360e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0270 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 167/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0040 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0235 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 168/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0030 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0209 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 169/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0221 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 170/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.2457e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0221 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 171/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.9207e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0218 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 172/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7197e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0187 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 173/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.7167e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0179 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 174/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 5.1766e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0176 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 175/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0020 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0200 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 176/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.1896e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0208 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 177/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.6228e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0204 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 178/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 3.4262e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0210 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 179/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.5615e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0213 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 180/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.7272e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0216 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 181/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.5821e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0263 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 182/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.4412e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0267 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 183/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.1613e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0267 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 184/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.9487e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0267 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 185/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.8680e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0277 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 186/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.2203e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0279 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 187/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.6480e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0245 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 188/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.2451e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0238 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 189/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3681e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0229 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 190/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.1195e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0225 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 191/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.9989e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0219 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 192/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.1059e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0215 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 193/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.9225e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0224 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 194/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4942e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0226 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 195/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.4713e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0229 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 196/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.1356e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0232 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 197/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6181e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0232 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 198/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.6072e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0229 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 199/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.6669e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0227 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 200/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.9329e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0228 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 201/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0287 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 202/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.4417e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0285 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 203/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1355e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0271 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 204/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.5134e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0280 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 205/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.1734e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0288 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 206/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.3290e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0294 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 207/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.4628e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0292 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 208/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.6669e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0297 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 209/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0036 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 0.0311 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 210/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.2867e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0314 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 211/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.4646e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0302 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 212/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.5076e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0296 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 213/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.0037e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0262 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 214/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.3251e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0253 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 215/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 3.3867e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0251 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 216/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3683e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0255 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 217/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.8393e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0258 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 218/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0066 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0307 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 219/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.8013e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0326 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 220/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.8618e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0455 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 221/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.5220e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0479 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 222/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0675e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0484 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 223/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.4871e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0486 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 224/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 9.7834e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0486 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 225/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.5055e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0484 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 226/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.0461e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0474 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 227/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0439 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 228/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0117 - binary_accuracy: 0.9971 - false_negatives_1: 0.0000e+00 - val_loss: 0.0386 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 229/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.4271e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0100 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 230/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0029 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0079 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 231/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0070 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 0.0257 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 232/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 7.7841e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0310 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 233/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.4695e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0330 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 234/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 6.9972e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0314 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 235/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.6925e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0310 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 236/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.6610e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0302 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 237/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.4803e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0298 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 238/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 2.1784e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0299 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 239/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.7332e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0298 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 240/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 8.0537e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0288 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 241/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.6224e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0287 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 242/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0033 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0298 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 243/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6032e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0311 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 244/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.6712e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0296 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 245/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.7540e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0265 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 246/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.3929e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0240 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 247/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.9077e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0232 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 248/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.4535e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0243 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 249/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 6.8518e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0247 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 250/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 9.2619e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0239 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 251/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0021 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0256 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 252/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6695e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0265 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 253/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.5207e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0264 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 254/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.3151e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0263 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 255/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.1637e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0258 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 256/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.2572e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0263 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 257/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.0266e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0258 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 258/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.0477e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0255 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 259/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.9030e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0226 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 260/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8895e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0208 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 261/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.4764e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0203 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 262/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.1544e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0203 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 263/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.2617e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0203 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 264/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0332e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0191 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 265/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.6774e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0184 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 266/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.2053e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0176 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 267/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0017 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0170 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 268/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.8579e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0092 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 269/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.5191e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0085 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 270/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0034 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0127 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 271/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0033 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0158 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 272/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2948e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0308 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 273/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0110 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0298 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 274/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2093e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 275/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.1092e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.3720e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 276/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6934e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.2934e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 277/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 8.1517e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0044 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 278/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0043 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 279/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3420e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0035 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 280/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0817e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0037 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 281/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 5.8534e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0035 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 282/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0526e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 283/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.2074e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 284/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0016 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0046 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 285/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.4352e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 286/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0043 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 287/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.2092e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 288/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.2466e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 289/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.0937e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0038 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 290/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.2688e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 291/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0018 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 292/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 5.7771e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 293/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.7380e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 294/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 2.4769e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0040 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 295/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0031 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 296/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.4501e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0055 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 297/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0018 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0111 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 298/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 5.9889e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0121 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 299/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.5377e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0301 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 300/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0280 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 301/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.0525e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0238 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 302/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.2185e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0233 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 303/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.4674e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0232 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 304/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.2331e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0227 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 305/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.0438e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0220 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 306/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.7260e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0214 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 307/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0035 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 308/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.9374e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 5.6508e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 309/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.3408e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.8240e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 310/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.4839e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.8758e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 311/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.5385e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 5.0677e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 312/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.7764e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 5.7495e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 313/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.2035e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.8086e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 314/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.8141e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.8305e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 315/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.4054e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.7087e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 316/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0828e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 317/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1298e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 318/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.3568e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 319/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.3139e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 320/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.5688e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.5203e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 321/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.3186e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.6473e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 322/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.2418e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.9977e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 323/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.4474e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.4609e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 324/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.1896e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 325/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 7.3692e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 326/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0164 - binary_accuracy: 0.9971 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 327/700\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 3.1904e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 328/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0173 - binary_accuracy: 0.9942 - false_negatives_1: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 329/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0053 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 0.0088 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 330/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0034 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0153 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 331/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0062 - binary_accuracy: 0.9957 - false_negatives_1: 3.0000 - val_loss: 0.0156 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 332/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.7823e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0093 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 333/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.3928e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0086 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 334/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.7579e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0081 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 335/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0103e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0082 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 336/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.7425e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0086 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 337/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.6713e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0063 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 338/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.6988e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0059 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 339/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0109 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 340/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.4953e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0118 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 341/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.8633e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0127 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 342/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.2402e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0124 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 343/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0049 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0120 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 344/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.4076e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0089 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 345/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.2780e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0093 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 346/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.9532e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0096 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 347/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.3612e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0112 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 348/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.4573e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0114 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 349/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 7.7733e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0106 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 350/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.1727e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0092 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 351/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0100 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 352/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.7865e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0119 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 353/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.0669e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0123 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 354/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0020 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0121 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 355/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.1482e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0073 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 356/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.7839e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0072 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 357/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0103e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0076 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 358/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.5131e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0076 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 359/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4842e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0081 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 360/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0024 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0054 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 361/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.7048e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0045 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 362/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.2264e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0044 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 363/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.3059e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0041 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 364/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.6006e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0032 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 365/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6391e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 366/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.6406e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 367/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.6377e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0032 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 368/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.1764e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 369/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8781e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 370/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.1861e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 371/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.3049e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0033 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 372/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.1473e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0035 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 373/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 9.4644e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0057 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 374/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.7986e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0059 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 375/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.7724e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0058 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 376/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 6.8173e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0057 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 377/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 8.4564e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0053 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 378/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0874e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0053 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 379/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0178e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0052 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 380/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8276e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 381/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3284e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 382/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.7074e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0047 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 383/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.5461e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0052 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 384/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.1360e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0065 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 385/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.4145e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0062 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 386/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7563e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0060 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 387/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.7548e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0058 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 388/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.6458e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0055 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 389/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.3024e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0051 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 390/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0139e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0051 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 391/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.2669e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0062 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 392/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1443e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0067 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 393/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.2483e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0065 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 394/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.7537e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0065 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 395/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.1347e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0060 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 396/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.3420e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0062 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 397/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.0622e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0060 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 398/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 6.2593e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0058 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 399/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 5.3133e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0057 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 400/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.9324e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0056 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 401/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 7.6386e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0057 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 402/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.5678e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0056 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 403/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.2577e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0043 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 404/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 6.8815e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0040 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 405/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.6023e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0040 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 406/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.0594e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 407/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.6801e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 408/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.5242e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 409/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0347e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 410/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.2825e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 411/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.6608e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0033 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 412/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.4033e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 413/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0192 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 414/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.7120e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 415/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0078 - binary_accuracy: 0.9957 - false_negatives_1: 1.0000 - val_loss: 6.3211e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 416/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.5477e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.2731e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 417/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2776e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 418/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.1301e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 419/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 6.2748e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 420/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.0856e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 421/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.4705e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0031 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 422/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0977e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0037 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 423/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.8621e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0045 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 424/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 5.3490e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0045 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 425/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.6835e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0042 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 426/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 427/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.6422e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 428/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.7145e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0033 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 429/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.0858e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 430/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.3390e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0065 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 431/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.6523e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0070 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 432/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6074e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0069 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 433/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0023 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0115 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 434/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0098 - binary_accuracy: 0.9971 - false_negatives_1: 0.0000e+00 - val_loss: 0.0099 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 435/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0017 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 436/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.6497e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.7336e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 437/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.9557e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.5535e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 438/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.9735e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.9071e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 439/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.0496e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.0757e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 440/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1014e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.2963e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 441/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.9138e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.2622e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 442/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0030 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 443/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1481e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0093 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 444/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0059 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 6.6730e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 445/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 6.7264e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.4040e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 446/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.3445e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.6556e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 447/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.9133e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.5999e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 448/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.1170e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.9141e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 449/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0080 - binary_accuracy: 0.9971 - false_negatives_1: 0.0000e+00 - val_loss: 0.0058 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 450/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0811e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0083 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 451/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 2.5495e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0088 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 452/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0013 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 453/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.3922e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0101 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 454/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.9199e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0096 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 455/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.1818e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0092 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 456/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.9337e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0093 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 457/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.0022e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0089 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 458/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.4091e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0087 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 459/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0029 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 460/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.3450e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0044 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 461/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.1510e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0038 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 462/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.1347e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0041 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 463/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 6.0482e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0037 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 464/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.3652e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0039 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 465/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 8.5479e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0039 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 466/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.3777e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0038 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 467/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3706e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0046 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 468/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.9434e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0048 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 469/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.1762e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0047 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 470/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.2675e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 471/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.8831e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0048 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 472/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.9072e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0058 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 473/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.2792e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0061 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 474/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0091 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 475/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0044 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 476/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.9483e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.8388e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 477/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.3615e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 5.0493e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 478/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.3617e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.0253e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 479/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.5598e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.5301e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 480/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.7877e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.3783e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 481/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 3.1198e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.9161e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 482/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.8127e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.7361e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 483/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.6932e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.4912e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 484/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0017 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 5.9617e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 485/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0046 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 486/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3862e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0065 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 487/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.7897e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0069 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 488/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.2267e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0065 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 489/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4912e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0067 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 490/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.2173e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0070 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 491/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.7296e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0069 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 492/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7478e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0073 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 493/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.8272e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0071 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 494/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.2225e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0051 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 495/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.4361e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0052 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 496/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3467e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0047 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 497/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.4487e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0046 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 498/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2103e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0049 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 499/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0057 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 500/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 9.7901e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0054 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 501/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.8173e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 502/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 5.7622e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 503/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.5520e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 504/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.1803e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 505/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.5465e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 506/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0050 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 507/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.4952e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 508/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.5173e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 509/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 6.4028e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 510/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0117 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 511/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.3867e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 512/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.2988e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 513/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.5901e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 514/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 1.8909e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 515/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.6161e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 516/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.3866e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 517/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0020 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 518/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 7.4126e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 519/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0753e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 520/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.6521e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.8353e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 521/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 4.1935e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.8991e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 522/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.8001e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.5735e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 523/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0176e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.8601e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 524/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.2453e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 525/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 6.7257e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 526/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.0622e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 527/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2871e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 528/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.1353e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 529/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.7956e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 530/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.6110e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 531/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.3467e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 532/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.9776e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 533/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.3669e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 534/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.7880e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 535/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.9385e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 536/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 8.7567e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 537/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1121e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 538/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.5900e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 539/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.3049e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 540/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.9639e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 541/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.3346e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 542/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1688e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.9243e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 543/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.1456e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 544/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.9667e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.8594e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 545/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 7.2269e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 546/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.5164e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 547/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7593e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 548/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1533e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.2381e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 549/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8.6829e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.1664e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 550/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.2454e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.2588e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 551/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.8260e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.0549e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 552/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.9073e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.6657e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 553/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.1229e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.2136e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 554/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.5012e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 7.3045e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 555/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.9069e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 7.3813e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 556/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.0350e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.0428e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 557/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.4376e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 7.4600e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 558/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.5095e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.1638e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 559/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.6045e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 5.5526e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 560/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 5.5646e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 5.9138e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 561/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 2.7461e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.1052e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 562/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.3421e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.6249e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 563/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 5.0738e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 7.6841e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 564/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 7.5118e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 7.4427e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 565/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.5877e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 7.7695e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 566/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.4061e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 7.9283e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 567/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 8.5063e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.0495e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 568/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6.8630e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.5544e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 569/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 6.2597e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.8163e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 570/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 9.5061e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.0563e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 571/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 5.6395e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 572/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.3980e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 573/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 5.2902e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 574/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.5155e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 575/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 8.6637e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 576/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.0491e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 577/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.0942e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 578/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.1573e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 579/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 5.6294e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 580/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.2796e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 581/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.3140e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 582/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.2086e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 583/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.0415e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 584/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.0495e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 585/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 3.3604e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 586/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.1363e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 587/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.6710e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 588/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.7061e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 589/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.0389e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.8353e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 590/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 2.0480e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.5664e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 591/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1464e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.3212e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 592/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0996e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 593/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.7155e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 594/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.2788e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 3.0168e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 595/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 3.8646e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 97ms/step - loss: 3.2659e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.6535e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 596/700\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0120 - binary_accuracy: 0.9971 - false_negatives_1: 0.0000e+00 - val_loss: 2.9522e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 597/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.1617e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.2961e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 598/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.2376e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.0287e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 599/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.2977e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.1229e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 600/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.3763e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.2030e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 601/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 602/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.6198e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 603/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.9219e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 604/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 7.9225e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 605/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.7998e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 606/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.8188e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 607/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.9677e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 608/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 5.3420e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 609/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.3279e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 610/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 4.5528e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 611/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.0073e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 612/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.7555e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 613/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.0479e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 614/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 4.6377e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 615/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 7.2238e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 616/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 4.2668e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 617/700\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 6.1741e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 618/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6116e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 619/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.3295e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 620/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.9165e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 621/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.0631e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 622/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.4317e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 623/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.9359e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 624/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1101e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 625/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.0470e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 626/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.2693e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 627/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0361e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 628/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0447e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 629/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.6748e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 630/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0599e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 631/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0072 - binary_accuracy: 0.9971 - false_negatives_1: 2.0000 - val_loss: 7.6514e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 632/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 3.8794e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 94ms/step - loss: 8.8873e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.7810e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 633/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 6.9779e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 105ms/step - loss: 5.9008e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.5018e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 634/700\n",
            "16/22 [====================>.........] - ETA: 0s - loss: 3.8729e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 103ms/step - loss: 2.8869e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.2612e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 635/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.4501e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.3215e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 636/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 1.4093e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 4s 175ms/step - loss: 1.1835e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.0784e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 637/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 1.3156e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 102ms/step - loss: 1.0379e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.7466e-06 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 638/700\n",
            "17/22 [======================>.......] - ETA: 0s - loss: 4.2826e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231002_154023-wke2j8mw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 2s 101ms/step - loss: 3.4006e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 9.6837e-06 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 639/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.0218e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.2702e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 640/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3599e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.4366e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 641/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.3709e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.6015e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 642/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.7562e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.5463e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 643/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.2915e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.8109e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 644/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.4868e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.4819e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 645/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 3.0453e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.7851e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 646/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.3730e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.5440e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 647/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0486e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.0938e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 648/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1204e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.5730e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 649/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 5.1881e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.6667e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 650/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.4618e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.6490e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 651/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.5747e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.8237e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 652/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.9922e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.4712e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 653/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.0420e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 5.0615e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 654/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.6431e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 4.8895e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 655/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 2.1108e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 2.3018e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 656/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.1501e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.2814e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 657/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.1704e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.2494e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 658/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.0901e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.2477e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 659/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 4.4461e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.2537e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 660/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0035 - binary_accuracy: 0.9986 - false_negatives_1: 0.0000e+00 - val_loss: 8.2703e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 661/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0016 - binary_accuracy: 0.9986 - false_negatives_1: 1.0000 - val_loss: 8.3571e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 662/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 9.3035e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.5080e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 663/700\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 3.3901e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.3840e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 664/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.5211e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.2760e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 665/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 3.0775e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.1294e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 666/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.4357e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 5.6865e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 667/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 1.6578e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.1589e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 668/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 8.9724e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.5868e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 669/700\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8.9139e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.4663e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 670/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.2447e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.5572e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 671/700\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 7.2177e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.5042e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 672/700\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.9846e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 6.1758e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 673/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 7.9883e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 7.9609e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 674/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0870e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.0597e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 675/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.2472e-04 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 8.1729e-05 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 676/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1981e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.2239e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 677/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 1.5742e-04 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 678/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1613e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 679/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0869e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0053 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 680/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.3646e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0060 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 681/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.9441e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0064 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 682/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.7403e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0068 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 683/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.3948e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0070 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 684/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.9543e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0070 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 685/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.0112e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0071 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 686/700\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 6.8447e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0065 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 687/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1580e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0065 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 688/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.7866e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0060 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 689/700\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 5.9880e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0060 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 690/700\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 3.6558e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0054 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 691/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.0754e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0054 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 692/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.0036e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 693/700\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 4.4902e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0050 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 694/700\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 5.0544e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0040 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 695/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.1574e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 696/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.9146e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0034 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 697/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.7981e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0035 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 698/700\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.6819e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0036 - val_binary_accuracy: 0.9957 - val_false_negatives_1: 1.0000\n",
            "Epoch 699/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.5091e-05 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n",
            "Epoch 700/700\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.7180e-06 - binary_accuracy: 1.0000 - false_negatives_1: 0.0000e+00 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_false_negatives_1: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x782fc8417850>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(model7.history.history)[['loss','val_loss']].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "jr8wcFNPDbHJ",
        "outputId": "84e989cb-bdda-47be-a35e-702e5c074236"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(model7.history.history)[['binary_accuracy','val_binary_accuracy']].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "wd7QG1oWIhHi",
        "outputId": "7972c1d3-1fb6-434f-bc7d-ca08ac518e35"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Go78TAiBJ86N"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x5F57tNBLV71"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}